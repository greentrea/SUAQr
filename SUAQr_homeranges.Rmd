---
title: "SUAQr_homeranges"
author: "Stefan Graf"
date: "2/14/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#### Script description
This is the main script for calculating the home ranges for individuals of orangutans.


```{r import, echo= 'F',results='hide'}
# CLASSICAL PACKAGE IMPORTER (Stefan Graf & Tobias Frey)
packages_checker <- function(packages_list){
  for (package in packages_list){
    if (!require(package, character.only = T)) {
      install.packages(package)
    }
    library(package, character.only = T)
  }
}

packages_checker(
  c('tripack', # circlecumferance function
    'bitops', # simple functions for HRE quality description
    'adehabitatMA', # simple functions for HRE quality description
    'adehabitatLT', # simple functions for HRE quality description
    'caTools', # calcualted area under the curve
    'networkD3',
    'patchwork', #testing diagrams
    'circlize', # testing circular plots
    'spatstat', # get nearest neighbour value for sf object
    'rgeos',
    'tidyr',
    'tmap',
    'tmaptools',# read_gpx function
    'hrbrthemes', # for colors --> viridis
    'rgdal',
    'ctmm',
    'lubridate',
    'plyr',
    'dplyr',
    'tidyr',
    'tidyverse',
    'stargazer',
    'sf', # Simple feature --> super spatial data handling structure
    'raster', # For raster data
    'rgdal',
    'plotly', # zoomable, pannable ggplot
    'move',# Brownian Bridge Movement Model
    'adehabitatHR', # home range algorithms etc.
    'lme4',
    'nlme',
    'ggplot2',
    'ggpubr',
    'GGally',
    'ggfortify', #check linear regression assumptions
    'GGally', # usefull pairs function to create many scatterplots
    'maptools',# used in move package
    'viridis',
    'lmerTest',
    'sp',
    'ks' # used in KDE functions
    ))
#install.packages("tlocoh", dependencies=TRUE, repos=c("http://R-Forge.R-project.org", "http://cran.cnr.berkeley.edu"), type="source")
#require(tlocoh)

rm(list = ls())
getwd()



### CUSTOM FUNCTIONS ###

# Function for displaying scale labels in ggplot not as f.e. 4e+05
fancy_scientific <- function(l) {
     # turn in to character string in scientific notation
     l <- format(l, scientific = TRUE)
     # quote the part before the exponent to keep all the digits
     l <- gsub("^(.*)e", "'\\1'e", l)
     # turn the 'e+' into plotmath format
     l <- gsub("e", "%*%10^", l)
     # return this as an expression
     parse(text=l)
}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
clockS = function(t){hour(t)*3600+minute(t)*60+second(t)}
st_kde <- function(points,cellsize, bandwith, extent = NULL){
  require(MASS)
  require(raster)
  require(sf)
  if(is.null(extent)){
    extent_vec <- st_bbox(points)[c(1,3,2,4)]
  } else{
    extent_vec <- st_bbox(extent)[c(1,3,2,4)]
  }
  
  n_y <- ceiling((extent_vec[4]-extent_vec[3])/cellsize)
  n_x <- ceiling((extent_vec[2]-extent_vec[1])/cellsize)
  
  extent_vec[2] <- extent_vec[1]+(n_x*cellsize)-cellsize
  extent_vec[4] <- extent_vec[3]+(n_y*cellsize)-cellsize
  
  coords <- st_coordinates(points)
  matrix <- kde2d(coords[,1],coords[,2],h = bandwith,n = c(n_x,n_y),lims = extent_vec)
  raster(matrix)
}




#### Custom functions for analysis
clockS = function(t){hour(t)*3600+minute(t)*60+second(t)}


euclid <- function(x1,y1,x2,y2){
  return(sqrt((x1-x2)^2+(y1-y2)^2))
}
calculate_mode <- function(x) {
  uniqx <- unique(na.omit(x))
  uniqx[which.max(tabulate(match(x, uniqx)))]
}
turning_angle <- function(x,y,lead_lag = 1){ 
  if(length(x) < 3){return(NA)}
  if(length(x) != length(y)){stop("x and y must be of the same length")}
  p1x <- lag(x,lead_lag)
  p1y <- lag(y,lead_lag)
  p2x <- x
  p2y <- y
  p3x <- lead(x,lead_lag)
  p3y <- lead(y,lead_lag)
  p12 <- euclid(p1x,p1y,p2x,p2y)
  p13 <- euclid(p1x,p1y,p3x,p3y)
  p23 <- euclid(p2x,p2y,p3x,p3y)
  rad <- acos((p12^2+p23^2-p13^2)/(2*p12*p23))
  grad <- (rad*180)/pi
  grad[p12 == 0 | p23 == 0] <- NA
  d <-  (p3x-p1x)*(p2y-p1y)-(p3y-p1y)*(p2x-p1x)
  d <- ifelse(d == 0,1,d)
  d[d>0] <- 1
  d[d<0] <- -1
  d[d==0] <- 1
  turning <- grad*d*-1+180
  return(turning)
}

# Source https://exploratory.io/note/kanaugust/1701090969905358
calculate_mode <- function(x) {
  uniqx <- unique(na.omit(x))
  uniqx[which.max(tabulate(match(x, uniqx)))]
}


# Statistics from here: https://github.com/aufrank/R-hacks/blob/master/mer-utils.R
vif.mer <- function (fit) {
    ## adapted from rms::vif

    v <- vcov(fit)
    nam <- names(fixef(fit))

    ## exclude intercepts
    ns <- sum(1 * (nam == "Intercept" | nam == "(Intercept)"))
    if (ns > 0) {
        v <- v[-(1:ns), -(1:ns), drop = FALSE]
        nam <- nam[-(1:ns)]
    }

    d <- diag(v)^0.5
    v <- diag(solve(v/(d %o% d)))
    names(v) <- nam
    v
}

aggregate.sf = function(x, by, FUN, ..., do_union = TRUE, simplify = TRUE,
		join = st_intersects) {

	if (inherits(by, "sf") || inherits(by, "sfc")) {
		if (inherits(by, "sfc"))
			by = st_sf(by)
		i = join(st_geometry(by), st_geometry(x))
		st_geometry(x) = NULL
		# dispatch to stats::aggregate:
		a = aggregate(x[unlist(i), , drop = FALSE],
			list(rep(seq_len(nrow(by)), lengths(i))), FUN, ...)
		nrow_diff = nrow(by) - nrow(a)
		if(nrow_diff > 0) {
			a_na = a[rep(NA, nrow(by)),] # 'top-up' missing rows
			a_na[a$Group.1,] = a
			a = a_na
		}
		a$Group.1 = NULL # remove
		row.names(a) = row.names(by)
		st_set_geometry(a, st_geometry(by))
	} else {
		crs = st_crs(x)
		lst = lapply(split(st_geometry(x), by), function(y) do.call(c, y))
		geom = do.call(st_sfc, lst[!sapply(lst, is.null)])

		if (do_union)
			geom = st_union(st_set_precision(geom, st_precision(x)), by_feature = TRUE)

		st_geometry(x) = NULL
		x = aggregate(x, by, FUN, ..., simplify = simplify)
		st_geometry(x) = geom # coerces to sf
		st_crs(x) = crs

		# now set agr:
		geoms = which(vapply(x, function(vr) inherits(vr, "sfc"), TRUE))
		agr_names = names(x)[-geoms]
		agr = rep("aggregate", length(agr_names))
		names(agr) = agr_names
		# which ones are identity variables?
		n = if (!is.null(names(by)))
			names(by)
		else
			paste0("Group.", seq_along(by))
		agr[n] = "identity"
		st_agr(x) = agr

		x
	}
}

#### read in homeranges from shp list in data f.e. for ctmm results
st_read_homeranges <- function(flnm){
    out <- tryCatch(
        { message("Try to read file")
            file <- data.frame()
            start <- Sys.time()
            file <- st_read(flnm) # better than read_GPX
            file<- st_transform(file,crs = 23867)
            #if(class(file)[1]=="list"){file <- file$waypoints} # only use if read_GPX is used
            end <- Sys.time()
            processduration <- end-start
            file <- file %>% #Skip the first 16 rows because see below
              mutate(fileN=substr(flnm, regexpr("\\/[^\\/]*$", flnm)+1,nchar(flnm)-4)) %>% 
              separate(fileN,c("number","hrprcnt","focal2","skip","model","modeltype"),sep =" ")%>%
              separate(name,c("focal","hrprcnt","statisticalBoundary"),sep =" ") %>% 
              filter(statisticalBoundary=="est") %>% 
              dplyr::select(-skip,-number,-focal2)

            return(file)
        },
        error=function(cond) {
            message(paste("File seems not to exist", flnm))
            message("Here's the original error message:")
            message(cond)
            # Choose a return value in case of error
            return(data.frame()) # use dataframe as return instead of NA --> See here why, without it throws an error. https://stackoverflow.com/questions/48512461/error-in-bind-rows-x-id-argument-1-must-have-names-using-map-df-in-purrr
        },
        warning=function(cond) {
            message(paste("Loading file didn't work", flnm))
            message("Here's the original warning message:")
            message(cond)
            # Choose a return value in case of warning
            return(data.frame())
        },
        finally={
            message(paste("Processed URL: ", flnm," Duration: ",processduration))
            message("Finished")
        }
    )    
    return(out)
}

setwd("/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/")

schoener <- function(tr, keep, byburst=TRUE)
{
    ## Verifications
    if (!inherits(tr, "traj"))
        stop("tr should be of class traj")

    ## Remove the missing values
    tr <- tr[!is.na(tr$x),]
    tr <- tr[!is.na(tr$y),]

    ## splits per burst or id
    li <- split(tr, tr$id)
    if (byburst)
        li <- split(tr, tr$burst)

    ## This function computes the schoener ratio
    ## for each element of this list
    foo <- function(tr) {

        ## Computation of r2
        d <- unclass(tr$date)
        x <- tr[,c("x","y")]
        r2 <- sum(((x[,1]-mean(x[,1]))^2) +
                  ((x[,2]-mean(x[,2]))^2))/(nrow(x) -1)

        ## Computation of t2
        diffd <- outer(d,d,"-")
        t2tmp <- as.matrix(dist(x)^2)
        cons <- diffd>keep[1]&diffd<keep[2]
        t2 <- sum(t2tmp[cons])/sum(cons)

        ## The ratio
        rat <- t2/r2
        n <- nrow(x)
        m <- sum(cons)

        ## Output
        return(c(rat, n, m))
    }

    ## The function is applied to each element of the list
    rr <- do.call("rbind", lapply(li, foo))
    rr <- as.data.frame(rr)
    row.names(rr) <- names(li)
    names(rr) <- c("value","n","m")

    ## Output
    return(rr)
}
.checktz <- function(x)
{
    if (!inherits(x, "ltraj"))
        stop("x should be of class \"ltraj\"")
    tz <- lapply(x, function(y) attr(y$date, "tzone"))
    atz <- all(sapply(1:length(tz), function(i) identical(tz[[i]],tz[[1]])))
    if (!atz)
        stop("multiple time zones not allowed in objects of class ltraj")
    if (is.null(tz[[1]]))
        return("")
    if (tz[[1]]=="")
        return("")
    return(tz[[1]])
}
ltraj2traj <- function(x)
{
    if (!inherits(x, "ltraj"))
        stop("x should be of class \"ltraj\"")
    if (!attr(x,"typeII"))
        stop("x should be of type II (time recorded")
    id <- factor(unlist(lapply(x, function(y)
                               id <- rep(attr(y,"id"), nrow(y)))))
    burst <- factor(unlist(lapply(x, function(y)
        id <- rep(attr(y,"burst"), nrow(y)))))
    if (attr(x,"typeII"))
        tz <- .checktz(x)
    if (!is.null(infolocs(x)))
        infol <- do.call("rbind", infolocs(x))
    res <- do.call("rbind", x)
    res <- cbind(id,burst,res)
    if (!is.null(infolocs(x)))
        res <- cbind(res, infol)
    class(res) <- c("traj","data.frame")
    return(res)
}


normalize <- function(x){
  return((x-min(x)) / (max(x)-min(x)))
}
```

#### SUAQ homerange analysis

```{r GPS Loader,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}

### Load Project variables ### 
##### waypoints ##### "data/Processed_data/SUAQ_waypoints_11all20.csv"
##### ATTENTION: read_csv guesses a columns type as boolean if first 1200 entries are NA
# find most recent file
mostrecent <- list.files(path = "data/Processed_data/", full.names = FALSE, recursive = FALSE)
mostrecent <- as.data.frame(mostrecent)
mostrecent <- mostrecent %>% filter(grepl("SUAQ_waypoints_11all20",mostrecent)) %>% 
  mutate(date=as.numeric(str_extract(mostrecent,"\\d{8}"))) %>% arrange(desc(date)) %>% top_n(1,date)

SUAQ_waypoints_11all20_loc <-
  read_csv(paste0("data/Processed_data/",mostrecent$date[1],"_SUAQ_waypoints_11all20.csv"),guess_max = min(10000, 30000))
SUAQ_waypoints_11all20_loc <- SUAQ_waypoints_11all20_loc %>% mutate(monthYearDate=format(as.Date(manualDate), "%Y-%m"))
SUAQ_waypoints_11all20_loc <- SUAQ_waypoints_11all20_loc %>% mutate(automaticDatetime=with_tz(automaticDatetime,tz = "Asia/Pontianak"))
SUAQ_waypoints_11all20_loc <- SUAQ_waypoints_11all20_loc %>% mutate(manualDatetime=with_tz(manualDatetime,tz = "Asia/Pontianak"))
SUAQ_waypoints_11all20_loc <- SUAQ_waypoints_11all20_loc %>% 
  mutate(month=as.factor(month(lubridate::ym(monthYearDate)))) %>% 
  mutate(monthname=month.name[month])%>%
  mutate(year=as.character(year(lubridate::ym(monthYearDate))))%>%
  mutate(rainyseason=ifelse(month %in% c(10,11,12),"rainy","normal"))

SUAQ_orangutans <-
  read_csv(paste0("data/Processed_data/",mostrecent$date[1],"_SUAQ_orangutans.csv"),guess_max = min(10000, 30000))
#### add party individuals as individual gps points.
SUAQ_waypoints_11all20_loc_party <- SUAQ_waypoints_11all20_loc %>% filter(PtType%in%c("party"))

SUAQ_waypoints_11all20_loc_party1 <- SUAQ_waypoints_11all20_loc_party %>% 
  dplyr::select(altitude,name_original,sym,fileN,gpsextraction,gpsextractionquality,filedate,followername,manualDatetime, manualTime, manualDate, automaticDatetime, automaticTime,automaticDate,PtType,E,N,AgeSex,follow,PtType_individual_1) %>% filter(!is.na(PtType_individual_1)) %>%  mutate(focal=PtType_individual_1,PtType="party2") %>% dplyr::select(-PtType_individual_1) 

SUAQ_waypoints_11all20_loc_party2 <- SUAQ_waypoints_11all20_loc_party %>% 
  dplyr::select(altitude,name_original,sym,fileN,gpsextraction,gpsextractionquality,filedate,followername,manualDatetime, manualTime, manualDate, automaticDatetime, automaticTime,automaticDate,PtType,E,N,AgeSex,follow,PtType_individual_2) %>% filter(!is.na(PtType_individual_2)) %>%  mutate(focal=PtType_individual_2,PtType="party2") %>% dplyr::select(-PtType_individual_2) 

#### Combine datasets if for one follow there is an individual at party1 and at party2 position (f.e. if maybe at the first party point another individual was present but at the second on the same follow not) its still gets one new follownumber.
SUAQ_waypoints_11all20_loc_party <- SUAQ_waypoints_11all20_loc_party1 %>% bind_rows(SUAQ_waypoints_11all20_loc_party2)

SUAQ_waypoints_11all20_loc_party <- SUAQ_waypoints_11all20_loc_party%>% 
  group_by(fileN,focal,manualDate,follow) %>% # if .$follow it can be modified later idk why with only "follow" it doesnt work
  mutate(follow = as.numeric(cur_group_id()+1110000))## adding FN above 11

SUAQ_waypoints_11all20_loc_party <- SUAQ_waypoints_11all20_loc_party%>% 
  mutate(ClassFocal=SUAQ_orangutans[SUAQ_orangutans$SUAQ_orangutans.orangutanname==focal,]$SUAQ_orangutans.Class) %>% 
  mutate(ClassFocal=ifelse(ClassFocal=="mother","adult female",ClassFocal)) %>% 
  mutate(ClassFocal=ifelse(ClassFocal=="unfl.male","unflanged male",ClassFocal))


SUAQ_waypoints_11all20_loc <- SUAQ_waypoints_11all20_loc %>% 
  bind_rows(SUAQ_waypoints_11all20_loc_party)

##### Weather and FAI #####
SUAQ_weather <- read_csv("data/Processed_data/SUAQ_weather.csv")
SUAQ_fai <- read_csv("data/Processed_data/SUAQ_fai.csv")

SUAQ_weather_monthly<-SUAQ_weather %>% 
  group_by(SUAQ_weather.year,SUAQ_weather.month) %>% 
  summarise_all(funs(mean))
SUAQ_weather_monthly<- SUAQ_weather_monthly%>% dplyr::select(-SUAQ_weather.weather_id,-SUAQ_weather.day,-SUAQ_weather.daymonthyear)

##### location network ##### 
SUAQ_locationnetwork_sf <- st_read("data/20201201_StudyBalimbingStudyArea_points.GPX")
SUAQ_locationnetwork_sf_loc <- st_transform(SUAQ_locationnetwork_sf,crs = 23867)
##### for locale coordinate system
coordinates_tmp <- st_coordinates(SUAQ_locationnetwork_sf_loc)
colnames(coordinates_tmp) <- c("E","N")
SUAQ_locationnetwork_sf_loc <- cbind(SUAQ_locationnetwork_sf_loc,coordinates_tmp)
SUAQ_locationnetwork_loc <- st_drop_geometry(SUAQ_locationnetwork_sf_loc)

SUAQ_pathnetwork<- as.data.frame(read_GPX(file="data/SUAQ_Peta_WithLines.GPX",layers = c("routes")))
colnames(SUAQ_pathnetwork)[15]<- "geometry"
SUAQ_pathnetwork_sf<- st_as_sf(SUAQ_pathnetwork,crs=4326)
SUAQ_pathnetwork_sf_loc <- st_transform(SUAQ_pathnetwork_sf,crs = 23867)

##### physical features for plots
SUAQ_river_sf_wgs<- st_read(dsn="data/external/GeodataIndonesia/Wasser/fluss_50k_perimetergross.shp")
SUAQ_river_sf_loc <- st_transform(SUAQ_river_sf_wgs,crs = 23867)

SUAQ_smallriver_sf_wgs<- st_read(dsn="data/external/GeodataIndonesia/Wasser/kleinflüsse_50k_perimetergross.shp")
SUAQ_smallriver_sf_loc <- st_transform(SUAQ_smallriver_sf_wgs,crs = 23867)

SUAQ_contour_sf_wgs<- st_read(dsn="data/external/GeodataIndonesia/Hoehenllinien/hohenlinien_50k_perimetergross.shp")
SUAQ_contour_sf_loc <- st_transform(SUAQ_contour_sf_wgs,crs = 23867)

SUAQ_station_sf_wgs<- st_read(dsn="data/external/researchstation.shp")
SUAQ_station_sf_loc <- st_transform(SUAQ_station_sf_wgs,crs = 23867)

##### Selection only pointtypes which are taken on the orangutan way? is this true for all? ##### 
SUAQ_rangepoints_11all20_loc <- SUAQ_waypoints_11all20_loc %>% filter(PtType %in% c("daynest","found","lost","mornnest","nightnest","range","tree", "party2")) # get rid of lcg lch points and party one is not taken because sometimes party points are seperatly taken and we end up with two points for an individual at the same time

##### Change trackpoint_id and total num of GPS per follow
###### trackpoint ID 
SUAQ_rangepoints_11all20_loc <- SUAQ_rangepoints_11all20_loc %>% group_by(follow) %>% dplyr::select(-trackpoint_id) %>% mutate(trackpoint_id = row_number())
###### Definitive number of gps per follow
result_totnumfollows <- SUAQ_rangepoints_11all20_loc %>% 
  group_by(follow) %>% summarise(follow_totNumOfGPSpoints=n()) # 1323 Follows
SUAQ_rangepoints_11all20_loc <- SUAQ_rangepoints_11all20_loc %>%dplyr::select(-follow_totNumOfGPSpoints) %>% left_join(result_totnumfollows,by=c("follow"="follow"))
###### orangutan number of points ID 
result_numoffollows<- SUAQ_rangepoints_11all20_loc %>% group_by(follow,focal) %>% summarise(count=n()) %>% group_by(focal) %>% summarise(count=n())
specs_orangutan_tot_num_of_gps <-SUAQ_rangepoints_11all20_loc %>% 
  group_by(focal) %>%
  summarise(n()) %>% left_join(result_numoffollows,by=c('focal'='focal'))
colnames(specs_orangutan_tot_num_of_gps) <- c("focal",
                                           "orangutan_tot_num_of_gps","orangutan_num_of_follows")
tmp<- specs_orangutan_tot_num_of_gps
SUAQ_rangepoints_11all20_loc <-SUAQ_rangepoints_11all20_loc %>% dplyr::select(-orangutan_num_of_follows,-orangutan_tot_num_of_gps) %>% 
  left_join(tmp,by = c("focal" = "focal"))

##### Recalculate edge lengths etc. based on new point selection for rangepoints dataframe
SUAQ_rangepoints_11all20_loc<- SUAQ_rangepoints_11all20_loc %>% 
  group_by(follow)%>% arrange(manualTime,.by_group = TRUE) %>% 
  mutate(timelag=as.numeric(difftime(as.POSIXlt(manualTime),
                                     as.POSIXlt(lag(manualTime)),units 
                                     ="secs")),
         # calculate distance with approach number 1 --> st_distance but to do that we need to calculate lead first because the lead function doesnt work within st distance (not same datatype (df))
         timelag_lead=as.numeric(difftime(as.POSIXlt(lead(manualTime)),
                                          as.POSIXlt(manualTime),units ="secs")),
         manual_distTolast=sqrt((E-lag(E))^2+(N-lag(N))^2),
         manual_distToNext=sqrt((E-lead(E))^2+(N-lead(N))^2),
         speed_last = manual_distTolast/timelag,
         speed_next = manual_distToNext/timelag_lead,
         turningAngle=turning_angle(E,N),
         altitudediff_next=altitude-lead(altitude),
         )





##### WGS84 file
SUAQ_rangepoints_11all20_loc_sf <-  st_as_sf(SUAQ_rangepoints_11all20_loc, 
                          coords = c("E","N"), 
                          crs = 23867) # can also do that in the new sricpts
SUAQ_rangepoints_11all20_loc_wgs <- st_transform(SUAQ_rangepoints_11all20_loc_sf,4326)
coordinates_tmp <- st_coordinates(SUAQ_rangepoints_11all20_loc_wgs)
colnames(coordinates_tmp) <- c("long","lat")
SUAQ_rangepoints_11all20_loc_wgs <- cbind(SUAQ_rangepoints_11all20_loc_wgs,coordinates_tmp)
SUAQ_rangepoints_11all20_loc_wgs<- st_drop_geometry(SUAQ_rangepoints_11all20_loc_wgs)


##### Selection only females / most tracked females ##### 
SUAQ_rangepoints_11all20_loc_females <-
  SUAQ_rangepoints_11all20_loc %>%   filter(!(SUAQ_orangutans.Sex == "male")) %>% ungroup()

SUAQ_rangepoints_11all20_loc_above50GPS <- SUAQ_rangepoints_11all20_loc %>% filter(orangutan_tot_num_of_gps>250) %>% 
  filter(!(ClassFocal%in%c("character(0)","infant","juvenile")))
levels(as.factor(SUAQ_rangepoints_11all20_loc$ClassFocal))
SUAQ_rangepoints_11all20_loc_females_above50GPS <- SUAQ_rangepoints_11all20_loc %>% filter(!(SUAQ_orangutans.Sex == "male")) %>% filter(orangutan_tot_num_of_gps>50)

SUAQ_rangepoints_11all20_loc_males_above50GPS <- SUAQ_rangepoints_11all20_loc %>% filter((SUAQ_orangutans.Sex == "male")) %>% filter(orangutan_tot_num_of_gps>50)

SUAQ_rangepoints_11all20_loc_females_10 <-
  SUAQ_rangepoints_11all20_loc %>%   filter(!(SUAQ_orangutans.Sex == "male")) %>% filter(
    focal %in% c(
      "lisa",
      "friska",
      "ellie",
      "cissy",
      "lilly",
      "yulia",
      "raffi",
      "sarabi",
      "trident",
      "tiara"
    )
  )%>% ungroup()


#### Read in most recent bandwiths for KDE if not newly calculated
mostrecent <- list.files("/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/output/Homeranges/KDE/bandwiths/", full.names = FALSE, recursive = FALSE)
mostrecent <- as.data.frame(mostrecent)
colnames(mostrecent) <- c("date")
mostrecent <- mostrecent %>% filter(date!="_archive") %>%  arrange(desc(date)) %>% top_n(1,date)
imdir <-paste("/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/output/Homeranges/KDE/bandwiths/")
bandwiths <- read_csv(paste0(imdir,paste(mostrecent$date[1], sep="")))

#### Homerange calculations parameter
### Extent
# use always same extent
extentmargin <- 500
extentfactor <- 0.1
axisshifty <- 110 # shift of axis in plots x axis
axisshiftx <- -50 # shift of axis in plots y axis
    
legendoffsetx <- 0.03
legendoffsety <- -0.03
xmin <- min(SUAQ_rangepoints_11all20_loc_females_10$E)-extentmargin 
xmax <- max(SUAQ_rangepoints_11all20_loc_females_10$E)+extentmargin
ymin <- min(SUAQ_rangepoints_11all20_loc_females_10$N)-extentmargin 
ymax <- max(SUAQ_rangepoints_11all20_loc_females_10$N)+extentmargin
step <- 25 # resolution size of grid used in plotting
axisstep <- 200 # resolution size of grid used in plotting

xmin_xmax_round_steps<- c(axisstep*(ceiling(xmin/axisstep)):(round(xmax/axisstep)))
xmin_xmax_round_steps <- xmin_xmax_round_steps[2:(length(xmin_xmax_round_steps)-2)] #manual adjustment of tick breaks how many does it need
ymin_ymax_round_steps<- c(axisstep*(ceiling(ymin/axisstep)):(round(ymax/axisstep)))
ymin_ymax_round_steps <- ymin_ymax_round_steps[2:(length(ymin_ymax_round_steps)-1)] #manual adjustment of tick breaks how many does it need

# second approach
#########same grid for all#########
xgrid <- seq(xmin,xmax,by=step)
ygrid <- seq(ymin,ymax,by=step)
grid <- expand.grid(x=xgrid,y=ygrid)
coordinates(grid) <- ~x+y
gridded(grid) <- TRUE
class(grid)

# Extent for background layers
SUAQ_river_sf_loc<- st_crop(SUAQ_river_sf_loc, c(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax))
SUAQ_smallriver_sf_loc<- st_crop(SUAQ_smallriver_sf_loc, c(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax))
SUAQ_contour_sf_loc<- st_crop(SUAQ_contour_sf_loc, c(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax))
SUAQ_station_sf_loc<- st_crop(SUAQ_station_sf_loc, c(xmin = xmin, ymin = ymin, xmax = xmax, ymax = ymax))




#### research periods data as list
# Split the data into 4 sampling periods. Calculate the respective HR.
SUAQ_rangepoints_11all20_loc_females_10 <- SUAQ_rangepoints_11all20_loc_females_10 %>% mutate(year=year(manualDatetime))

# make 5 lists for all 4 research periods and one for all data
period_list <- split(SUAQ_rangepoints_11all20_loc_females_10, f = SUAQ_rangepoints_11all20_loc_females_10$researchperiod)

# add all data as the 5th list (period)
period_list[["total research period"]] <- SUAQ_rangepoints_11all20_loc_females_10
period_list <- period_list[c("total research period","before 2012","2012 until 2016","2016 until August 2018","Since August 2018")]

# make lists for every year
year_list <- split(SUAQ_rangepoints_11all20_loc_females_10, f = SUAQ_rangepoints_11all20_loc_females_10$year)

#### Selected animals as list/vector
selected_females <- SUAQ_rangepoints_11all20_loc_females_10 %>% group_by(focal) %>% summarise()
selected_females <- as_vector(selected_females)


```

```{r Autocorrelation,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
results <- data.frame()
for (i in selected_females){
xy_selected <- SUAQ_rangepoints_11all20_loc_females_10 %>%
  dplyr::select(E,N,timelag_lead,manualDatetime,focal,researchperiod) %>% filter(focal==i) %>% 
  mutate(manualDatetime=as.POSIXct(manualDatetime,tz="Asia/Pontianak"))
dupes<-xy_selected$manualDatetime[duplicated(xy_selected$manualDatetime)] 
colnames(xy_selected) <- c("x","y","timelag_lead","timestamp","focal","researchperiod") #adjust column names
xy_selected <- xy_selected %>%  mutate(timelag_lead = round(timelag_lead,digits=0))
xy_selected <- xy_selected %>%  mutate(timelag_lead = round(timelag_lead,digits=0))

xy_selected <- xy_selected[order(xy_selected$timestamp , decreasing = FALSE ),] 

traj <- as.ltraj(xy=xy_selected[,c("x", "y")], date=xy_selected$timestamp, id=i)
traj<- ltraj2traj(traj)
numbers<- as.data.frame(schoener(traj,keep = c(1*60, 70*60))) %>% cbind(focal=i)
results <- results %>% rbind(numbers)
}

result_totnumfollows_perset <- SUAQ_waypoints_11all20 %>% 
  group_by(follow,gpsextraction) %>% summarise(follow_totNumOfGPSpoints=n()) %>% group_by(gpsextraction) %>% summarise(numfollows=n(),numGPS=sum(follow_totNumOfGPSpoints,na.rm = TRUE)) # 1323 Follows


write.csv(results,"/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/autocorrelation_analysis_full")
```
Homerange sizes:

# Homerange calculations
## MCP
```{r MCP - HR per-researchperiods and all ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/MCP/periods/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/MCP/periods/",format(Sys.Date(), "%Y%m%d"), "/", sep="")


mcp_list <- data.frame()

for (samplinginterval in c(1:length(period_list))){
  print(paste("mcp for period: ",samplinginterval))
  ##### Determine the smoothing parameters
  selected_females <- period_list[[samplinginterval]] %>% group_by(focal) %>% summarise()
  selected_females <- as_vector(selected_females)
  
  iterator <- 1
  for (i in selected_females) { # do the following for every animal in the list
    print(paste("mcp for focal: ",i))
    n_follows <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
        group_by(follow) %>% summarise() %>% nrow() # just as a variable for later results dataframe --> number of follows

    xy_selected <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
      dplyr::select(E,N)
    n_gps <- xy_selected %>% nrow() # just as a variable for later results dataframe --> number of GPS points
    
    coordinates(xy_selected) <- c("E","N")
    proj4string(xy_selected) <- CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs" )
    
    # check if enough gps points are still here otherwise make NA's
    xy_selected_toolessdata <- TRUE
    if(length(xy_selected)<30){xy_selected_toolessdata <- FALSE}
    
    iterator <- iterator+1
    
      if(xy_selected_toolessdata){# only execute when enough data
      hr100<- mcp(xy_selected,percent = 100)
      hr99 <- mcp(xy_selected,percent = 99)
      hr95 <- mcp(xy_selected,percent = 95)
      hr50 <- mcp(xy_selected,percent = 50)
      hr100_area <- mcp.area(xy_selected, percent = 100,unout = "km2")
      hr99_area <- mcp.area(xy_selected, percent = 99,unout = "km2")
      hr95_area <- mcp.area(xy_selected, percent = 95,unout = "km2")
      hr50_area <- mcp.area(xy_selected, percent = 50,unout = "km2")
      hr100_sf<- st_as_sf(hr100)
      hr99_sf<- st_as_sf(hr99)
      hr95_sf<- st_as_sf(hr95)
      hr50_sf<- st_as_sf(hr50)
      
      png(paste(imdir,i, "_MCP_UD_",names(period_list)[samplinginterval], ".png", sep=""), width=900, height=700, res=120, units="px")
      plot(xy_selected,pch = 16,cex=0.3,fill="darkolivegreen", xlab="x [m]",ylab="y [m]",xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1)))
      plot(hr50, lty=3, lwd=2.5, border="coral1", add=T,axes=F)
      plot(hr95, lty=1, lwd=2, border="cadetblue2", add=T, axes=F)
      plot(hr99, lty=4, lwd=0.8, border="darkturquoise", add=T, axes=F)
      plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 0.7), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 0.7),lwd=0.3, bg="darkred", add=T, axes=F)
      plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
      plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkred", 0.7), add=T, axes=F)
      axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
      axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
      title(paste(i, " : ",names(period_list)[samplinginterval], sep=""), line=-1.5)
      legend("topright", c("HR 50%", "HR 95%", "HR 100%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsety,legendoffsety))
      dev.off()
      }
      

    ########## export results ############
    if (xy_selected_toolessdata) {
      resultList_50 <-
        data.frame(
          focal = i,
          homerange = hr50_area$a,
          hrpercentage = "50%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(period_list)[samplinginterval],
          geometry= hr50_sf$geometry
        )
      resultList_95 <-
        data.frame(
          focal = i,
          homerange = hr95_area$a,
          hrpercentage = "95%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(period_list)[samplinginterval],
          geometry= hr95_sf$geometry
        )
      resultList_99 <-
        data.frame(
          focal = i,
          homerange = hr99_area$a,
          hrpercentage = "99%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(period_list)[samplinginterval],
          geometry= hr99_sf$geometry
        )
      resultList_100 <-
        data.frame(
          focal = i,
          homerange = hr100_area$a,
          hrpercentage = "100%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(period_list)[samplinginterval],
          geometry= hr100_sf$geometry
        )
    }
    if (!xy_selected_toolessdata) {
      resultList_50 <-
        data.frame(
          focal = i,
          homerange = NA,
          hrpercentage = "50%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(period_list)[samplinginterval],
          geometry= NA
        )
      resultList_95 <-
        data.frame(
          focal = i,
          homerange = NA,
          hrpercentage = "95%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(period_list)[samplinginterval],
          geometry= NA
        )
      resultList_99 <-
        data.frame(
          focal = i,
          homerange = NA,
          hrpercentage = "99%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(period_list)[samplinginterval],
          geometry= NA
        )
      resultList_100 <-
        data.frame(
          focal = i,
          homerange = NA,
          hrpercentage = "100%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(period_list)[samplinginterval],
          geometry= NA
        )
    }
    mcp_list <- mcp_list %>% rbind(resultList_50,resultList_95,resultList_99,resultList_100)
    print(paste(i,": Calculation finished", sep=""))
  }
}

st_write(mcp_list, dsn = paste(
  paste(
    imdir,
    "mcp_values_allperiods",
    sep = ""
  ),
  "shp",
  sep = "."
))
#system("say alle minimum konvex Polygone berechnet für die verschiedenen Untersuchungsperioden")


```

```{r MCP - HR per-year ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/MCP/years/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/MCP/years/",format(Sys.Date(), "%Y%m%d"), "/", sep="")


mcp_list <- data.frame() # results

for (samplinginterval in c(1:length(year_list))){
  print(paste("mcp for period: ",samplinginterval))
  ##### Determine the smoothing parameters
  selected_females <- year_list[[samplinginterval]] %>% group_by(focal) %>% summarise()
  selected_females <- as_vector(selected_females)
  
  iterator <- 1
  for (i in selected_females) { # do the following for every animal in the list
    print(paste("mcp for focal: ",i))
    n_follows <- year_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
        group_by(follow) %>% summarise() %>% nrow() # just as a variable for later results dataframe --> number of follows

    xy_selected <- year_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
      dplyr::select(E,N)
    n_gps <- xy_selected %>% nrow() # just as a variable for later results dataframe --> number of GPS points
    
    coordinates(xy_selected) <- c("E","N")
    proj4string(xy_selected) <- CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " )
    
    # check if enough gps points are still here otherwise make NA's
    xy_selected_toolessdata <- TRUE
    if(length(xy_selected)<30){xy_selected_toolessdata <- FALSE}
    
    iterator <- iterator+1
    
      if(xy_selected_toolessdata){# only execute when enough data
      hr100<- mcp(xy_selected,percent = 100)
      hr99 <- mcp(xy_selected,percent = 99) 
      hr95 <- mcp(xy_selected,percent = 95)
      hr50 <- mcp(xy_selected,percent = 50)
      hr100_area <- mcp.area(xy_selected, percent = 100,unout = "km2")
      hr99_area <- mcp.area(xy_selected, percent = 99,unout = "km2")
      hr95_area <- mcp.area(xy_selected, percent = 95,unout = "km2")
      hr50_area <- mcp.area(xy_selected, percent = 50,unout = "km2")
  
      
      png(paste(imdir,i, "_MCP_UD_",names(year_list)[samplinginterval], ".png", sep=""), width=900, height=700, res=120, units="px")
      plot(xy_selected,pch = 16,cex=0.3,fill="darkolivegreen", xlab="x [m]",ylab="y [m]",xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1)))
      plot(hr50, lty=3, lwd=2.5, border="coral1", add=T,axes=F)
      plot(hr95, lty=1, lwd=2, border="cadetblue2", add=T, axes=F)
      plot(hr99, lty=4, lwd=2, border="darkturquoise", add=T, axes=F)
      plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 0.7), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 0.7),lwd=0.3, bg="darkred", add=T, axes=F)
      plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
      plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
      axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
      axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
      title(paste(i, " : ",names(year_list)[samplinginterval], sep=""), line=-1.5)
      legend("topright", c("HR 50%", "HR 95%", "HR 100%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsety,legendoffsety))
      dev.off()
      }
      

    ########## export results ############
    if (xy_selected_toolessdata) {
      resultList_50 <-
        data.frame(
          focal = i,
          homerange = hr50_area$a,
          hrpercentage = "50%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(year_list)[samplinginterval],
          geometry= hr50_sf$geometry
        )
      resultList_95 <-
        data.frame(
          focal = i,
          homerange = hr95_area$a,
          hrpercentage = "95%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(year_list)[samplinginterval],
          geometry= hr95_sf$geometry
        )
      resultList_99 <-
        data.frame(
          focal = i,
          homerange = hr99_area$a,
          hrpercentage = "99%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(year_list)[samplinginterval],
          geometry= hr99_sf$geometry
        )
      resultList_100 <-
        data.frame(
          focal = i,
          homerange = hr100_area$a,
          hrpercentage = "100%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(year_list)[samplinginterval],
          geometry= hr100_sf$geometry
        )
    }
    if (!xy_selected_toolessdata) {
      resultList_50 <-
        data.frame(
          focal = i,
          homerange = NA,
          hrpercentage = "50%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(year_list)[samplinginterval],
          geometry= NA
        )
      resultList_95 <-
        data.frame(
          focal = i,
          homerange = NA,
          hrpercentage = "95%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(year_list)[samplinginterval],
          geometry= NA
        )
      resultList_99 <-
        data.frame(
          focal = i,
          homerange = NA,
          hrpercentage = "99%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(year_list)[samplinginterval],
          geometry= NA
        )
      resultList_100 <-
        data.frame(
          focal = i,
          homerange = NA,
          hrpercentage = "100%",
          n_gps = n_gps,
          n_follows = n_follows,
          period = names(year_list)[samplinginterval],
          geometry= NA
        )
    }
    mcp_list <- mcp_list %>% rbind(resultList_50,resultList_95,resultList_99,resultList_100)
    print(paste(i,": Calculation finished", sep=""))
  }
}

st_write(mcp_list, dsn = paste(
  paste(
    imdir,
    "mcp_values_years",
    sep = ""
  ),
  "shp",
  sep = "."
))
system("say alle minimum konvex Polygone berechnet für jedes Jahr")


```

```{r MCP -  HR sizes with bootstrap ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
### Homerange Stability
##### Using MCP --> The latter plot probably shows more the usage then the stability because mcp.area takes the points away based on their spatial location
mcp.area(SUAQ_rangepoints_11all20_loc_females_more50GPS.sp, percent = seq(30, 90, by = 5))

##### FEMALES: Using MCP bootstrapping, randomly selecting points
SUAQ_move_selected <- SUAQ_rangepoints_11all20_loc_females_10[order(SUAQ_rangepoints_11all20_loc_females_10$focal,SUAQ_rangepoints_11all20_loc_females_10$manualDatetime , decreasing = FALSE ),] %>% ungroup()

SUAQ_move_selected <- move(x=SUAQ_move_selected$E, y=SUAQ_move_selected$N, 
              time=as.POSIXct(SUAQ_move_selected$manualDatetime, format="%Y-%m-%d %H:%M:%OS", tz="Asia/Pontianak"),
              proj=CRS("+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs "), 
              data=SUAQ_move_selected, animal=SUAQ_move_selected$focal, sensor="gps")
all<- hrBootstrap(x=SUAQ_move_selected, rep=25,level=100,
            levelMax=100, unin="m",unout='km2')

##### Exkurs MALES: Using MCP bootstrapping, randomly selecting points
SUAQ_move_selected <- SUAQ_rangepoints_11all20_loc_above50GPS[order(SUAQ_rangepoints_11all20_loc_above50GPS$focal,SUAQ_rangepoints_11all20_loc_above50GPS$manualDatetime , decreasing = FALSE ),] %>% ungroup()

SUAQ_move_selected <- move(x=SUAQ_move_selected$E, y=SUAQ_move_selected$N, 
              time=as.POSIXct(SUAQ_move_selected$manualDatetime, format="%Y-%m-%d %H:%M:%OS", tz="Asia/Pontianak"),
              proj=CRS("+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs "), 
              data=SUAQ_move_selected, animal=SUAQ_move_selected$focal, sensor="gps")
all<- hrBootstrap(x=SUAQ_move_selected, rep=25,level=100,plot=FALSE,
            levelMax=100, unin="m",unout='km2')
all_flatten<- data.frame(do.call(rbind, all))
all_flatten$name<- rownames(all_flatten)
all_flatten <- all_flatten %>% rowwise() %>%  mutate(focal=strsplit(name,"\\.")[[1]][1],points=as.numeric(strsplit(name,"\\.")[[1]][2])) %>% 
  dplyr::select(-name) %>% left_join(SUAQ_orangutans[,c(1,3)],by=c("focal"="orangutanname")) 

all_flatten %>% ggplot()+geom_path(aes(x=points,X50.,colour=focal,linetype=Sex)) + scale_x_log10()+
  geom_path(aes(x=points,X50.,colour=focal,linetype=Sex))+
  geom_path(aes(x=points,X0.,colour=focal,linetype=Sex,alpha=0.5))+
  geom_path(aes(x=points,X100.,colour=focal,linetype=Sex,alpha=0.5))
```

```{r MCP -  HR sizes with bootstrap new approach ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
### Homerange Stability
##### Using MCP --> The latter plot probably shows more the usage then the stability because mcp.area takes the points away based on their spatial location
# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/MCP/bootstrap/sampling/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/MCP/bootstrap/sampling/",format(Sys.Date(), "%Y%m%d"), "/", sep="")


#### amount of data
amountofdata <- seq(0.1,10,by=0.1)/10
mcp_list_bootstrap <- data.frame() # results
follows <- SUAQ_rangepoints_11all20_loc_females_10 %>% group_by(follow) %>% summarise()

for(per in amountofdata){
  print(paste("PERCENTAGE: ",per))

  selected_females <- SUAQ_rangepoints_11all20_loc_females_10 %>% group_by(focal) %>% summarise()
  selected_females <- as_vector(selected_females)
  iterator <- 1
  
  for (i in selected_females) { # do the following for every animal in the list
      print(paste("mcp for focal: ",i))
      follows_focal <- SUAQ_rangepoints_11all20_loc_females_10 %>% filter(focal%in%c(i)) %>% group_by(follow) %>% summarise()
      selectedfollows <- sample_n(follows_focal, round(nrow(follows_focal)*per)) #use when  subsetting by follow not but by number of GPS
      
      xy_selected_perc <- SUAQ_rangepoints_11all20_loc_females_10 %>% filter(follow %in% pull(selectedfollows,follow))# use when  subsetting by follow not but by number of GPS  
    if(nrow(xy_selected_perc)>5){
      #xy_selected <- SUAQ_rangepoints_11all20_loc_females_10 %>% filter(focal%in%c(i)) # use when not subsetting by follow but by number of GPS
      xy_selected <- xy_selected_perc %>% filter(focal%in%c(i)) # use when  subsetting by follow not but by number of GPS
      n_follows <- xy_selected %>% group_by(follow) %>% summarise() %>% nrow()
      #xy_selected<- sample_n(xy_selected, round(nrow(xy_selected)*per)) %>% dplyr::select(E,N) # use when not subsetting by follow but by number of GPS
      xy_selected<- xy_selected %>% dplyr::select(E,N) # use when  subsetting by follow not but by number of GPS
      n_gps <- xy_selected %>% nrow()
      coordinates(xy_selected) <- c("E","N")
      proj4string(xy_selected) <- CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs" )
      mcp99 <- data.frame(
              focal = i,
              area = mcp.area(xy_selected, percent = 99,unout = "km2"),
              hrpercentage ="99%",
              n_gps = n_gps,
              n_follows=n_follows,
              percentagedate = per
            )
      mcp95 <- data.frame(
              focal = i,
              area = mcp.area(xy_selected, percent = 95,unout = "km2"),
              hrpercentage ="95%",
              n_gps = n_gps,
              n_follows=n_follows,
              percentagedate = per
            )
      mcp50 <- data.frame(
              focal = i,
              area = mcp.area(xy_selected, percent = 50,unout = "km2"),
              hrpercentage ="50%",
              n_gps = n_gps,
              n_follows=n_follows,
              percentagedate = per
            )
      mcp_list_bootstrap <- mcp_list_bootstrap %>% rbind(mcp99) %>% rbind(mcp95) %>% rbind(mcp50)
      }
      
  }
}

mcp_list_bootstrap_temp <- mcp_list_bootstrap %>% group_by(focal,n_gps) %>% summarise() %>% arrange(desc(n_gps)) %>% ungroup()
mcp_list_bootstrap_temp<- mcp_list_bootstrap_temp%>%  group_by(focal) %>%
  top_n(n = 1)%>% rename(n_gps_tot=n_gps)
mcp_list_bootstrap <- mcp_list_bootstrap  %>% 
  left_join(mcp_list_bootstrap_temp, by=c("focal"="focal")) %>% 
  mutate(relativeamount=n_gps/n_gps_tot)
colnames(mcp_list_bootstrap)[colnames(mcp_list_bootstrap) == 'a'] <- 'area'

st_write(mcp_list_bootstrap, dsn = paste(
  paste(
    imdir,
    "mcp_list_bootstrap_percfollow",
    sep = ""
  ),
  "csv",
  sep = "."
))

```

## KDE

```{r KDE - HR sizes with bootstrap sampling amount per follow,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
#bandwiths <- read_csv(paste0("data/Processed_data/",str_remove_all(Sys.Date(), "-"),"_KDE_bandwiths.csv"))

dir.create(paste(
    "output/Homeranges/KDE/bootstrap/sampling/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/KDE/bootstrap/sampling/",format(Sys.Date(), "%Y%m%d"), "/", sep="")


### KDE-stability:
kde95_bootstrap_long <- data_frame()
kde50_bootstrap_long <- data_frame()

for(iter in c(1:20)){
  print(iter)
amountofdata <- seq(0.5,10,by=0.5)/10
kde95_bootstrap <- data.frame(focal=as_vector(selected_females),
                 HSCV_area_5=vector(mode="numeric", length=10),             
                 HSCV_area_10=vector(mode="numeric", length=10),
                 HSCV_area_15=vector(mode="numeric", length=10),
                 HSCV_area_20=vector(mode="numeric", length=10),
                 HSCV_area_25=vector(mode="numeric", length=10),
                 HSCV_area_30=vector(mode="numeric", length=10),
                 HSCV_area_35=vector(mode="numeric", length=10),
                 HSCV_area_40=vector(mode="numeric", length=10),
                 HSCV_area_45=vector(mode="numeric", length=10),
                 HSCV_area_50=vector(mode="numeric", length=10),
                 HSCV_area_55=vector(mode="numeric", length=10),
                 HSCV_area_60=vector(mode="numeric", length=10),
                 HSCV_area_65=vector(mode="numeric", length=10),
                 HSCV_area_70=vector(mode="numeric", length=10),
                 HSCV_area_75=vector(mode="numeric", length=10),
                 HSCV_area_80=vector(mode="numeric", length=10),
                 HSCV_area_85=vector(mode="numeric", length=10),
                 HSCV_area_90=vector(mode="numeric", length=10),
                 HSCV_area_95=vector(mode="numeric", length=10),
                 HSCV_area_100=vector(mode="numeric", length=10),
                 stringsAsFactors=FALSE)
kde50_bootstrap <- data.frame(focal=as_vector(selected_females),
                 HSCV_area_5=vector(mode="numeric", length=10),             
                 HSCV_area_10=vector(mode="numeric", length=10),
                 HSCV_area_15=vector(mode="numeric", length=10),
                 HSCV_area_20=vector(mode="numeric", length=10),
                 HSCV_area_25=vector(mode="numeric", length=10),
                 HSCV_area_30=vector(mode="numeric", length=10),
                 HSCV_area_35=vector(mode="numeric", length=10),
                 HSCV_area_40=vector(mode="numeric", length=10),
                 HSCV_area_45=vector(mode="numeric", length=10),
                 HSCV_area_50=vector(mode="numeric", length=10),
                 HSCV_area_55=vector(mode="numeric", length=10),
                 HSCV_area_60=vector(mode="numeric", length=10),
                 HSCV_area_65=vector(mode="numeric", length=10),
                 HSCV_area_70=vector(mode="numeric", length=10),
                 HSCV_area_75=vector(mode="numeric", length=10),
                 HSCV_area_80=vector(mode="numeric", length=10),
                 HSCV_area_85=vector(mode="numeric", length=10),
                 HSCV_area_90=vector(mode="numeric", length=10),
                 HSCV_area_95=vector(mode="numeric", length=10),
                 HSCV_area_100=vector(mode="numeric", length=10),
                 stringsAsFactors=FALSE)


for(per in amountofdata){
  iterator <- 1
for (i in selected_females){ # compute KDE home range for every individual

  #xy_selected <- SUAQ_rangepoints_11all20_loc_females_10 %>% filter(focal%in%c(i)) %>% dplyr::select(E,N)
  #xy_selected<- sample_n(xy_selected, round(nrow(xy_selected)*per))
  follows <- SUAQ_rangepoints_11all20_loc_females_10 %>% filter(focal%in%c(i)) %>% group_by(follow) %>% summarise()
  selectedfollows <- sample_n(follows,round(nrow(follows)*per))
  xy_selected_perc <- SUAQ_rangepoints_11all20_loc_females_10 %>% filter(follow %in% pull(selectedfollows,follow))# use when  subsetting by follow not but by number of GPS
  #xy_selected <- SUAQ_rangepoints_11all20_loc_females_10 %>% filter(focal%in%c(i)) # use when not subsetting by follow but by number of GPS
  xy_selected <- xy_selected_perc %>% filter(focal%in%c(i)) %>% dplyr::select(E,N)
  
  colnames(xy_selected) <- c("x","y") #adjust column names
  
  resultList <- list(hr50=NA, hr95=NA, UD=NA)
  if(nrow(xy_selected)>5){
  xy_selected <- SpatialPoints(xy_selected,proj4string = CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " )) # Converts SpatialPointDataFrame to SpatialPoint (only x & y)


  resultList <- list()
  methListTitle <- list("SCV")
  methList <- list("HSCV")
  
  
  extVal <- 0.4 #0.3 How much bigger the UD should be calculated than the research are (minimum bounding box). The higher the more Computation
  gridVal <- 800 #700 How much cells or pixels should be considered for UD calculation. The higher the more Computation
  
  for (j in seq(1, length(methList))) { # compute one home range for each bandwidth method and individual
    if (j == 1) {
      UD <- (kernelUD(xy_selected, grid=gridVal, extent=3, h=as.numeric(bandwiths[iterator,"hscv"]))) 
    }
    else {
      print("Error")
    }
    hr95 <- getverticeshr(UD, percent=95,unin = c("m"),unout = c("km2"))
    hr50 <- getverticeshr(UD, percent=50,unin = c("m"),unout = c("km2"))
    
    ########## export results #########
    resultList <- list(hr50=hr50, hr95=hr95, UD=UD)
  }
  
    assign(methList[[j]], resultList) #resultList is renamed according to the ith element of methList
  }

  animRes <- list(HSCV=HSCV)
  assign(selected_females[[iterator]], animRes) # is renamed according to the ith element of animList
  #print(paste(selected_females[[iterator]], ": Calculation finished with Subset of ",as.character(100*per),"% of Points", sep=""))
  
  iterator <- iterator+1
}
  kde_list <- list(lisa=lisa,
      friska=friska,
      ellie=ellie,
      cissy=cissy,
      lilly=lilly,
      yulia=yulia,
      raffi=raffi,
      sarabi=sarabi,
      trident=trident,
      tiara=tiara)
  itera <- 1
for(n in as_vector(selected_females)){
  #print(n)
  try(kde50_bootstrap[itera,paste("HSCV_area","_",as.character(100*per),sep = "")] <-  kde_list[[n]]$HSCV$hr50$area,silent = TRUE)
  try(kde95_bootstrap[itera,paste("HSCV_area","_",as.character(100*per),sep = "")] <-  kde_list[[n]]$HSCV$hr95$area,silent = TRUE)
  itera <- itera+1

}
  }
colnames(kde95_bootstrap) <- c("focal",as.character(seq(0.5,10,0.5)*10))
kde95_bootstrap_long_iter<- gather(kde95_bootstrap,as.character(seq(0.5,10,0.5)*10),key="subset %",value = "HR [km2]")
kde95_bootstrap_long_iter <- kde95_bootstrap_long_iter %>% mutate(`subset %`=as.numeric(`subset %`))
kde95_bootstrap_long_iter <- kde95_bootstrap_long_iter %>% mutate(iteration=iter)
kde95_bootstrap_long <- kde95_bootstrap_long %>% rbind(kde95_bootstrap_long_iter)

colnames(kde50_bootstrap) <- c("focal",as.character(seq(0.5,10,0.5)*10))
kde50_bootstrap_long_iter<- gather(kde50_bootstrap,as.character(seq(0.5,10,0.5)*10),key="subset %",value = "HR [km2]")
kde50_bootstrap_long_iter <- kde50_bootstrap_long_iter %>% mutate(`subset %`=as.numeric(`subset %`))
kde50_bootstrap_long_iter <- kde50_bootstrap_long_iter %>% mutate(iteration=iter)
kde50_bootstrap_long <- kde50_bootstrap_long %>% rbind(kde50_bootstrap_long_iter)
}




# colnames(kde95_bootstrap) <- c("focal",as.character(seq(0.5,10,0.5)*10))
# kde95_bootstrap_long<- gather(kde95_bootstrap,as.character(seq(0.5,10,0.5)*10),key="subset %",value = "HR [km2]")
# kde95_bootstrap_long <- kde95_bootstrap_long %>% mutate(`subset %`=as.numeric(`subset %`))
# kde95_bootstrap_long <- kde95_bootstrap_long %>% mutate(iteration=1)
# 
# colnames(kde50_bootstrap) <- c("focal",as.character(seq(0.5,10,0.5)*10))
# kde50_bootstrap_long<- gather(kde50_bootstrap,as.character(seq(0.5,10,0.5)*10),key="subset %",value = "HR [km2]")
# kde50_bootstrap_long <- kde50_bootstrap_long %>% mutate(`subset %`=as.numeric(`subset %`))
# kde50_bootstrap_long <- kde50_bootstrap_long %>% mutate(iteration=1)
# 
# 
# 
# kde50_bootstrap_long %>%  ggplot(aes(`subset %`,`HR [km2]`,colour=focal)) + geom_line()
# rownames(kde) <- c(1:10)
# kde95_bootstrap_long %>%  ggplot(aes(`subset %`,`HR [km2]`,colour=focal)) + geom_point(size=0.3)+geom_jitter(size=0.3)
# rownames(kde) <- c(1:10)
# 
kde50_bootstrap_long <- kde50_bootstrap_long %>% mutate(hrpercentage="50%")
kde95_bootstrap_long <- kde95_bootstrap_long %>% mutate(hrpercentage="95%")
kde_bootstrap_monthly <- kde50_bootstrap_long %>% rbind(kde95_bootstrap_long) 
kde_bootstrap_monthly <- kde_bootstrap_monthly %>% mutate(algorithm="HSCV")
st_write(kde_bootstrap_monthly, dsn = paste(
  paste(imdir,
    "kde_bootstrap_monthly_perfollow_HSCV_iterated",
    sep = ""
  ),
  "csv",
  sep = "."
))

```

```{r KDE - HR sizes with bootstrap temporal amount,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# createa directory for kde periods calculation (named by the current date)
# Split the data into 4 sampling periods. Calculate the respective HR.
monthyear_list <- split(SUAQ_rangepoints_11all20_loc_females_10, f = SUAQ_rangepoints_11all20_loc_females_10$monthYearDate)

dir.create(paste(
    "output/Homeranges/KDE/bootstrap/sampling/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/KDE/bootstrap/sampling/",format(Sys.Date(), "%Y%m%d"), "/", sep="")

kde_results <- data.frame() # results
for (samplinginterval in c(1:length(monthyear_list))){
print(paste("kdes for month: ",samplinginterval))
##### Determine the smoothing parameters
selected_females <- data.frame()
for(l in c(1:samplinginterval)){selected_females <-selected_females %>% rbind(monthyear_list[[l]])}
selected_females <- selected_females%>% group_by(focal) %>% summarise()
selected_females <- as_vector(selected_females)

bandwiths <-  data.frame(focal=as_vector(selected_females),
                 hpi=vector(mode="numeric", length=length(selected_females)),hbcv=vector(mode="numeric", length=length(selected_females)),hscv=vector(mode="numeric", length=length(selected_females)),
                 stringsAsFactors=FALSE)
iterator <- 1
for (i in selected_females){
  print(paste("kdes for focal: ",i))
  xy_selected <- data.frame()
  for(l in c(1:samplinginterval)){xy_selected <-xy_selected %>% rbind(monthyear_list[[l]])}
  xy_selected <- SUAQ_rangepoints_11all20_loc_females_10 %>% filter(focal%in%c(i)) %>% dplyr::select(E,N)
  colnames(xy_selected) <- c("x","y") #adjust column names
  hpi <- sqrt(prod(sqrt(diag(Hpi.diag(xy_selected[,1:2], nstage=2))))) # using diagonal bandwith not full bandwith? why?
  hbcv <- sqrt(prod(sqrt(diag(Hbcv.diag(xy_selected[,1:2], whichbcv=1)))))
  hscv <- sqrt(prod(sqrt(diag(Hscv.diag(xy_selected[,1:2], nstage=2)))))
  bandwiths[iterator,"focal"] <- i
  bandwiths[iterator,"hpi"] <- as.numeric(hpi)
  bandwiths[iterator,"hbcv"] <- as.numeric(hbcv)
  bandwiths[iterator,"hscv"] <- as.numeric(hscv)

  iterator <- iterator+1
}
rownames(bandwiths) <- c(1:length(selected_females))

### KDE: Calculate UD, HR
iterator <- 1
results_focal <- data.frame()
for (i in selected_females){ # compute KDE home range for every individual
  xy_selected <- data.frame()
  for(l in c(1:samplinginterval)){xy_selected <-xy_selected %>% rbind(monthyear_list[[l]])}
  n_follows <- xy_selected %>% filter(focal%in%c(i)) %>% group_by(follow) %>% summarise() %>% nrow()
  xy_selected <- xy_selected %>% filter(focal%in%c(i)) %>% dplyr::select(E,N)
  n_gps <- xy_selected %>% nrow()
  
  colnames(xy_selected) <- c("x","y") #adjust column names
  resultList <- list()
  methListTitle <- list("REF", "PI", "BCV", "SCV")
  methList <- list("HREF", "HPI", "HBCV", "HSCV")
  
  xy_selected <- SpatialPoints(xy_selected,proj4string = CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " )) # Converts SpatialPointDataFrame to SpatialPoint (only x & y)
  
  extVal <- 15 #0.3 How much bigger the UD should be calculated than the research are (minimum bounding box). The higher the more Computation
  gridVal <- 700 #700 How much cells or pixels should be considered for UD calculation. The higher the more Computation

  for (j in seq(1, length(methList))) { # compute one home range for each bandwidth method and individual
    if (j == 1) {
      UD <- (kernelUD(xy_selected, grid=gridVal, extent=extVal, h="href"))
    }
    else if (j == 2) {
      UD <- (kernelUD(xy_selected, grid=gridVal, extent=extVal, h=bandwiths[iterator,"hpi"]))
    }
    else if (j == 3) {
      UD <- (kernelUD(xy_selected, grid=gridVal, extent=extVal, h=bandwiths[iterator,"hbcv"]))
    }
    else if (j == 4) {
      UD <- (kernelUD(xy_selected, grid=gridVal, extent=extVal, h=bandwiths[iterator,"hscv"])) 
    }
    else {
      print("Error")
    }
    hr99 <- getverticeshr(UD, percent=99,unin = c("m"),unout = c("km2"))
    hr95 <- getverticeshr(UD, percent=95,unin = c("m"),unout = c("km2"))
    hr50 <- getverticeshr(UD, percent=50,unin = c("m"),unout = c("km2"))
    hr99_sf <- st_as_sf(hr99)
    hr95_sf <- st_as_sf(hr95)
    hr50_sf <- st_as_sf(hr50)
    
    ########## plot results ##########

    png(paste(imdir, selected_females[[iterator]],"_",gsub(" ", "", names(monthyear_list)[samplinginterval], fixed = TRUE), "_KDE_VUD_", methList[[j]], ".png", sep=""), width=1800, height=1400, res=240, units="px")
    image(getvolumeUD(UD),xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1)))
    plot(hr50, lty=3, lwd=1.5, border="azure4", add=T,axes=F)
    plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
    plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
    plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
    plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 0.7), add=T, axes=F)
    plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 0.7),lwd=0.3, bg="darkred", add=T, axes=F)
    plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
    plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
    axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
    axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
    #text(xmin-500, (ymin+ymax)/2, "y [m]", adj=c(NA,-4), srt=90)
    title(paste(selected_females[[iterator]], ": KDE ", "(", methListTitle[[j]], ")", sep=""), line=-1.5)
    legend("topright", c("HR 50%", "HR 95%", "HR 100%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsety,legendoffsety))
    dev.off()
    
    results_selectedmethod <- data.frame(bandwithmethod=c(methList[[j]],methList[[j]],methList[[j]]),
            hrpercentage=c("50%","95%","99%"),
            area=c(hr50_sf$area,hr95_sf$area,hr99_sf$area),
            n_gps=c(n_gps,n_gps,n_gps),
            n_follows=c(n_follows,n_follows,n_follows))

    results_selectedfocal<- results_selectedmethod %>% mutate(focal=selected_females[[iterator]])
    
    results_focal <- rbind(results_focal,results_selectedfocal)
  }

  

  print(paste(selected_females[[iterator]], ": Calculation finished", sep=""))
  iterator <- iterator+1
}
results_focal <- results_focal %>% mutate(period=names(monthyear_list)[samplinginterval])
kde_results <- kde_results %>% rbind(results_focal)


}
st_write(kde_results, dsn = paste(
  paste(imdir,
    "kde_temporal_bootstrap_monthly",
    sep = ""
  ),
  "csv",
  sep = "."
))
system("say alle kernel distanzen berechnet für die verschiedenen Untersuchungsperioden")

```

```{r KDE - HR per-researchperiods and all - HR sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/KDE/periods/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/KDE/periods/",format(Sys.Date(), "%Y%m%d"), "/", sep="")

kde_results_perperiod <- data.frame() # results
kde_overlap_UD_period <- list() # only for tital research period activate filter above
indexitter <- 0

for (samplinginterval in c(1:length(period_list))){
print(paste("kdes for period: ",samplinginterval))
##### Determine the smoothing parameters
selected_females <- period_list[[samplinginterval]] %>% group_by(focal) %>% summarise()
selected_females <- as_vector(selected_females)

bandwiths <-  data.frame(focal=as_vector(selected_females),
                 hpi=vector(mode="numeric", length=length(selected_females)),hbcv=vector(mode="numeric", length=length(selected_females)),hscv=vector(mode="numeric", length=length(selected_females)),
                 stringsAsFactors=FALSE)
iterator <- 1

for (i in selected_females){
  print(paste("kdes for focal: ",i))
  xy_selected <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>% dplyr::select(E,N)
  colnames(xy_selected) <- c("x","y") #adjust column names
  hpi <- sqrt(prod(sqrt(diag(Hpi.diag(xy_selected[,1:2], nstage=2))))) # using diagonal bandwith not full bandwith? why?
  hbcv <- sqrt(prod(sqrt(diag(Hbcv.diag(xy_selected[,1:2], whichbcv=1)))))
  hscv <- sqrt(prod(sqrt(diag(Hscv.diag(xy_selected[,1:2], nstage=2)))))
  bandwiths[iterator,"focal"] <- i
  bandwiths[iterator,"hpi"] <- as.numeric(hpi)
  bandwiths[iterator,"hbcv"] <- as.numeric(hbcv)
  bandwiths[iterator,"hscv"] <- as.numeric(hscv)

  iterator <- iterator+1
}
rownames(bandwiths) <- c(1:length(selected_females))

### KDE: Calculate UD, HR
iterator <- 1
results_focal <- data.frame()
for (i in selected_females){ # compute KDE home range for every individual
  n_follows <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>% group_by(follow) %>% summarise() %>% nrow()
  xy_selected <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>% dplyr::select(E,N)
  n_gps <- xy_selected %>% nrow()
  
  colnames(xy_selected) <- c("x","y") #adjust column names
  resultList <- list()
  methListTitle <- list("REF", "PI", "BCV", "SCV")
  methList <- list("HREF", "HPI", "HBCV", "HSCV")
  xy_simple <- xy_selected
  xy_selected <- SpatialPoints(xy_selected,proj4string = CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " )) # Converts SpatialPointDataFrame to SpatialPoint (only x & y)
  
  extVal <- 15 #0.3 How much bigger the UD should be calculated than the research are (minimum bounding box). The higher the more Computation
  gridVal <- 2000 #700 How much cells or pixels should be considered for UD calculation. The higher the more Computation

  for (j in seq(1, length(methList))) { # compute one home range for each bandwidth method and individual
    if (j == 1) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extentfactor, h="href"))
    }
    else if (j == 2) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extentfactor, h=bandwiths[iterator,"hpi"]))
    }
    else if (j == 3) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extentfactor, h=bandwiths[iterator,"hbcv"]))
    }
    else if (j == 4) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extentfactor, h=bandwiths[iterator,"hscv"])) 
    }
    else {
      print("Error")
    }
    tryCatch(
            expr = {
              hr95 <- getverticeshr(UD, percent=95, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr95_sf <- st_as_sf(hr95)
            },
            error = function(e){ 
              hr95 <- NA
              hr95_sf <- NA
              message()
              message(paste(selected_females[[iterator]],methList[[j]],n_gps,n_follows,samplinginterval,sep = " : "))
            }
        )
      tryCatch(
            expr = {
              hr99 <- getverticeshr(UD, percent=99, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr99_sf <- st_as_sf(hr99)
            },
            error = function(e){ 
              hr99 <- NA
              hr99_sf <- NA
              message()
              message(paste(selected_females[[iterator]],methList[[j]],n_gps,n_follows,samplinginterval,sep = " : "))
            }
        )
      tryCatch(
            expr = {
              hr50 <- getverticeshr(UD, percent=50, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr50_sf <- st_as_sf(hr50)
            },
            error = function(e){ 
              hr50 <- NA
              hr50_sf <- NA
              message(paste(selected_females[[iterator]],methList[[j]],n_gps,n_follows,samplinginterval," getting hr percentage polygon didn't work",sep = " : "))
            }
        )
    
    ########## save UD ##########
    kde_overlap_UD_period[[1+indexitter]] <- list(selected_females[[iterator]],UD,"kde",methList[[j]],n_gps,n_follows,names(period_list)[samplinginterval])
    indexitter <- indexitter+1
    
    ########## Calculate AUC ###########
    udvol<- getvolumeUD(UD, standardize = FALSE)
    loc<-xy_simple[,c("x", "y")]
    
    coordinates(loc) = c("x", "y") # conversion of locations to format SpatialPointsDataFrame (necessary for count.cells)
    crs(loc) <- CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " )
    nlocrast<-count.points(loc,udvol); # counts the number of GPS points in each pixel of the grid using adehabitatMA package
    kerneldata <- udvol@data$n # vector containing volume contour(=predicted) values
    pointdata <- nlocrast@data$x
    pointdata <- ifelse(pointdata>=1,1,0) # vector containing location (=actual) values
    AUC <- colAUC(kerneldata, pointdata, plotROC=FALSE, alg=c("Wilcoxon","ROC"))
    AUC <- as.numeric(AUC[1,])
      
    # GRAPHS
    filename<-paste(imdir, selected_females[[iterator]],"_",gsub(" ", "", names(period_list)[samplinginterval], fixed = TRUE), "_KDE_UD_", methList[[j]], "_AUC.png", sep="")
    png(filename,height=20,width=30,units="cm",res=300)
    par(mar=c(7,7,2,2))
    nf<- graphics::layout(mat=matrix(c(1,1,2,1,1,3),nrow=2,ncol=3,byrow=T),respect=TRUE)

    # Plot AUC
    myPal <- colorRampPalette( c("red","orange","yellow") )
    udvoltmp<-udvol
    udvoltmp@data$n<- ifelse(udvoltmp@data$n>=99.9,NA,udvoltmp@data$n)
    udvoltmp<-raster(udvoltmp)
    image(udvoltmp,col=myPal(64),frame.plot=FALSE,cex.axis=1.5, cex.lab=2)
    points(xy_simple[,c("x","y")],pch=3,cex=0.2)
    title(main=paste("KDE",as.character(selected_females[[iterator]]),as.character(methList[[j]])," bandwith method)","\n AUC=",round(AUC,2), sep=" "),line=0,cex.main=1)
    # Colorbar
      
    ncolors<-64
    rangev <- (0:(ncolors - 1))/(ncolors - 1)
    rangebar <- matrix(rangev, nrow = 2, ncol = 64, byrow = TRUE)
    image(z = rangebar, axes = FALSE, col = myPal(64), frame.plot = TRUE)
    axis(side = 2, (0:5)/5, labels = c("0", "", "", "", "","100"))
    title(ylab=expression("Volume contours [%]"),line=2, cex.lab=2)
      
    # Graph AUC
    colAUC(kerneldata, pointdata, plotROC=TRUE, alg=c("Wilcoxon","ROC"))
      
    dev.off()
    
    
    ########## plot results #########
    png(paste(imdir, selected_females[[iterator]],"_",gsub(" ", "", names(period_list)[samplinginterval], fixed = TRUE), "_KDE_UD_", methList[[j]], ".png", sep=""), width=1800, height=1400, res=240, units="px")
    par(0,0,0,0)
    image(UD,xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1)))
    plot(hr50, lty=3, lwd=1.5, border="darkseagreen3", add=T,axes=F)
    plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
    plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
    plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
    plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 1), add=T, axes=F)
    plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 1),lwd=0.3, bg="darkred", add=T, axes=F)
    plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
    plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
    axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
    axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
    #text(xmin-550, (ymin+ymax)/2, "y [m]", adj=c(NA,-4), srt=90)
    title(paste(selected_females[[iterator]], ": KDE ", "(", methListTitle[[j]], ")", sep=""), line=-1.5)
    legend("topright", c("HR 50%", "HR 95%", "HR 99%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsetx,legendoffsety), border=NA,box.lwd=NA)
    dev.off()

    png(paste(imdir, selected_females[[iterator]],"_",gsub(" ", "", names(period_list)[samplinginterval], fixed = TRUE), "_KDE_VUD_", methList[[j]], ".png", sep=""), width=1800, height=1400, res=240, units="px")
    image(getvolumeUD(UD),xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1)))
    plot(hr50, lty=3, lwd=1.5, border="azure4", add=T,axes=F)
    plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
    plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
    plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
    plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 1), add=T, axes=F)
    plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 1),lwd=0.3, bg="darkred", add=T, axes=F)
    plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
    plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
    axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
    axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
    #text(xmin-500, (ymin+ymax)/2, "y [m]", adj=c(NA,-4), srt=90)
    title(paste(selected_females[[iterator]], ": KDE ", "(", methListTitle[[j]], ")", sep=""), line=-1.5)
    legend("topright", c("HR 50%", "HR 95%", "HR 99%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsetx,legendoffsety), border=NA,box.lwd=NA)
    dev.off()
    
    results_selectedmethod <- data.frame(bandwithmethod=c(methList[[j]],methList[[j]],methList[[j]]),
            hrpercentage=c("50%","95%","99%"),
            area=c(hr50_sf$area,hr95_sf$area,hr99_sf$area),
            n_gps=c(n_gps,n_gps,n_gps),
            n_follows=c(n_follows,n_follows,n_follows),
            geometry=c(hr50_sf$geometry,hr95_sf$geometry,hr99_sf$geometry),
            AUC=AUC)

    results_selectedfocal<- results_selectedmethod %>% mutate(focal=selected_females[[iterator]])
    
    results_focal <- rbind(results_focal,results_selectedfocal)
  }

  

  print(paste(selected_females[[iterator]], ": Calculation finished", sep=""))
  iterator <- iterator+1
}
results_focal <- results_focal %>% mutate(period=names(period_list)[samplinginterval])
kde_results_perperiod <- kde_results_perperiod %>% rbind(results_focal)


}
st_write(kde_results_perperiod, dsn = paste(
  paste(imdir,
    "kde_values_allperiods",
    sep = ""
  ),
  "shp",
  sep = "."
))
system("say alle kernel distanzen berechnet für die verschiedenen Untersuchungsperioden")


```

```{r KDE - HR per-year - HR sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/KDE/years/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/KDE/years/",format(Sys.Date(), "%Y%m%d"), "/", sep="")

kde_results_perperyear <- data.frame() # results
kde_overlap_UD_year <- list() # only for tital research period activate filter above
indexitter <- 0
for (samplinginterval in c(1:length(year_list))){
print(paste("kdes for period: ",samplinginterval))
##### Determine the smoothing parameters
selected_females <- year_list[[samplinginterval]] %>% group_by(focal) %>% summarise()
selected_females <- as_vector(selected_females)

bandwiths <-  data.frame(focal=as_vector(selected_females),
                 hpi=vector(mode="numeric", length=length(selected_females)),hbcv=vector(mode="numeric", length=length(selected_females)),hscv=vector(mode="numeric", length=length(selected_females)),
                 stringsAsFactors=FALSE)
iterator <- 1
for (i in selected_females){
  print(paste("kdes for focal: ",i))
  xy_selected <- year_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>% dplyr::select(E,N)
  colnames(xy_selected) <- c("x","y") #adjust column names
  hpi <- sqrt(prod(sqrt(diag(Hpi.diag(xy_selected[,1:2], nstage=2))))) # using diagonal bandwith not full bandwith? why?
  hbcv <- sqrt(prod(sqrt(diag(Hbcv.diag(xy_selected[,1:2], whichbcv=1)))))
  hscv <- sqrt(prod(sqrt(diag(Hscv.diag(xy_selected[,1:2], nstage=2)))))
  bandwiths[iterator,"focal"] <- i
  bandwiths[iterator,"hpi"] <- as.numeric(hpi)
  bandwiths[iterator,"hbcv"] <- as.numeric(hbcv)
  bandwiths[iterator,"hscv"] <- as.numeric(hscv)

  iterator <- iterator+1
}
rownames(bandwiths) <- c(1:length(selected_females))

### KDE: Calculate UD, HR
iterator <- 1

results_focal <- data.frame()
for (i in selected_females){ # compute KDE home range for every individual
  n_follows <- year_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>% group_by(follow) %>% summarise() %>% nrow()
  xy_selected <- year_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>% dplyr::select(E,N)
  n_gps <- xy_selected %>% nrow()
  
  colnames(xy_selected) <- c("x","y") #adjust column names
  resultList <- list()
  methListTitle <- list("REF", "PI", "BCV", "SCV")
  methList <- list("HREF", "HPI", "HBCV", "HSCV")
  
  xy_selected <- SpatialPoints(xy_selected,proj4string = CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " )) # Converts SpatialPointDataFrame to SpatialPoint (only x & y)
  
  extVal <- 15 #0.3 How much bigger the UD should be calculated than the research are (minimum bounding box). The higher the more Computation
  gridVal <- 2000 #700 How much cells or pixels should be considered for UD calculation. The higher the more Computation

  for (j in seq(1, length(methList))) { # compute one home range for each bandwidth method and individual
    if (j == 1) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extentfactor, h="href"))
    }
    else if (j == 2) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extentfactor, h=bandwiths[iterator,"hpi"]))
    }
    else if (j == 3) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extentfactor, h=bandwiths[iterator,"hbcv"]))
    }
    else if (j == 4) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extentfactor, h=bandwiths[iterator,"hscv"])) 
    }
    else {
      print("Error")
    }
    tryCatch(
            expr = {
              hr95 <- getverticeshr(UD, percent=95, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr95_sf <- st_as_sf(hr95)
            },
            error = function(e){ 
              hr95 <- NA
              hr95_sf <- NA
              message()
              message(paste(selected_females[[iterator]],methList[[j]],n_gps,n_follows,samplinginterval,sep = " : "))
            }
        )
      tryCatch(
            expr = {
              hr99 <- getverticeshr(UD, percent=99, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr99_sf <- st_as_sf(hr99)
            },
            error = function(e){ 
              hr99 <- NA
              hr99_sf <- NA
              message()
              message(paste(selected_females[[iterator]],methList[[j]],n_gps,n_follows,samplinginterval,sep = " : "))
            }
        )
      tryCatch(
            expr = {
              hr50 <- getverticeshr(UD, percent=50, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr50_sf <- st_as_sf(hr50)
            },
            error = function(e){ 
              hr50 <- NA
              hr50_sf <- NA
              message(paste(selected_females[[iterator]],methList[[j]],n_gps,n_follows,samplinginterval," getting hr percentage polygon didn't work",sep = " : "))
            }
        )
    
    ########## save UD ##########
    kde_overlap_UD_year[[1+indexitter]] <- list(selected_females[[iterator]],UD,"kde",methList[[j]],n_gps,n_follows,names(year_list)[samplinginterval])
    indexitter <- indexitter+1
    
    ########## plot results #########
    png(paste(imdir, selected_females[[iterator]],"_",gsub(" ", "", names(year_list)[samplinginterval], fixed = TRUE), "_KDE_UD_", methList[[j]], ".png", sep=""), width=1800, height=1400, res=240, units="px")
    par(0,0,0,0)
    image(UD,xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1))) 
    plot(hr50, lty=3, lwd=1.5, border="darkseagreen3", add=T,axes=F)
    plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
    plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
    plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
    plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 1), add=T, axes=F)
    plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 1),lwd=0.3, bg="darkred", add=T, axes=F)
    plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
    plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
    axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
    axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
    #text(xmin-550, (ymin+ymax)/2, "y [m]", adj=c(NA,-4), srt=90)
    title(paste(selected_females[[iterator]], ": KDE ", "(", methListTitle[[j]], ")", sep=""), line=-1.5)
    legend("topright", c("HR 50%", "HR 95%", "HR 99%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsetx,legendoffsety), border=NA,box.lwd=NA)
    dev.off()

    png(paste(imdir, selected_females[[iterator]],"_",gsub(" ", "", names(year_list)[samplinginterval], fixed = TRUE), "_KDE_VUD_", methList[[j]], ".png", sep=""), width=1800, height=1400, res=240, units="px")
    image(getvolumeUD(UD), xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1)))
    plot(hr50, lty=3, lwd=1.5, border="azure4", add=T,axes=F)
    plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
    plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
    plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
    plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 1), add=T, axes=F)
    plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 1),lwd=0.3, bg="darkred", add=T, axes=F)
    plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
    plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
    axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
    axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
    #text(xmin-500, (ymin+ymax)/2, "y [m]", adj=c(NA,-4), srt=90)
    title(paste(selected_females[[iterator]], ": KDE ", "(", methListTitle[[j]], ")", sep=""), line=-1.5)
    legend("topright", c("HR 50%", "HR 95%", "HR 99%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsetx,legendoffsety), border=NA,box.lwd=NA)
    dev.off()
    
    results_selectedmethod <- data.frame(bandwithmethod=c(methList[[j]],methList[[j]],methList[[j]]),
            hrpercentage=c("50%","95%","99%"),
            area=c(hr50_sf$area,hr95_sf$area,hr99_sf$area),
            n_gps=c(n_gps,n_gps,n_gps),
            n_follows=c(n_follows,n_follows,n_follows),
            geometry=c(hr50_sf$geometry,hr95_sf$geometry,hr99_sf$geometry))

    results_selectedfocal<- results_selectedmethod %>% mutate(focal=selected_females[[iterator]])
    
    results_focal <- rbind(results_focal,results_selectedfocal)
  }

  

  print(paste(selected_females[[iterator]], ": Calculation finished", sep=""))
  iterator <- iterator+1
}
results_focal <- results_focal %>% mutate(period=names(year_list)[samplinginterval])
kde_results_perperyear <- kde_results_perperyear %>% rbind(results_focal)


}
st_write(kde_results_perperyear, dsn = paste(
  paste(
    "output/Homeranges/KDE/years/",
    format(Sys.Date(), "%Y%m%d"),"/",
    "kde_values_years",
    sep = ""
  ),
  "shp",
  sep = "."
))
system("say alle kernel distanzen berechnet für jedes Jahr")


```

## LOCOH
```{r TESTING LOCOH - HR per-researchperiods and all - HR sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/LOCOH/periods/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/LOCOH/periods/",format(Sys.Date(), "%Y%m%d"), "/", sep="")

locoh_list <- data.frame() # results
for (samplinginterval in c(1:length(period_list))){
  print(paste("LOCOH for period: ",samplinginterval))
  ##### Determine the smoothing parameters
  selected_females <- period_list[[samplinginterval]] %>% group_by(focal) %>% summarise()
  selected_females <- as_vector(selected_females)
  
  iterator <- 1
  for (i in selected_females) { # do the following for every animal in the list
    print(paste("LOCOH for focal: ",i))
    n_follows <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
        group_by(follow) %>% summarise() %>% nrow()

    xy_selected <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
      dplyr::select(E,N,manualDatetime,infantname,followtype,Activity,SUAQ_followlog.Observer1,SUAQ_orangutans.dominancecat,SUAQ_orangutans.matriline,SUAQ_weather.rainfall_ml_evening,SUAQ_fai.fai,ageFromDOB)
    xy_selected <- xy_selected[order(xy_selected$manualDatetime , decreasing = FALSE ),] 
    n_gps <- xy_selected %>% nrow()

    xy_only <- xy_selected %>%
      dplyr::select(E,N) %>% mutate(x=as.double(E),y=as.double(N)) %>% as.data.frame() %>% dplyr::select(-E,-N) # dataframe was a tibble --> caused troubles in the locoh package

    df.lxy <- xyt.lxy(xy=xy_only, dt=xy_selected$manualDatetime,anv=xy_selected[,4:12], id=i, proj4string=CRS("+init=epsg:23867")) # create xy-object. Duplicates are autom. removed
    # plot(df.lxy)
    hist(df.lxy) #distribution of locations by date, step length and SI -> some gaps, several SI
    # lxy.plot.freq(df.lxy, deltat.by.date=T) #sampling frequency over time -> several SI
    # lxy.plot.freq(df.lxy, cp=T) #find bursts of points that need to be thinned out, 2 sections because of two main SI
    
    # find bursts
    df.lxy <- lxy.thin.bursts(df.lxy, thresh=0.98) ## adjust threshold
    df.lxy <- lxy.ptsh.add(df.lxy)# find appropriate time parameter s. with rule from manual. Depending on RQ --> f.e. researching daily movement we want high s because we want two points near each other not as nearest neighbour because its seperated by a day.
    
    # # find s    
    # lxy.plot.pt2ctr(df.lxy) # proposes a s-value around 0.4
    # lxy.plot.sfinder(df.lxy, delta.t=3600*c(12,24,36,48,96,192)) # proposes a s-value around 0.15 # see how the time gaps are distributed compared to s selection. How much of timegap should be included in nearest neighbour
    # lxy.plot.mtdr(df.lxy, k=10)
    # lxy.plot.tspan(df.lxy, k=10) 
    
    ########################
    svalue <- 0.01      ###### s-VALUE SELECTION
    kselected <- 12    ## kmax-SELECTION
    aval <- 7000
    ########################
    
    df.lxy <- lxy.nn.add(df.lxy, s=svalue, k=kselected)
    df.lhs_12k <- lxy.lhs(df.lxy, k=kselected, s=svalue)
    df.lhs_12k <- lhs.iso.add(df.lhs_12k, iso.levels = c(0.25, 0.5, 0.65, 0.75, 0.85, 0.95)) # creates isopleths for each k-hullset, sorted by density
    

    
    # a method
    df.lxy <- lxy.nn.add(df.lxy, s=svalue, a=auto.a(nnn=12, ptp=0.98))
    df.lxy <- lxy.nn.add(df.lxy, s=svalue, a=12000)
    lhs_amixed <- lxy.lhs(df.lxy, s=svalue, a=4:12*1000, iso.add=T)
    
    for (l in seq(1:length(kmax_vec))) {
      start_time <- Sys.time()
      kmax <- kmax_vec[[l]]
      df.lxy <- lxy.nn.add(df.lxy, s=0.02, k=kmax)
      
      
      # revisits
      df.lhs_12k_revisits <- lhs.visit.add(df.lhs_12k, ivg=3600*18)
      summary(df.lhs_12k_revisits)
      plot(df.lhs_12k_revisits, hpp=T, hpp.classify="nsv", ivg=3600*18, col.ramp="rainbow") # number of visits
      plot(df.lhs_12k_revisits, hpp=T, hpp.classify="mnlv", col.ramp="rainbow") # duration of visit
      hsp <- lhs.plot.scatter(df.lhs_12k_revisits, x="nsv", y="mnlv", col="spiral", bg="black")
      plot(df.lhs_12k_revisits, hpp=T, hsp=hsp, hpp.classify="hsp")
      
      # Directional movement
      df.lhs_12k_directional <- lhs.ellipses.add(df.lhs_12k)
      df.lhs_12k_directional <- lhs.iso.add(df.lhs_12k_directional, sort.metric="ecc")
      plot(df.lhs_12k_directional, iso=T, iso.sort.metric="ecc")
      #lhs.save(df.lhs, dir=paste("~/_MyData/Masterarbeit Movement Analysis/Resultate/thesis/calculations/LCH/", animal, sep="")
      # plot(df.lhs, iso=T, record=T, ufipt=F) #Show results of the different k-/a-/r-values [pg up / pg dn]]
      # lhs.plot.isoarea(df.lhs, legend=0)
      # lhs.plot.isoear(df.lhs, legend=0)
      plot(df.lhs_12k_directional, iso=T, k=12, allpts=T, cex.allpts=0.3, col.allpts="gray30", ufipt=F)
      
      
      
      
      
      
      
      if(TRUE){# only execute when enough data xy_selected_toolessdata
      UD <- BRB(traj, D=vv, Tmax=tmax, Lmin=lmin, hmin=hmin, b=T, same4all=T, grid=gridVal, extent=extVal, filtershort=T, type="UD")
      
      hr95 <- getverticeshr(UD, percent=95, standardize=TRUE,unin = c("m"),unout = c("km2"))
      hr50 <- getverticeshr(UD, percent=50, standardize=TRUE,unin = c("m"),unout = c("km2"))
      hr99 <- getverticeshr(UD, percent=99, standardize=TRUE,unin = c("m"),unout = c("km2"))
      hr95_sf <- st_as_sf(hr95)
      hr50_sf <- st_as_sf(hr50)
      hr99_sf <- st_as_sf(hr99)
      
      par(0,0,0,0)
      step <- 200
      
      ########## plot results ##########
      hminTxt <- gsub(".", "_", as.character(hminFactor[[l]]), fixed=T)
      xmin_xmax_round_steps<- c(step*(ceiling(xmin/step)):(round(xmax/step)))
      xmin_xmax_round_steps <- xmin_xmax_round_steps[2:(length(xmin_xmax_round_steps)-2)] #manual adjustment of tick breaks how many does it need
      ymin_ymax_round_steps<- c(step*(ceiling(ymin/step)):(round(ymax/step)))
      ymin_ymax_round_steps <- ymin_ymax_round_steps[2:(length(ymin_ymax_round_steps)-1)] #manual adjustment of tick breaks how many does it need    
      
  
      
      png(paste(imdir,i, "_BRB_UD_", hminTxt,"_",names(period_list)[samplinginterval], ".png", sep=""), width=1800, height=1400, res=240, units="px")
      image(UD, xlab="x [m]",ylab="y [m]",xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1))) 
      plot(hr50, lty=3, lwd=1.5, border="darkseagreen3", add=T,axes=F)
      plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
      plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
      plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 0.7), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 0.7),lwd=0.3, bg="darkred", add=T, axes=F)
      plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
      plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
      axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
      axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
      title(paste(i, ": BRB (", hminFactor[[l]], "*hmin)", sep=""), line=-1.5)
      legend("topright", c("HR 50%", "HR 95%", "HR 100%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsety,legendoffsety))
      dev.off()
      
      png(paste(imdir,i, "_BRB_VUD_", hminTxt,"_",names(period_list)[samplinginterval], ".png", sep=""), width=1800, height=1400, res=240, units="px")
      image(getvolumeUD(UD), xlab="x [m]",ylab="y [m]",xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1))) 
      plot(hr50, lty=3, lwd=1.5, border="darkseagreen3", add=T,axes=F)
      plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
      plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
      plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 0.7), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 0.7),lwd=0.3, bg="darkred", add=T, axes=F)
      plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
      plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
      axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
      axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
      title(paste(i, ": BRB (", hminFactor[[l]], "*hmin)", sep=""), line=-1.5)
      legend("topright", c("HR 50%", "HR 95%", "HR 100%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsety,legendoffsety))
      dev.off()}
      
      end_time <- Sys.time()
      duration <- end_time-start_time
      
      ########## export results ############
      if(xy_selected_toolessdata) {
        resultList_50 <-
          data.frame(
            focal = i,
            homerange = hr50$area,
            hrpercentage ="50%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr50_sf$geometry
          )
        resultList_95 <-
          data.frame(
            focal = i,
            homerange = hr95$area,
            hrpercentage ="95%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr95_sf$geometry
          )
        resultList_99 <-
          data.frame(
            focal = i,
            homerange = hr99$area,
            hrpercentage ="99%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr99_sf$geometry
          )
      }
      if (!xy_selected_toolessdata) {
                resultList_50 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="50%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
        resultList_95 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="95%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
        resultList_99 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="99%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
      }
      locoh_list <- locoh_list %>% rbind(resultList_50,resultList_95,resultList_99)
      
      print(paste(hminTxt, ": Calculation finished", sep=""))
    }
  }
}

st_write(locoh_list, dsn = paste(
  paste(
    imdir,
    "locoh_values_allperiods",
    sep = ""
  ),
  "shp",
  sep = "."
))
system("say alle locoh verteilungen berechnet für die verschiedenen Untersuchungsperioden")

lhs.plot.isoarea(cissy.lhs.amixed)
lhs.plot.isoear(cissy.lhs.amixed)
toni.lhs.k15 <- lhs.visit.add(toni.lhs.k15, ivg=3600*12)

```

## BRB
```{r BRB - HR sizes with bootstrap sampling - HR sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/BRB/bootstrap/sampling/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/BRB/bootstrap/sampling/",format(Sys.Date(), "%Y%m%d"), "/", sep="")

#### retrieve sampling intervals
mainSI <- rep(30,length(selected_females))

#### amount of data
amountofdata <- seq(0.5,10,by=0.5)/10
brb_list_bootstrap <- data.frame() # results
follows <- SUAQ_rangepoints_11all20_loc_females_10 %>% group_by(follow) %>% summarise()

for(per in amountofdata){
  print(paste0("Datenmenge: ",per))
  iterator <- 1
  for (i in selected_females) { # do the following for every animal in the list
      xy_selected <- SUAQ_rangepoints_11all20_loc_females_10 %>% filter(focal%in%c(i))
      follows_focal <- xy_selected %>% group_by(follow) %>% summarise()

      selectedfollows<- sample_n(follows_focal, round(nrow(follows_focal)*per))
      #### Selected animals as list/vector
      xy_selected <- xy_selected %>% filter(follow %in% pull(selectedfollows,follow)) 
      #xy_selected_perc <- sample_n(SUAQ_rangepoints_11all20_loc_females_10,        round(nrow(SUAQ_rangepoints_11all20_loc_females_10)*per)) # for using the percentage of follows instead of points use the two lines above

      
  
      print(paste("brb for focal: ",i))
      n_follows <- xy_selected %>%
          group_by(follow) %>% summarise() %>% nrow()
  
      xy_selected <- xy_selected %>% 
        dplyr::select(E,N,timelag_lead,manualDatetime)
      n_gps <- xy_selected %>% nrow()
  
      colnames(xy_selected) <- c("x","y","timelag_lead","timestamp") #adjust column names
      xy_selected <- xy_selected %>%  mutate(timelag_lead = round(timelag_lead,digits=0))
    
      # only select points where timegaps are between 20-40min --> To do pretty bad selection we would need a function which selects points automatically by subsampling if mean timegap is too high or by interpolating if too small. But how much does it really affect the result of HR --> because we mainly compare HR sizes.
      #xy_selected <- xy_selected %>% filter((timelag_lead/60)>20) #select which SI to remove (xy_selected$timelag_lead/60 < (mainSI[[iterator]]-10))
      #xy_selected <- xy_selected %>% filter((timelag_lead/60)<40)
      #xy_selected <- xy_selected[!(is.na(xy_selected$y)),]
      
      # check if enough gps points are still here otherwise make NA's
      xy_selected_toolessdata <- TRUE
      if(nrow(xy_selected)<20){xy_selected_toolessdata <- FALSE}
    
      for (l in seq(1:length(hminFactor))) {
        if(xy_selected_toolessdata) {
        # samplingI <- vector()
        # samplingI <- xy_selected$timelag_lead/60
        # samplingI <- samplingI[2:length(samplingI)] # First value of timelag_lead is NA
        # plot(table(samplingI), type="h", xlim=c(20,40),col=4, ylab="frequency", xlab="sampling interval [min]")
        
        xy_selected <- xy_selected[order(xy_selected$timestamp , decreasing = FALSE ),] 
        moveObj <- move(x=xy_selected$x, y=xy_selected$y, time=xy_selected$timestamp, proj=CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " ),animal=i)
        ##########################################################################################
        relUn <- 12 # relocation uncertainty [m]
        ##########################################################################################
        velocity <- unname(quantile(speed(moveObj), 0.99)) * 60 # unit: [m/min]
        hmin <- relUn + (0.5 * velocity * 30) # meters, smoothing
        iterator <- iterator+1
        
        
        fulldata_forfemale<- SUAQ_rangepoints_11all20_loc_females_10[SUAQ_rangepoints_11all20_loc_females_10$focal==i,c("E", "N","manualDatetime")]
        colnames(fulldata_forfemale) <- c("x","y","timestamp")
        trajfull <- as.ltraj(xy=fulldata_forfemale, date=fulldata_forfemale$timestamp, id=i)
        traj <- as.ltraj(xy=xy_selected[,c("x", "y")], date=xy_selected$timestamp, id=i)
  
        ##########################################################################################
        tmax <- 70*60 # seconds, maximum time span for a segment
        lmin <- 12 # meters, minimal distance of a segment in order to count as movement
        tau <- 1*60 #seconds, approx. duration of one interpolated interval -> defines the number of intervals per step 
        extVal <- 15
        gridVal <- 2000
        hminRef <- 102 # computed through "BRB_leo_hmin computation.R"
        hminFactor <- c(0.8)
        ##########################################################################################
      
        vv <- BRB.D(trajfull, Tmax=tmax, Lmin=lmin) #estimate the diffusion coefficient
        
          
        start_time <- Sys.time()
        hmin <- hminFactor[[l]]*hminRef
     
        UD <- BRB(traj, D=vv, Tmax=tmax, Lmin=lmin, hmin=hmin, b=T,  grid=grid, extent=extentfactor, type="UD")
        plot(UD)
        hr95 <- getverticeshr(UD, percent=95, standardize=TRUE,unin = c("m"),unout = c("km2"))
        hr50 <- getverticeshr(UD, percent=50, standardize=TRUE,unin = c("m"),unout = c("km2"))
        hr99 <- getverticeshr(UD, percent=99, standardize=TRUE,unin = c("m"),unout = c("km2"))
        hr95_sf <- st_as_sf(hr95)
        hr50_sf <- st_as_sf(hr50)
        hr99_sf <- st_as_sf(hr99)
        
        par(0,0,0,0)
        step <- 200
        
        ########## plot results ##########
        hminTxt <- gsub(".", "_", as.character(hminFactor[[l]]), fixed=T)

        
        end_time <- Sys.time()
        duration <- end_time-start_time
        
        ########## export results ############

          resultList_50 <-
            data.frame(
              focal = i,
              homerange = hr50$area,
              hrpercentage ="50%",
              n_gps = n_gps,
              n_follows = n_follows,
              Velocity_percentile99 = velocity,
              GPSuncertainty = relUn,
              hmin = hmin,
              tmax = tmax,
              lmin = lmin,
              tau = tau,
              hminfac = hminFactor[[l]],
              hminRef = hminRef,
              processingtime = duration,
              percentagedata=per
            )
          resultList_95 <-
            data.frame(
              focal = i,
              homerange = hr95$area,
              hrpercentage ="95%",
              n_gps = n_gps,
              n_follows = n_follows,
              Velocity_percentile99 = velocity,
              GPSuncertainty = relUn,
              hmin = hmin,
              tmax = tmax,
              lmin = lmin,
              tau = tau,
              hminfac = hminFactor[[l]],
              hminRef = hminRef,
              processingtime = duration,
              percentagedata=per
            )
          resultList_99 <-
            data.frame(
              focal = i,
              homerange = hr99$area,
              hrpercentage ="99%",
              n_gps = n_gps,
              n_follows = n_follows,
              Velocity_percentile99 = velocity,
              GPSuncertainty = relUn,
              hmin = hmin,
              tmax = tmax,
              lmin = lmin,
              tau = tau,
              hminfac = hminFactor[[l]],
              hminRef = hminRef,
              processingtime = duration,
              percentagedata=per
            )
        }
        if (!xy_selected_toolessdata) {
                  resultList_50 <-
            data.frame(
              focal = i,
              homerange = NA,
              hrpercentage ="50%",
              n_gps = n_gps,
              n_follows = n_follows,
              Velocity_percentile99 = velocity,
              GPSuncertainty = relUn,
              hmin = hmin,
              tmax = tmax,
              lmin = lmin,
              tau = tau,
              hminfac = hminFactor[[l]],
              hminRef = hminRef,
              processingtime = duration,
              percentagedata=per
            )
          resultList_95 <-
            data.frame(
              focal = i,
              homerange = NA,
              hrpercentage ="95%",
              n_gps = n_gps,
              n_follows = n_follows,
              Velocity_percentile99 = velocity,
              GPSuncertainty = relUn,
              hmin = hmin,
              tmax = tmax,
              lmin = lmin,
              tau = tau,
              hminfac = hminFactor[[l]],
              hminRef = hminRef,
              processingtime = duration,
              percentagedata=per
            )
          resultList_99 <-
            data.frame(
              focal = i,
              homerange = NA,
              hrpercentage ="99%",
              n_gps = n_gps,
              n_follows = n_follows,
              Velocity_percentile99 = velocity,
              GPSuncertainty = relUn,
              hmin = hmin,
              tmax = tmax,
              lmin = lmin,
              tau = tau,
              hminfac = hminFactor[[l]],
              hminRef = hminRef,
              processingtime = duration,
              percentagedata=per
            )
        }
        brb_list_bootstrap <- brb_list_bootstrap %>% rbind(resultList_50,resultList_95,resultList_99)
        
        print(paste(hminTxt, ": Calculation finished", sep=""))
      
    }

  }
}
st_write(brb_list_bootstrap, dsn = paste(
  paste(
    imdir,
    "brb_list_bootstrap_perfollow",
    sep = ""
  ),
  "csv",
  sep = "."
))
system("say alle brown brücken für unterschiedliche samples berechnet")


```

```{r BRB - HR per-researchperiods and all - HR sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/BRB/periods/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/BRB/periods/",format(Sys.Date(), "%Y%m%d"), "/", sep="")

#### retrieve sampling intervals
mainSI <- rep(30,length(selected_females))
indexitter <- 0
brb_list <- data.frame() # results
brb_overlap_UD_period <- list() # only for tital research period activate filter above

for (samplinginterval in c(1:length(period_list))){
  print(paste("brb for period: ",samplinginterval))
  ##### Determine the smoothing parameters
  selected_females <- period_list[[samplinginterval]] %>% group_by(focal) %>% summarise()
  selected_females <- as_vector(selected_females)
  
  iterator <- 1
  for (i in selected_females) { # do the following for every animal in the list
    print(paste("brb for focal: ",i))
    n_follows <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
        group_by(follow) %>% summarise() %>% nrow()

    xy_selected <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
      dplyr::select(E,N,timelag_lead,manualDatetime)
    n_gps <- xy_selected %>% nrow()

    colnames(xy_selected) <- c("x","y","timelag_lead","timestamp") #adjust column names
    xy_selected <- xy_selected %>%  mutate(timelag_lead = round(timelag_lead,digits=0))
  
    # only select points where timegaps are between 20-40min --> To do pretty bad selection we would need a function which selects points automatically by subsampling if mean timegap is too high or by interpolating if too small. But how much does it really affect the result of HR --> because we mainly compare HR sizes.
    #xy_selected <- xy_selected %>% filter((timelag_lead/60)>20) #select which SI to remove (xy_selected$timelag_lead/60 < (mainSI[[iterator]]-10))
    #xy_selected <- xy_selected %>% filter((timelag_lead/60)<40)
    #xy_selected <- xy_selected[!(is.na(xy_selected$y)),]
    
    # check if enough gps points are still here otherwise make NA's
    xy_selected_toolessdata <- TRUE
    if(nrow(xy_selected)<30){xy_selected_toolessdata <- FALSE}
    
    # samplingI <- vector()
    # samplingI <- xy_selected$timelag_lead/60
    # samplingI <- samplingI[2:length(samplingI)] # First value of timelag_lead is NA
    # plot(table(samplingI), type="h", xlim=c(20,40),col=4, ylab="frequency", xlab="sampling interval [min]")
    
    xy_selected <- xy_selected[order(xy_selected$timestamp , decreasing = FALSE ),] 
    moveObj <- move(x=xy_selected$x, y=xy_selected$y, time=xy_selected$timestamp, proj=CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " ),animal=i)
    ##########################################################################################
    relUn <- 12 # relocation uncertainty [m]
    ##########################################################################################
    velocity <- unname(quantile(speed(moveObj), 0.99)) * 60 # unit: [m/min]
    velocity_selected <- 6
    hmin <- relUn + (0.5 * velocity_selected * 30) # meters, smoothing
    iterator <- iterator+1
    

    traj <- as.ltraj(xy=xy_selected[,c("x", "y")], date=xy_selected$timestamp, id=i)
  
    ##########################################################################################
    tmax <- 70*60 # seconds, maximum time span for a segment
    lmin <- 12 # meters, minimal distance of a segment in order to count as movement
    tau <- 1*60 #seconds, approx. duration of one interpolated interval -> defines the number of intervals per step 
    extVal <- 15
    gridVal <- 2000
    hminRef <- hmin # computed before
    hminFactor <- c(0.2,0.4,0.6, 0.8, 0.9,1.1,1.2,1.4)
    ##########################################################################################
  
    vv <- BRB.D(traj, Tmax=tmax, Lmin=lmin) #estimate the diffusion coefficient
    for (l in seq(1:length(hminFactor))) {
      start_time <- Sys.time()
      hmin <- hminFactor[[l]]*hminRef
      if(xy_selected_toolessdata){# only execute when enough data
      UD <- BRB(traj, D=vv, Tmax=tmax, Lmin=lmin, hmin=hmin, b=T,  grid=grid, extent=extentfactor, filtershort=T, type="UD")

      tryCatch(
            expr = {
              hr95 <- getverticeshr(UD, percent=95, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr95_sf <- st_as_sf(hr95)
            },
            error = function(e){ 
              hr95 <- NA
              hr95_sf <- NA
              message()
              message(paste(i,hminFactor[[l]],n_gps,n_follows,samplinginterval,sep = " : "))
            }
        )
      tryCatch(
            expr = {
              hr99 <- getverticeshr(UD, percent=99, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr99_sf <- st_as_sf(hr99)
            },
            error = function(e){ 
              hr99 <- NA
              hr99_sf <- NA
              message()
              message(paste(i,hminFactor[[l]],n_gps,n_follows,samplinginterval,sep = " : "))
            }
        )
      tryCatch(
            expr = {
              hr50 <- getverticeshr(UD, percent=50, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr50_sf <- st_as_sf(hr50)
            },
            error = function(e){ 
              hr50 <- NA
              hr50_sf <- NA
              message(paste(i,hminFactor[[l]],n_gps,n_follows,samplinginterval," getting hr percentage polygon didn't work",sep = " : "))
            }
        )

      
      ########## save UD ##########
      brb_overlap_UD_period[[1+indexitter]] <- list(i,UD,"brb",hminFactor[[l]],n_gps,n_follows,names(period_list)[samplinginterval])
      indexitter <- indexitter+1
      
      
      ########## Calculate AUC ###########
      hminTxt <- gsub(".", "_", as.character(hminFactor[[l]]), fixed=T)
      udvol<- getvolumeUD(UD, standardize = FALSE)
      loc<-xy_selected[,c("x", "y")]
      coordinates(loc) = c("x", "y") # conversion of locations to format SpatialPointsDataFrame (necessary for count.cells)

      nlocrast<-count.points(loc,udvol); # counts the number of GPS points in each pixel of the grid using adehabitatMA package
      kerneldata <- udvol@data$n # vector containing volume contour(=predicted) values
      pointdata <- nlocrast@data$x
      pointdata <- ifelse(pointdata>=1,1,0) # vector containing location (=actual) values
      AUC <- colAUC(kerneldata, pointdata, plotROC=FALSE, alg=c("Wilcoxon","ROC"))
      AUC <- as.numeric(AUC[1,])
      
      # GRAPHS
      filename<-paste(imdir,i, "_BRB_UD_", hminTxt,"_",names(period_list)[samplinginterval], "_AUC.png", sep="")
      png(filename,height=20,width=30,units="cm",res=300)
      par(mar=c(7,7,2,2))
      nf<- graphics::layout(mat=matrix(c(1,1,2,1,1,3),nrow=2,ncol=3,byrow=T),respect=TRUE)

      # Plot AUC
      myPal <- colorRampPalette( c("red","orange","yellow") )
      udvoltmp<-udvol
      udvoltmp@data$n<- ifelse(udvoltmp@data$n>=99.9,NA,udvoltmp@data$n)
      udvoltmp<-raster(udvoltmp)
      image(udvoltmp,col=myPal(64),frame.plot=FALSE,cex.axis=1.5, cex.lab=2)
      points(xy_selected[,c("x","y")],pch=3,cex=0.2)
      title(main=paste("BRB",as.character(i),"(",as.character(hminFactor[[l]]),"*hmin)","\n AUC=",round(AUC,2), sep=" "),line=0,cex.main=1)
      # Colorbar
      
      ncolors<-64
      rangev <- (0:(ncolors - 1))/(ncolors - 1)
      rangebar <- matrix(rangev, nrow = 2, ncol = 64, byrow = TRUE)
      image(z = rangebar, axes = FALSE, col = myPal(64), frame.plot = TRUE)
      axis(side = 2, (0:5)/5, labels = c("0", "", "", "", "","100"))
      title(ylab=expression("Volume contours [%]"),line=2, cex.lab=2)
      
      # Graph AUC
      colAUC(kerneldata, pointdata, plotROC=TRUE, alg=c("Wilcoxon","ROC"))
      
      dev.off()
      
      
      ########## plot results ##########
      hminTxt <- gsub(".", "_", as.character(hminFactor[[l]]), fixed=T)
      
      png(paste(imdir,i, "_BRB_UD_", hminTxt,"_",names(period_list)[samplinginterval], ".png", sep=""), width=1800, height=1400, res=240, units="px")
      image(UD,xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1))) 
      plot(hr50, lty=3, lwd=1.5, border="darkseagreen3", add=T,axes=F)
      plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
      plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
      plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 1),lwd=0.3, bg="darkred", add=T, axes=F)
      plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
      plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
      axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
      axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
      title(paste(i, ": BRB (", hminFactor[[l]], "*hmin)", sep=""), line=-1.5)
      legend("topright", c("HR 50%", "HR 95%", "HR 99%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsetx,legendoffsety), border=NA,box.lwd=NA)
      dev.off()
      
      png(paste(imdir,i, "_BRB_VUD_", hminTxt,"_",names(period_list)[samplinginterval], ".png", sep=""), width=1800, height=1400, res=240, units="px")
      image(getvolumeUD(UD),xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1))) 
      plot(hr50, lty=3, lwd=1.5, border="darkseagreen3", add=T,axes=F)
      plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
      plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
      plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 1),lwd=0.3, bg="darkred", add=T, axes=F)
      plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
      plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
      axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
      axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
      title(paste(i, ": BRB (", hminFactor[[l]], "*hmin)", sep=""), line=-1.5)
      legend("topright", c("HR 50%", "HR 95%", "HR 99%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsetx,legendoffsety), border=NA,box.lwd=NA)
      dev.off()}
      
      end_time <- Sys.time()
      duration <- end_time-start_time
      
      ########## export results ############
      if(xy_selected_toolessdata) {
        resultList_50 <-
          data.frame(
            focal = i,
            homerange = hr50$area,
            hrpercentage ="50%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr50_sf$geometry,
            AUC = AUC
          )
        resultList_95 <-
          data.frame(
            focal = i,
            homerange = hr95$area,
            hrpercentage ="95%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr95_sf$geometry,
            AUC = AUC
          )
        resultList_99 <-
          data.frame(
            focal = i,
            homerange = hr99$area,
            hrpercentage ="99%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr99_sf$geometry,
            AUC = AUC
          )
      }
      if (!xy_selected_toolessdata) {
                resultList_50 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="50%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA,
            AUC = NA
          )
        resultList_95 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="95%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA,
            AUC = NA
          )
        resultList_99 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="99%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA,
            AUC = NA
          )
      }
      brb_list <- brb_list %>% rbind(resultList_50,resultList_95,resultList_99)
      
      print(paste(hminTxt, ": Calculation finished", sep=""))
    }
  }
}

st_write(brb_list, dsn = paste(
  paste(
    imdir,
    "brb_values_allperiods",
    sep = ""
  ),
  "shp",
  sep = "."
))
system("say alle kernel distanzen berechnet für die verschiedenen Untersuchungsperioden")
all_homeranges_test <- all_homeranges %>% filter(algorithm=="brb")
```

```{r BRB - HR per-year - HR sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/BRB/years/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/BRB/years/",format(Sys.Date(), "%Y%m%d"), "/", sep="")

#### retrieve sampling intervals
mainSI <- rep(30,length(selected_females))
indexitter <- 0
brb_list <- data.frame() # results
brb_overlap_UD_year <- list() # only for tital research period activate filter above

for (samplinginterval in c(1:length(year_list))){
  print(paste("brb for year: ",samplinginterval))
  ##### Determine the smoothing parameters
  selected_females <- year_list[[samplinginterval]] %>% group_by(focal) %>% summarise()
  selected_females <- as_vector(selected_females)
  
  iterator <- 1
  for (i in selected_females) { # do the following for every animal in the list
    print(paste("brb for focal: ",i))
    n_follows <- year_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
        group_by(follow) %>% summarise() %>% nrow()

    xy_selected <- year_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
      dplyr::select(E,N,timelag_lead,manualDatetime)
    n_gps <- xy_selected %>% nrow()

    colnames(xy_selected) <- c("x","y","timelag_lead","timestamp") #adjust column names
    xy_selected <- xy_selected %>%  mutate(timelag_lead = round(timelag_lead,digits=0))
  
    # only select points where timegaps are between 20-40min --> To do pretty bad selection we would need a function which selects points automatically by subsampling if mean timegap is too high or by interpolating if too small. But how much does it really affect the result of HR --> because we mainly compare HR sizes.
    #xy_selected <- xy_selected %>% filter((timelag_lead/60)>20) #select which SI to remove (xy_selected$timelag_lead/60 < (mainSI[[iterator]]-10))
    #xy_selected <- xy_selected %>% filter((timelag_lead/60)<40)
    #xy_selected <- xy_selected[!(is.na(xy_selected$y)),]
    
    # check if enough gps points are still here otherwise make NA's
    xy_selected_toolessdata <- TRUE
    if(nrow(xy_selected)<30){xy_selected_toolessdata <- FALSE}
    
    # samplingI <- vector()
    # samplingI <- xy_selected$timelag_lead/60
    # samplingI <- samplingI[2:length(samplingI)] # First value of timelag_lead is NA
    # plot(table(samplingI), type="h", xlim=c(20,40),col=4, ylab="frequency", xlab="sampling interval [min]")
    
    xy_selected <- xy_selected[order(xy_selected$timestamp , decreasing = FALSE ),] 
    moveObj <- move(x=xy_selected$x, y=xy_selected$y, time=xy_selected$timestamp, proj=CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " ),animal=i)
    ##########################################################################################
    relUn <- 12 # relocation uncertainty [m]
    ##########################################################################################
    velocity <- unname(quantile(speed(moveObj), 0.99)) * 60 # unit: [m/min]
    hmin <- relUn + (0.5 * velocity * 30) # meters, smoothing
    iterator <- iterator+1
    
    
    
    traj <- as.ltraj(xy=xy_selected[,c("x", "y")], date=xy_selected$timestamp, id=i)
  
    ##########################################################################################
    tmax <- 70*60 # seconds, maximum time span for a segment
    lmin <- 12 # meters, minimal distance of a segment in order to count as movement
    tau <- 1*60 #seconds, approx. duration of one interpolated interval -> defines the number of intervals per step 
    extVal <- 15
    gridVal <- 2000
    hminRef <- hmin # computed through "BRB_leo_hmin computation.R"
    hminFactor <- c(0.6, 0.8, 1,1.2,1.4,  1.6, 1.8)
    ##########################################################################################
  
    vv <- BRB.D(traj, Tmax=tmax, Lmin=lmin) #estimate the diffusion coefficient
    for (l in seq(1:length(hminFactor))) {
      start_time <- Sys.time()
      hmin <- hminFactor[[l]]*hminRef
      if(xy_selected_toolessdata){# only execute when enough data
      UD <- BRB(traj, D=vv, Tmax=tmax, Lmin=lmin, hmin=hmin, b=T,  grid=grid, extent=extentfactor, filtershort=T, type="UD")

      tryCatch(
            expr = {
              hr95 <- getverticeshr(UD, percent=95, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr95_sf <- st_as_sf(hr95)
            },
            error = function(e){ 
              hr95 <- NA
              hr95_sf <- NA
              message()
              message(paste(i,hminFactor[[l]],n_gps,n_follows,samplinginterval,sep = " : "))
            }
        )
      tryCatch(
            expr = {
              hr99 <- getverticeshr(UD, percent=99, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr99_sf <- st_as_sf(hr99)
            },
            error = function(e){ 
              hr99 <- NA
              hr99_sf <- NA
              message()
              message(paste(i,hminFactor[[l]],n_gps,n_follows,samplinginterval,sep = " : "))
            }
        )
      tryCatch(
            expr = {
              hr50 <- getverticeshr(UD, percent=50, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr50_sf <- st_as_sf(hr50)
            },
            error = function(e){ 
              hr50 <- NA
              hr50_sf <- NA
              message(paste(i,hminFactor[[l]],n_gps,n_follows,samplinginterval," getting hr percentage polygon didn't work",sep = " : "))
            }
        )

      
      ########## save UD ##########
      brb_overlap_UD_year[[1+indexitter]] <- list(i,UD,"brb",hminFactor[[l]],n_gps,n_follows,names(period_list)[samplinginterval])
      indexitter <- indexitter+1
      
      ########## plot results ##########
      hminTxt <- gsub(".", "_", as.character(hminFactor[[l]]), fixed=T)
      
      png(paste(imdir,i, "_BRB_UD_", hminTxt,"_",names(year_list)[samplinginterval], ".png", sep=""), width=1800, height=1400, res=240, units="px")
      image(UD,xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1))) 
      plot(hr50, lty=3, lwd=1.5, border="darkseagreen3", add=T,axes=F)
      plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
      plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
      plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 0.7), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 0.7),lwd=0.3, bg="darkred", add=T, axes=F)
      plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
      plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
      axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
      axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
      title(paste(i, ": BRB (", hminFactor[[l]], "*hmin)", sep=""), line=-1.5)
      legend("topright", c("HR 50%", "HR 95%", "HR 99%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsety,legendoffsety), border=NA,box.lwd=NA)
      dev.off()
      
      png(paste(imdir,i, "_BRB_VUD_", hminTxt,"_",names(year_list)[samplinginterval], ".png", sep=""), width=1800, height=1400, res=240, units="px")
      image(getvolumeUD(UD),xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1))) 
      plot(hr50, lty=3, lwd=1.5, border="darkseagreen3", add=T,axes=F)
      plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
      plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
      plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 0.7), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 0.7),lwd=0.3, bg="darkred", add=T, axes=F)
      plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
      plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
      axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
      axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
      title(paste(i, ": BRB (", hminFactor[[l]], "*hmin)", sep=""), line=-1.5)
      legend("topright", c("HR 50%", "HR 95%", "HR 99%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsety,legendoffsety), border=NA,box.lwd=NA)
      dev.off()}
      
      end_time <- Sys.time()
      duration <- end_time-start_time
      
      ########## export results ############
      if(xy_selected_toolessdata) {
        resultList_50 <-
          data.frame(
            focal = i,
            homerange = hr50$area,
            hrpercentage ="50%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(year_list)[samplinginterval],
            processingtime = duration,
            geometry=hr50_sf$geometry
          )
        resultList_95 <-
          data.frame(
            focal = i,
            homerange = hr95$area,
            hrpercentage ="95%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(year_list)[samplinginterval],
            processingtime = duration,
            geometry=hr95_sf$geometry
          )
        resultList_99 <-
          data.frame(
            focal = i,
            homerange = hr99$area,
            hrpercentage ="99%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(year_list)[samplinginterval],
            processingtime = duration,
            geometry=hr99_sf$geometry
          )
      }
      if (!xy_selected_toolessdata) {
                resultList_50 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="50%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(year_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
        resultList_95 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="95%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(year_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
        resultList_99 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="99%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(year_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
      }
      brb_list <- brb_list %>% rbind(resultList_50,resultList_95,resultList_99)
      
      print(paste(hminFactor[[l]],": Calculation finished", sep=""))
    }
  }
}

st_write(brb_list, dsn = paste(
  paste(
    imdir,
    "brb_values_years",
    sep = ""
  ),
  "shp",
  sep = "."
))
system("say alle kernel distanzen berechnet für die verschiedenen Untersuchungsjahre")


```


## dBBMM
```{r TESTING dBBMM - HR sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/CTMM/periods/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/CTMM/periods/",format(Sys.Date(), "%Y%m%d"), "/", sep="")

#### retrieve sampling intervals
mainSI <- rep(30,length(selected_females))

ctmm_list <- data.frame() # results
for (samplinginterval in c(1:length(period_list))){
  print(paste("brb for period: ",samplinginterval))
  ##### Determine the smoothing parameters
  selected_females <- period_list[[samplinginterval]] %>% group_by(focal) %>% summarise()
  selected_females <- as_vector(selected_females)
  
  iterator <- 1
  for (i in selected_females) { # do the following for every animal in the list
    print(paste("brb for focal: ",i))
    n_follows <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
        group_by(follow) %>% summarise() %>% nrow()

    xy_selected <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
      dplyr::select(E,N,timelag_lead,manualDatetime)
    n_gps <- xy_selected %>% nrow()

    colnames(xy_selected) <- c("x","y","timelag_lead","timestamp") #adjust column names
    xy_selected <- xy_selected %>%  mutate(timelag_lead = round(timelag_lead,digits=0))
  
    # only select points where timegaps are between 20-40min --> To do pretty bad selection we would need a function which selects points automatically by subsampling if mean timegap is too high or by interpolating if too small. But how much does it really affect the result of HR --> because we mainly compare HR sizes.
    #xy_selected <- xy_selected %>% filter((timelag_lead/60)>20) #select which SI to remove (xy_selected$timelag_lead/60 < (mainSI[[iterator]]-10))
    #xy_selected <- xy_selected %>% filter((timelag_lead/60)<40)
    #xy_selected <- xy_selected[!(is.na(xy_selected$y)),]
    
    # check if enough gps points are still here otherwise make NA's
    xy_selected_toolessdata <- TRUE
    if(nrow(xy_selected)<30){xy_selected_toolessdata <- FALSE}
    
    # samplingI <- vector()
    # samplingI <- xy_selected$timelag_lead/60
    # samplingI <- samplingI[2:length(samplingI)] # First value of timelag_lead is NA
    # plot(table(samplingI), type="h", xlim=c(20,40),col=4, ylab="frequency", xlab="sampling interval [min]")
    
    xy_selected <- xy_selected[order(xy_selected$timestamp , decreasing = FALSE ),] 
    moveObj <- move(x=xy_selected$x, y=xy_selected$y, time=xy_selected$timestamp, proj=CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " ),animal=i)
    ##########################################################################################
    relUn <- 12 # relocation uncertainty [m]
    ##########################################################################################
    velocity <- unname(quantile(speed(moveObj), 0.99)) * 60 # unit: [m/min]
    hmin <- relUn + (0.5 * velocity * 30) # meters, smoothing
    iterator <- iterator+1
    
    
    
    traj <- as.ltraj(xy=xy_selected[,c("x", "y")], date=xy_selected$timestamp, id=i)
  
    ##########################################################################################
    tmax <- 70*60 # seconds, maximum time span for a segment
    lmin <- 12 # meters, minimal distance of a segment in order to count as movement
    tau <- 1*60 #seconds, approx. duration of one interpolated interval -> defines the number of intervals per step 
    extVal <- 15
    gridVal <- 2000
    hminRef <- hmin # computed through "BRB_leo_hmin computation.R"
    hminFactor <- c(0.6, 0.8, 1,1.2,1.4,  1.6, 1.8)
    ##########################################################################################
  
    vv <- BRB.D(traj, Tmax=tmax, Lmin=lmin) #estimate the diffusion coefficient
    for (l in seq(1:length(hminFactor))) {
      start_time <- Sys.time()
      hmin <- hminFactor[[l]]*hminRef
      if(xy_selected_toolessdata){# only execute when enough data
      UD <- BRB(traj, D=vv, Tmax=tmax, Lmin=lmin, hmin=hmin, b=T, same4all=T, grid=gridVal, extent=extVal, filtershort=T, type="UD")
      
      hr95 <- getverticeshr(UD, percent=95, standardize=TRUE,unin = c("m"),unout = c("km2"))
      hr50 <- getverticeshr(UD, percent=50, standardize=TRUE,unin = c("m"),unout = c("km2"))
      hr99 <- getverticeshr(UD, percent=99, standardize=TRUE,unin = c("m"),unout = c("km2"))
      hr95_sf <- st_as_sf(hr95)
      hr50_sf <- st_as_sf(hr50)
      hr99_sf <- st_as_sf(hr99)
      
      par(0,0,0,0)
      step <- 200
      
      ########## plot results ##########
      hminTxt <- gsub(".", "_", as.character(hminFactor[[l]]), fixed=T)
      xmin_xmax_round_steps<- c(step*(ceiling(xmin/step)):(round(xmax/step)))
      xmin_xmax_round_steps <- xmin_xmax_round_steps[2:(length(xmin_xmax_round_steps)-2)] #manual adjustment of tick breaks how many does it need
      ymin_ymax_round_steps<- c(step*(ceiling(ymin/step)):(round(ymax/step)))
      ymin_ymax_round_steps <- ymin_ymax_round_steps[2:(length(ymin_ymax_round_steps)-1)] #manual adjustment of tick breaks how many does it need    
      
  
      
      png(paste(imdir,i, "_BRB_UD_", hminTxt,"_",names(period_list)[samplinginterval], ".png", sep=""), width=1800, height=1400, res=240, units="px")
      image(UD, xlab="x [m]",ylab="y [m]",xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1))) 
      plot(hr50, lty=3, lwd=1.5, border="darkseagreen3", add=T,axes=F)
      plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
      plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
      plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 0.7), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 0.7),lwd=0.3, bg="darkred", add=T, axes=F)
      plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
      plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
      axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
      axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
      title(paste(i, ": BRB (", hminFactor[[l]], "*hmin)", sep=""), line=-1.5)
      legend("topright", c("HR 50%", "HR 95%", "HR 100%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsety,legendoffsety))
      dev.off()
      
      png(paste(imdir,i, "_BRB_VUD_", hminTxt,"_",names(period_list)[samplinginterval], ".png", sep=""), width=1800, height=1400, res=240, units="px")
      image(getvolumeUD(UD), xlab="x [m]",ylab="y [m]",xlim=c(xmin_xmax_round_steps[1],tail(xmin_xmax_round_steps,n=1)),ylim=c(ymin_ymax_round_steps[1],tail(ymin_ymax_round_steps,n=1))) 
      plot(hr50, lty=3, lwd=1.5, border="darkseagreen3", add=T,axes=F)
      plot(hr95, lty=1, lwd=1, border="cadetblue2", add=T, axes=F)
      plot(hr99, lty=4, lwd=1, border="darkturquoise", add=T, axes=F)
      plot(SUAQ_contour_sf_loc,lty=3, lwd=0.2, col=alpha("black", 1), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 21,cex=1.5, col=alpha("black", 0.7), add=T, axes=F)
      plot(SUAQ_station_sf_loc,pch = 16,cex=1, col=alpha("darkred", 0.7),lwd=0.3, bg="darkred", add=T, axes=F)
      plot(SUAQ_river_sf_loc,lty=1, lwd=0.3, col=alpha("cornflowerblue", 0.7), add=T, axes=F)
      plot(SUAQ_pathnetwork_sf_loc, lty=1, lwd=0.3, col=alpha("darkolivegreen", 0.7), add=T, axes=F)
      axis(1, at=xmin_xmax_round_steps,pos=ymin+axisshifty) # x axis
      axis(2, at=ymin_ymax_round_steps, pos=xmin+axisshiftx)
      title(paste(i, ": BRB (", hminFactor[[l]], "*hmin)", sep=""), line=-1.5)
      legend("topright", c("HR 50%", "HR 95%", "HR 100%","Trail","River"), col=c("coral1", "cadetblue2", "darkturquoise","darkred",alpha("cornflowerblue", 0.7)), lwd=c(2.5,2,2,0.3,4), lty=c(3,1,4,1,1), inset=c(legendoffsety,legendoffsety))
      dev.off()}
      
      end_time <- Sys.time()
      duration <- end_time-start_time
      
      ########## export results ############
      if(xy_selected_toolessdata) {
        resultList_50 <-
          data.frame(
            focal = i,
            homerange = hr50$area,
            hrpercentage ="50%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr50_sf$geometry
          )
        resultList_95 <-
          data.frame(
            focal = i,
            homerange = hr95$area,
            hrpercentage ="95%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr95_sf$geometry
          )
        resultList_99 <-
          data.frame(
            focal = i,
            homerange = hr99$area,
            hrpercentage ="99%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr99_sf$geometry
          )
      }
      if (!xy_selected_toolessdata) {
                resultList_50 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="50%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
        resultList_95 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="95%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
        resultList_99 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="99%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
      }
      ctmm_list <- ctmm_list %>% rbind(resultList_50,resultList_95,resultList_99)
      
      print(paste(hminTxt, ": Calculation finished", sep=""))
    }
  }
}

st_write(ctmm_list, dsn = paste(
  paste(
    imdir,
    "ctmm_values_allperiods",
    sep = ""
  ),
  "shp",
  sep = "."
))
system("say alle kernel distanzen berechnet für die verschiedenen Untersuchungsperioden")


```

```{r CTMM - HR size online,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}

##### Save Dataset for CTMM online f.e.
SUAQ_rangepoints_11all20_loc_females12_wgs <- SUAQ_rangepoints_11all20_loc_wgs[order(SUAQ_rangepoints_11all20_loc_wgs$focal,SUAQ_rangepoints_11all20_loc_wgs$manualDatetime , decreasing = TRUE ),] %>% rename(
    c("event-id"="identification","timestamp"="manualDatetime","location-long"="long","location-lat"="lat","Animal ID"="focal","Tag No"="follow")
  ) %>% filter(`Animal ID`%in% c("lisa","friska","ellie","cissy","lilly","yulia","raffi","sarabi","trident","alice","tiara","cinnamon")) %>% mutate("sensor-type"="gps")
write_csv(SUAQ_rangepoints_11all20_loc_wgs, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "SUAQ_rangepoints_11all20_loc_females12_wgs",
    sep = ""
  ),
  "csv",
  sep = "."
))
SUAQ_rangepoints_11all20_loc_females6_wgs <- SUAQ_rangepoints_11all20_loc_wgs[order(SUAQ_rangepoints_11all20_loc_wgs$focal,SUAQ_rangepoints_11all20_loc_wgs$manualDatetime , decreasing = TRUE ),] %>% rename(
    c("event-id"="identification","timestamp"="manualDatetime","location-long"="long","location-lat"="lat","Animal ID"="focal","Tag No"="follow")
  ) %>% filter(`Animal ID`%in% c("lisa","friska","ellie","cissy","lilly","yulia")) %>% mutate("sensor-type"="gps")
write_csv(SUAQ_rangepoints_11all20_loc_females6_wgs, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "SUAQ_rangepoints_11all20_loc_females6_wgs",
    sep = ""
  ),
  "csv",
  sep = "."
))


SUAQ_rangepoints_11all20_loc_females_10_wgs <- SUAQ_rangepoints_11all20_loc_wgs[order(SUAQ_rangepoints_11all20_loc_wgs$focal,SUAQ_rangepoints_11all20_loc_wgs$manualDatetime , decreasing = TRUE ),] %>% rename(
    c("event-id"="identification","timestamp"="manualDatetime","location-long"="long","location-lat"="lat","Animal ID"="focal","Tag No"="follow")
  ) %>% filter(`Animal ID`%in% c("lisa",
      "friska",
      "ellie",
      "cissy",
      "lilly",
      "yulia",
      "raffi",
      "sarabi",
      "trident",
      "tiara")) %>% mutate("sensor-type"="gps")
write_csv(SUAQ_rangepoints_11all20_loc_females_10_wgs, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "SUAQ_rangepoints_11all20_loc_females_10_wgs",
    sep = ""
  ),
  "csv",
  sep = "."
))

```

# Trees per Homeranges and full dataset
```{r Homeranges - Create full dataset ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
## Import datasets
### read in ctmm results
#### pooled
shplist_pooled<- list.files("/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/output/Homeranges/CTMM/periods/pooled/20210325/10_most_ctmm_4errors_12uere_pooled_HR_shp/", pattern="*.shp", full.names=TRUE)

start_time <- Sys.time()
SUAQ_ctmm_homeranges_pooled<- shplist_pooled%>% 
  map_df(~st_read_homeranges(.))
end_time <- Sys.time()
print(start_time-end_time)
SUAQ_ctmm_homeranges_pooled <- SUAQ_ctmm_homeranges_pooled %>% mutate(modelbase="pooled",algorithm="akde")
SUAQ_ctmm_homeranges_pooled$area <- as.numeric(st_area(SUAQ_ctmm_homeranges_pooled))/1000000

#### unpooled
shplist_unpooled<- list.files("/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/output/Homeranges/CTMM/periods/unpooled/20210325/hrshape/", pattern="*.shp", full.names=TRUE)

start_time <- Sys.time()
SUAQ_ctmm_homeranges_unpooled<- shplist_unpooled%>% 
  map_df(~st_read_homeranges(.))
end_time <- Sys.time()
print(start_time-end_time)
SUAQ_ctmm_homeranges_unpooled <- SUAQ_ctmm_homeranges_unpooled %>% mutate(modelbase="unpooled",algorithm="akde")
SUAQ_ctmm_homeranges_unpooled$area <- as.numeric(st_area(SUAQ_ctmm_homeranges_unpooled))/1000000

#### total
ctmm_allperiods_sf <- SUAQ_ctmm_homeranges_unpooled %>% rbind(SUAQ_ctmm_homeranges_pooled) %>% dplyr::select(-statisticalBoundary) %>% mutate(period="total research period")

#### Homerange sizes overview
lastdate<- "20210611"
scnddate <- "20210706_globalHminref"
kde_allperiods_sf<- st_read(dsn=paste0("output/Homeranges/KDE/periods/",lastdate,"/kde_values_allperiods.shp")) %>% 
  mutate(algorithm="kde") %>% st_set_crs(23867)
brb_allperiods_sf<- st_read(dsn=paste0("output/Homeranges/BRB/periods/",scnddate,"/brb_values_allperiods.shp")) %>% 
  mutate(algorithm="brb") %>% rename(area=homerng) %>% st_set_crs(23867)
mcp_allperiods_sf<- st_read(dsn=paste0("output/Homeranges/MCP/periods/",lastdate,"/mcp_values_allperiods.shp")) %>% 
  mutate(algorithm="mcp") %>% rename(area=homerng) %>% st_set_crs(23867)
all_homeranges_sf <- kde_allperiods_sf %>% bind_rows(brb_allperiods_sf) %>% bind_rows(mcp_allperiods_sf) %>% bind_rows(ctmm_allperiods_sf)
all_homeranges_sf$period <- factor(all_homeranges_sf$period, levels = c("before 2012", "2012 until 2016", "left", "2016 until August 2018", "Since August 2018","total research period"))
all_homeranges <- all_homeranges_sf %>% st_drop_geometry()

### Feeding trees
SUAQ_waypoints_11all20_loc_tree <- SUAQ_waypoints_11all20_loc %>% filter(PtType=="tree")
SUAQ_waypoints_11all20_loc_tree_sf <-  st_as_sf(SUAQ_waypoints_11all20_loc_tree, 
                          coords = c("E","N"), 
                          crs = 23867) # can also do that in the new script
SUAQ_waypoints_11all20_loc_sf <- SUAQ_waypoints_11all20_loc
SUAQ_waypoints_11all20_loc_sf <-  st_as_sf(SUAQ_waypoints_11all20_loc_sf, 
                          coords = c("E","N"), 
                          crs = 23867) # can also do that in the new script




```

```{r Homeranges - HRE comparison, bandwith comparison, final data frame of HR ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}

# area under the curve is already calculated see mor at Walter 2015 only for KDE and BRB
all_homeranges_sf$Comp_fullarea <- NA
all_homeranges_sf$Comp_compactness <- NA
all_homeranges_sf$Comp_holearea <- NA_integer_
all_homeranges_sf$Comp_polycount <- NA_integer_

### Progress bar
pb <-  txtProgressBar(min = 0, max = NROW(all_homeranges_sf), initial = 0) 
stepi <-0
          

for (i in c(1:nrow(all_homeranges_sf))) {
  print(i)
    if(as.numeric(st_area(st_as_sf(all_homeranges_sf[i,])))>0){# check if geometry is available
  object<- as_Spatial(all_homeranges_sf[i,])
  all_homeranges_sf$Comp_fullarea[i] <- gArea(object)}}


### Progress bar
for (i in c(1:nrow(all_homeranges_sf))) {
  if(as.numeric(st_area(st_as_sf(all_homeranges_sf[i,])))>0){# check if geometry is available
  object<- as_Spatial(all_homeranges_sf[i,])

  polycount <- 0
  holecount <- 0
  holearea <- 0
 
  for (j in seq(1:length(object@polygons[[1]]@Polygons))) {     #Nr of polygons
    if (object@polygons[[1]]@Polygons[[j]]@hole == FALSE) {
      if (object@polygons[[1]]@Polygons[[j]]@area >= 1000) {
        polycount <- polycount + 1
      }
    }
    else if (object@polygons[[1]]@Polygons[[j]]@hole == TRUE) { #Nr of holes
      holearea <- holearea + object@polygons[[1]]@Polygons[[j]]@area
      if (object@polygons[[1]]@Polygons[[j]]@area >= 1000) {
        holecount <- holecount +1
      }
    }
  }
  
  #print(holecount)
  #print(polycount)
  #capture.output(holecount, file=outputPath, append=T)
  #capture.output(polycount, file=outputPath, append=T)
  
  tmp<- slot(object, 'polygons')                                 #Compactness
  xc <- c()
  yc <- c()
  tmp2 <- slot(tmp[[1]],'Polygons')
  for (k in seq(1:length(tmp[[1]]@Polygons))) {
    if (tmp2[[k]]@hole == FALSE) {
      xc <- c(xc, tmp2[[k]]@coords[,1])
      yc <- c(yc, tmp2[[k]]@coords[,2])
    }
  }
  circle <-circumcircle(xc, yc,plot=F)
  circRad <- circle$radius
  polArea <- gArea(object) + holearea
  s3 <- (4*polArea)/(pi*((2*circRad)^2))
  #print(s3)
  all_homeranges_sf$Comp_fullarea[i] <- gArea(object)
  all_homeranges_sf$Comp_compactness[i] <- s3
  all_homeranges_sf$holecount[i] <- holecount
  all_homeranges_sf$Comp_holearea[i] <- holearea
  all_homeranges_sf$Comp_polycount[i] <- polycount
  
  # change progress bar
  setTxtProgressBar(pb,stepi) 
  stepi <-  stepi + 1
  # change progress bar
  }
}

st_write(all_homeranges_sf, dsn = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "20210713_all_homeranges_sf",
    sep = ""
  ),
  "shp",
  sep = "."
))

```

```{r Homeranges - Number of trees in HR ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
##### Initialize progressbar
pb <-  txtProgressBar(min = 0, max = NROW(all_homeranges_sf), initial = 0) 
stepi <-0
all_homeranges_sf <- all_homeranges_sf %>% mutate(number_of_trees=NA_integer_,first_nn_average= NA_integer_)
##### Adding number of fruittrees
for (i in c(1:NROW(all_homeranges_sf))){
  nndist_trees<- st_intersection(SUAQ_waypoints_11all20_loc_tree_sf$geometry,all_homeranges_sf[i,])
  nndist_trees <- do.call(rbind, st_geometry(nndist_trees)) %>% 
  as_tibble() %>% setNames(c("x","y"))

  ifelse(nrow(nndist_trees)==0,first_nn_average <- NA,first_nn_average <- mean(nndist(nndist_trees),na.rm = TRUE))  
       
  number_of_pnts_within<- st_intersection(SUAQ_waypoints_11all20_loc_tree_sf$geometry,all_homeranges_sf[i,]) %>% NROW()
  all_homeranges_sf$number_of_trees[i] <- number_of_pnts_within
  all_homeranges_sf$first_nn_average[i] <- first_nn_average
  setTxtProgressBar(pb,stepi) # change progress bar
  stepi <-  stepi + 1
}
pb <-  txtProgressBar(min = 0, max = NROW(all_homeranges_sf), initial = 0) 
stepi <-0
all_homeranges_sf <- all_homeranges_sf %>% mutate(researcheffort_ngps=NA_integer_)
for (i in c(1:NROW(all_homeranges_sf))){

  number_of_pnts_within<- st_intersection(SUAQ_waypoints_11all20_loc_sf$geometry,all_homeranges_sf[i,]) %>% NROW()
  all_homeranges_sf$researcheffort_ngps[i] <- number_of_pnts_within
  setTxtProgressBar(pb,stepi) # change progress bar
  stepi <-  stepi + 1
}
all_homeranges_sf <- all_homeranges_sf %>% mutate(fruittree_normalized=number_of_trees/researcheffort_ngps) %>% mutate(fruittree_norm_per_sqkm=fruittree_normalized/area) %>% mutate(fruittree_per_sqkm=number_of_trees/area)

st_write(all_homeranges_sf, dsn = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "all_homeranges_sf",
    sep = ""
  ),
  "shp",  
  sep = "."
))
write.csv(colnames(all_homeranges_sf),"/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/all_homeranges_sf_colnames.csv")

### Create homeranges dataframe with HR levels in each row
all_homeranges_dense50 <- all_homeranges %>% filter(hrprcnt=="50%") 
all_homeranges_dense95 <- all_homeranges %>% filter(hrprcnt=="95%")  %>% dplyr::select(area,hrprcnt,focal,bndwthm,period,hmin)
all_homeranges_dense99 <- all_homeranges %>% filter(hrprcnt=="99%")  %>% dplyr::select(area,hrprcnt,focal,bndwthm,period,hmin)
all_homeranges_dense100 <- all_homeranges %>% filter(hrprcnt=="100%")  %>% dplyr::select(area,hrprcnt,focal,bndwthm,period,hmin)
all_homeranges_dense <- all_homeranges_dense50 %>% 
  left_join(all_homeranges_dense95,by=c("focal"="focal","bndwthm"="bndwthm","period"="period","hmin"="hmin")) %>% 
  left_join(all_homeranges_dense99,by=c("focal"="focal","bndwthm"="bndwthm","period"="period","hmin"="hmin")) %>% 
  left_join(all_homeranges_dense100,by=c("focal"="focal","bndwthm"="bndwthm","period"="period","hmin"="hmin")) %>%   rename(area_50=area.x,hrprcnt_50=hrprcnt.x,area_95=area.y,hrprcnt_95=hrprcnt.y,area_99=area.x.x,hrprcnt_99=hrprcnt.x.x,area_100=area.y.y,hrprcnt_100=hrprcnt.y.y)
all_homeranges_dense <- all_homeranges_dense %>% mutate(corearea_ratio=area_50/area_95) 


plot_HRcomparison_ratio95_50corearea<- all_homeranges_dense %>% filter(hminfac%in%c(1.1,NA)) %>% filter(bndwthm%in%c("HREF",NA)) %>%  ggplot(aes(corearea_ratio,focal)) +geom_boxplot()+geom_point(aes(color=algorithm))
plot_HRcomparison_ratio95_50corearea
plot_brb_bootstrap_monthly %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_HRcomparison_females",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=600,width = 29.7,height = 21,units="cm")



```

# Overlaps and Number of Trees in Overlap
## Overlaps calculated from 95 and 50% HR
```{r Homeranges overlaps 50 and 95 (Simple, Jaccard, more??) - Create full dataset ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# save.image(file='20210411_HR_UDoverlaps.RData') save the recalculated UD's --> big file
# Load results from homerange creation and results of trees in homeranges
all_homeranges_sf<- st_read(dsn="/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/all_homeranges_sf.shp")
colnames<- read.csv("/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/all_homeranges_sf_colnames.csv")
colnames<- as.vector(colnames$x[!colnames$x %in% c("geometry")])
colnames <- c(colnames,c("geometry"))
colnames(all_homeranges_sf) <- colnames
### Create a non sf object aswell
all_homeranges <- all_homeranges_sf %>% st_drop_geometry()

all_homeranges_sf_selected <- all_homeranges_sf %>% filter(bndwthm %in% c(NA,"HBCV","HSCV")) %>% filter(hrprcnt%in%c("95%","50%")) %>% filter(hminfac %in% c(NA,0.8,1)) %>%  dplyr::select(-Vlct_99,-lmin,-fruittree_normalized,-researcheffort_ngps,-number_of_trees,-fruittree_per_sqkm,-fruittree_norm_per_sqkm,-GPSncrt,-tau,-hmin)

vecalgo<- levels(factor(as.factor(all_homeranges_sf_selected$algorithm)))
periods<- levels(factor(as.factor(all_homeranges_sf_selected$periods)))
all_overlaps_jaccard <- data.frame()
starttest <- TRUE
for(algo in vecalgo){
  print(algo)
  vechomreange <- levels(factor(as.factor(all_homeranges_sf_selected$hrprcnt)))
  for (hr in vechomreange){
    print(hr)
    if(algo=="akde"){methods <- levels(factor(as.factor(all_homeranges_sf_selected$modelbase)))}
    if(algo=="kde"){methods <- levels(factor(as.factor(all_homeranges_sf_selected$bndwthm)))}
    if(algo=="brb"){methods <- levels(factor(as.factor(all_homeranges_sf_selected$hminfac)))}
    if(algo=="mcp"){methods <- "mcptotal"}
    if(algo=="akde"){periods<- levels(factor(as.factor(all_homeranges_sf_selected[all_homeranges_sf_selected$algorithm=="ctmm",]$period)))}
    if(algo=="kde"){periods<- levels(factor(as.factor(all_homeranges_sf_selected[all_homeranges_sf_selected$algorithm=="kde",]$period)))}
    if(algo=="brb"){periods<- levels(factor(as.factor(all_homeranges_sf_selected[all_homeranges_sf_selected$algorithm=="brb",]$period)))}
    if(algo=="mcp"){periods<- levels(factor(as.factor(all_homeranges_sf_selected[all_homeranges_sf_selected$algorithm=="mcp",]$period)))}

    for (peri in periods){
      print(peri)
      for(method in methods){
      print(method)
      if(algo=="kde"){algo_data <- all_homeranges_sf_selected %>% filter(algorithm==algo) %>% filter(hrprcnt==hr) %>% filter(bndwthm==method) %>% filter(period==peri)}
      if(algo=="akde"){algo_data <- all_homeranges_sf_selected %>% filter(algorithm==algo) %>% filter(hrprcnt==hr) %>% filter(modelbase==method) %>% filter(period==peri)}
      if(algo=="brb"){algo_data <- all_homeranges_sf_selected %>% filter(algorithm==algo) %>% filter(hrprcnt==hr) %>% filter(hminfac==method)%>% filter(period==peri)}
      if(algo=="mcp"){algo_data <- all_homeranges_sf_selected %>% filter(algorithm==algo) %>% filter(hrprcnt==hr)%>% filter(period==peri)}
      focals<- levels(as.factor(algo_data$focal))
      focalcombination<- expand.grid(focals,focals)
      focalcombination<- focalcombination %>% filter(Var1!=Var2)
      #indx <- !duplicated(t(apply(focalcombination, 1, sort))) # finds non - duplicates in sorted rows, if active we get rid of the vis et verca combinations --> Just one way dyad if the overlap distance is undirected that works
      #focalcombination<- focalcombination[indx, ]
      for(overlap in c(1:NROW(focalcombination))){
        # Jaccard and normal overlap
        #print(paste0("overlap calc of ", focalcombination[overlap,1]," : ",focalcombination[overlap,2]))
        sf_focal1 <- algo_data %>% filter(focal==focalcombination[overlap,1])
        sf_focal2 <- algo_data %>% filter(focal==focalcombination[overlap,2])
        
        # Calculate the total percentage of space shared with any other Orangutan
        sf_allothers <- algo_data %>% filter(focal!=focalcombination[overlap,1])
        sf_allothers <- st_union(sf_allothers)

        area_shared <- 0
        if(st_intersects(sf_focal1,sf_allothers,sparse = FALSE)){
          area_shared <- (st_area(st_intersection(sf_focal1,sf_allothers))/1000000)/(st_area(sf_focal1)/1000000)}
        
        
        result_overlap<- st_intersection(sf_focal1,sf_focal2)# overlap in [km^2] (undirected)
        if(st_intersects(sf_focal1,sf_focal2,sparse = FALSE)){
          overlap_relative <- as.numeric((st_area(result_overlap)/1000000)/(st_area(sf_focal1)/1000000))
          overlap_jaccard <- ifelse(as.logical(st_intersects(sf_focal2,sf_focal1, sparse = FALSE)),as.numeric(((as.numeric(st_area(result_overlap)/1000000))/(st_area(st_union(sf_focal1,sf_focal2))/1000000))),0) # homerange similarity by size and overlap, overlp divided by total area of both (undirected)
          result_overlap<- bind_cols(result_overlap,data.frame(overlap=as.numeric(st_area(result_overlap)/1000000)))
          #ggplot(data=sf_focal1)+geom_sf(color="blue")+geom_sf(data=sf_focal2,color="red",fill=NA)
          result_overlapindices <- data.frame(
                area_shared = area_shared,
                overlap_jaccard = overlap_jaccard,
                overlap_relative = overlap_relative,
                overlap_HRshared = NA,
                overlap_HRpartof = NA,
                overlap_PHRotherself = NA,
                overlap_PHRselfother = NA,
                overlap_BA = NA,
                overlap_UDOI = NA,
                overlap_VI = NA,
                overlap_HD = NA
              )
          ### Testing KDE
          if(algo=="kde" & hr=="95%"){
          print("hello")
          boolean<- kde_overlap_UD_period %>% map(~ has_element(.x, c(as.character(focalcombination[overlap,1])))) %>% as_vector() # get the right algorithm
          focal1_UD<- kde_overlap_UD_period[boolean]
          boolean<- focal1_UD %>% map(~ has_element(.x, c(as.character(method)))) %>% as_vector() # get the right algorithm
          focal1_UD<- focal1_UD[boolean]
          boolean<- focal1_UD %>% map(~ has_element(.x, c(as.character(peri)))) %>% as_vector() # get the right algorithm
          focal1_UD<- focal1_UD[boolean]
          focal1_UD<- focal1_UD[[1]][[2]]
          boolean<- kde_overlap_UD_period %>% map(~ has_element(.x, c(as.character(focalcombination[overlap,2])))) %>% as_vector() # get the right algorithm
          focal2_UD<- kde_overlap_UD_period[boolean]
          boolean<- focal2_UD %>% map(~ has_element(.x, c(as.character(method)))) %>% as_vector() # get the right algorithm
          focal2_UD<- focal2_UD[boolean]
          boolean<- focal2_UD %>% map(~ has_element(.x, c(as.character(peri)))) %>% as_vector() # get the right algorithm
          focal2_UD<- focal2_UD[boolean]
          focal2_UD<- focal2_UD[[1]][[2]]
          estUDm_pseudo <- list(focal1=focal1_UD,focal2=focal2_UD)
          class(estUDm_pseudo) <- "estUDm"
          
          
          # hr95_1 <- getverticeshr(focal1_UD, percent=50,unin = c("m"),unout = c("km2"))
          # hr95_2 <- getverticeshr(focal2_UD, percent=50,unin = c("m"),unout = c("km2"))
          # hr95_1_sf<- st_as_sf(hr95_1) %>% st_set_crs(23867)
          # hr95_2_sf <- st_as_sf(hr95_2)%>% st_set_crs(23867)
          # ggplot(data=hr95_1_sf)+geom_sf(color="blue")+geom_sf(data=hr95_2_sf,color="red",fill=NA)
          # image(estUDm_pseudo)
          
          # HR − Proportion of animal i’s home range that is overlapped by animal j’s home range (Kernohan et al. 2001).
          currentUDoverlap_HR<- kerneloverlaphr(estUDm_pseudo, meth="HR", conditional=TRUE) #(is an DIRECTED index)
          
          # PHR − Probability of animal j being located in animal i’s home range and vice versa (i.e., volume measure; Ostfeld 1986).
          currentUDoverlap_PHR<- kerneloverlaphr(estUDm_pseudo, meth="PHR", conditional=TRUE) #(is an DIRECTED index)
          
          # BA − a statistical measure of affinity between 2 populations that assumes they use space independently of one another (Bhattacharyya 1943). Values range from zero (no overlap) to 1 (identical UDs).
          currentUDoverlap_BA<- kerneloverlaphr(estUDm_pseudo, meth="BA", conditional=TRUE) #(is an UNDIRECTED index)
          
          # UDOI − an UD overlap index similar to Hurlbert index of niche overlap that assumes they use space independently of one another (Hurlbert 1978). Values range from zero (no overlap) to 1 (uniformly distributed and have 100% overlap) but can be >1 if both UDs are nonuniformly distributed and have a high degree of overlap.
          currentUDoverlap_UDOI<- kerneloverlaphr(estUDm_pseudo, meth="UDOI", conditional=TRUE) #(is an UNDIRECTED index)
          
          # Volume of intersection under the full UDs of 2 animals (Seidel 1992, Millspaugh et al. 2000). Values range from zero (no overlap) to 1 (identical UDs).
          currentUDoverlap_VI<- kerneloverlaphr(estUDm_pseudo, meth="VI", conditional=TRUE) #(is an UNDIRECTED index)
          
          # HD − a measure of distance between 2 populations (Matusita 1973).
          currentUDoverlap_HD<- kerneloverlaphr(estUDm_pseudo, meth="HD", conditional=TRUE) #(is an UNDIRECTED index)
          
          result_overlapindices <- data.frame(
                area_shared = area_shared,
                overlap_jaccard = overlap_jaccard,
                overlap_relative = overlap_relative,
                overlap_HRshared = currentUDoverlap_HR[1, 2],
                overlap_HRpartof = currentUDoverlap_HR[2, 1],
                overlap_PHRotherself = currentUDoverlap_HR[1, 2],
                overlap_PHRselfother = currentUDoverlap_HR[2, 1],
                overlap_BA = currentUDoverlap_BA[1, 2],
                overlap_UDOI = currentUDoverlap_UDOI[1, 2],
                overlap_VI = currentUDoverlap_VI[1, 2],
                overlap_HD = currentUDoverlap_HD[1, 2]
              )
          }
          if(algo=="brb" & hr=="95%"){
            print("UD brb")
            boolean<- brb_overlap_UD_period %>% map(~ has_element(.x, c(as.character(focalcombination[overlap,1])))) %>% as_vector() # get the right algorithm
            focal1_UD<- brb_overlap_UD_period[boolean]
            boolean<- focal1_UD %>% map(~ has_element(.x, c(as.double(method)))) %>% as_vector() # get the right algorithm
            focal1_UD<- focal1_UD[boolean]
            boolean<- focal1_UD %>% map(~ has_element(.x, c(as.character(peri)))) %>% as_vector() # get the right algorithm
            focal1_UD<- focal1_UD[boolean]
            focal1_UD<- focal1_UD[[1]][[2]]
            boolean<- brb_overlap_UD_period %>% map(~ has_element(.x, c(as.character(focalcombination[overlap,2])))) %>% as_vector() # get the right algorithm
            focal2_UD<- brb_overlap_UD_period[boolean]
            boolean<- focal2_UD %>% map(~ has_element(.x, c(as.double(method)))) %>% as_vector() # get the right algorithm
            focal2_UD<- focal2_UD[boolean]
            boolean<- focal2_UD %>% map(~ has_element(.x, c(as.character(peri)))) %>% as_vector() # get the right algorithm
            focal2_UD<- focal2_UD[boolean]
            focal2_UD<- focal2_UD[[1]][[2]]
            estUDm_pseudo <- list(focal1=focal1_UD,focal2=focal2_UD)
            class(estUDm_pseudo) <- "estUDm"
            
            
            # hr95_1 <- getverticeshr(focal1_UD, percent=50,unin = c("m"),unout = c("km2"))
            # hr95_2 <- getverticeshr(focal2_UD, percent=50,unin = c("m"),unout = c("km2"))
            # hr95_1_sf<- st_as_sf(hr95_1) %>% st_set_crs(23867)
            # hr95_2_sf <- st_as_sf(hr95_2)%>% st_set_crs(23867)
            # ggplot(data=hr95_1_sf)+geom_sf(color="blue")+geom_sf(data=hr95_2_sf,color="red",fill=NA)
            # image(estUDm_pseudo)
            
            # HR − Proportion of animal i’s home range that is overlapped by animal j’s home range (Kernohan et al. 2001).
            currentUDoverlap_HR<- kerneloverlaphr(estUDm_pseudo, meth="HR", conditional=TRUE) #(is an DIRECTED index)
            
            # PHR − Probability of animal j being located in animal i’s home range and vice versa (i.e., volume measure; Ostfeld 1986).
            currentUDoverlap_PHR<- kerneloverlaphr(estUDm_pseudo, meth="PHR", conditional=TRUE) #(is an DIRECTED index)
            
            # BA − a statistical measure of affinity between 2 populations that assumes they use space independently of one another (Bhattacharyya 1943). Values range from zero (no overlap) to 1 (identical UDs).
            currentUDoverlap_BA<- kerneloverlaphr(estUDm_pseudo, meth="BA", conditional=TRUE) #(is an UNDIRECTED index)
            
            # UDOI − an UD overlap index similar to Hurlbert index of niche overlap that assumes they use space independently of one another (Hurlbert 1978). Values range from zero (no overlap) to 1 (uniformly distributed and have 100% overlap) but can be >1 if both UDs are nonuniformly distributed and have a high degree of overlap.
            currentUDoverlap_UDOI<- kerneloverlaphr(estUDm_pseudo, meth="UDOI", conditional=TRUE) #(is an UNDIRECTED index)
            
            # Volume of intersection under the full UDs of 2 animals (Seidel 1992, Millspaugh et al. 2000). Values range from zero (no overlap) to 1 (identical UDs).
            currentUDoverlap_VI<- kerneloverlaphr(estUDm_pseudo, meth="VI", conditional=TRUE) #(is an UNDIRECTED index)
            
            # HD − a measure of distance between 2 populations (Matusita 1973).
            currentUDoverlap_HD<- kerneloverlaphr(estUDm_pseudo, meth="HD", conditional=TRUE) #(is an UNDIRECTED index)
            result_overlapindices <- data.frame(
                  area_shared = area_shared,
                  overlap_jaccard = overlap_jaccard,
                  overlap_relative = overlap_relative,
                  overlap_HRshared = currentUDoverlap_HR[1, 2],
                  overlap_HRpartof = currentUDoverlap_HR[2, 1],
                  overlap_PHRotherself = currentUDoverlap_HR[1, 2],
                  overlap_PHRselfother = currentUDoverlap_HR[2, 1],
                  overlap_BA = currentUDoverlap_BA[1, 2],
                  overlap_UDOI = currentUDoverlap_UDOI[1, 2],
                  overlap_VI = currentUDoverlap_VI[1, 2],
                  overlap_HD = currentUDoverlap_HD[1, 2]
                )
            }
          
          
        result_overlap <-
          bind_cols(
              result_overlap,result_overlapindices
            ) %>% ungroup()
          ###
        }
        if(!st_intersects(sf_focal1,sf_focal2,sparse = FALSE)){result_overlap<- bind_cols(result_overlap,data.frame(overlap=NA,area_shared=area_shared,overlap_jaccard = NA,
                overlap_relative = NA,
                overlap_HRshared = NA,
                overlap_HRpartof = NA,
                overlap_PHRotherself = NA,
                overlap_PHRselfother = NA,
                overlap_BA = NA,
                overlap_UDOI = NA,
                overlap_VI = NA,
                overlap_HD = NA))}
        
        ifelse(starttest,
               all_overlaps_jaccard <- result_overlap ,
               all_overlaps_jaccard <- all_overlaps_jaccard %>% rbind(result_overlap))
        starttest <- FALSE
        

      }
      }
    }
  }
}






### Adding number of trees in overlaps --> use the above initialized datasets
##### Initialize progressbar
pb <-  txtProgressBar(min = 0, max = NROW(all_overlaps_jaccard), initial = 0) 
stepi <-0
all_overlaps_jaccard <- all_overlaps_jaccard %>% mutate(number_of_trees=NA_integer_)


##### Adding number of fruittrees
for (i in c(1:NROW(all_overlaps_jaccard))){
  number_of_pnts_within<- st_intersection(SUAQ_waypoints_11all20_loc_tree_sf$geometry,all_overlaps_jaccard[i,]) %>% NROW()
  all_overlaps_jaccard$number_of_trees[i] <- number_of_pnts_within
  setTxtProgressBar(pb,stepi) # change progress bar
  stepi <-  stepi + 1
}
pb <-  txtProgressBar(min = 0, max = NROW(all_overlaps_jaccard), initial = 0) 
stepi <-0
all_overlaps_jaccard <- all_overlaps_jaccard %>% mutate(researcheffort_ngps=NA_integer_)
for (i in c(1:NROW(all_overlaps_jaccard))){
  number_of_pnts_within<- st_intersection(SUAQ_waypoints_11all20_loc_sf$geometry,all_overlaps_jaccard[i,]) %>% NROW()
  all_overlaps_jaccard$researcheffort_ngps[i] <- number_of_pnts_within
  setTxtProgressBar(pb,stepi) # change progress bar
  stepi <-  stepi + 1
}
all_overlaps_jaccard <- all_overlaps_jaccard %>% mutate(fruittree_normalized=number_of_trees/researcheffort_ngps) %>% 
  mutate(fruittree_norm_per_sqkm=fruittree_normalized/area) %>% mutate(fruittree_per_sqkm=number_of_trees/area)

all_overlaps_jaccard <- all_overlaps_jaccard %>% mutate(
  area_shared=as.numeric(area_shared)
  )
st_write(all_overlaps_jaccard, dsn = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "all_overlaps",
    sep = ""
  ),
  "shp",
  sep = "."
))
write.csv(colnames(all_overlaps_jaccard),"/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/all_overlaps.csv")

### Adding additional infos
explanatoryvars <- SUAQ_rangepoints_11all20_loc_females_10[,c("focal","SUAQ_orangutans.matriline", "SUAQ_orangutans.agecategory","SUAQ_orangutans.dominancecat")] %>% group_by(focal,SUAQ_orangutans.matriline,SUAQ_orangutans.agecategory,SUAQ_orangutans.dominancecat) %>% summarise()
colnames(explanatoryvars) <- c("focal","matriline","agecat","dominance")

all_overlaps_50 <- all_overlaps_jaccard %>% left_join(explanatoryvars, by=c("focal"="focal")) %>% filter(hrprcnt=="50%")
all_overlaps_95 <- all_overlaps_jaccard %>% left_join(explanatoryvars, by=c("focal"="focal")) %>% filter(hrprcnt=="95%")
colnames(explanatoryvars) <- c("focal1","matriline1","agecat1","dominance1")
all_overlaps_50 <- all_overlaps_50 %>% left_join(explanatoryvars, by=c("focal.1"="focal1")) %>% filter(hrprcnt=="50%")
all_overlaps_95 <- all_overlaps_95 %>% left_join(explanatoryvars, by=c("focal.1"="focal1")) %>% filter(hrprcnt=="95%")
all_overlaps_50 <- all_overlaps_50 %>% mutate(dominancediff=abs(dominance1-dominance),related=ifelse(matriline1==matriline,TRUE,FALSE),agediff=abs(agecat1-agecat))
all_overlaps_95 <- all_overlaps_95 %>% mutate(dominancediff=abs(dominance1-dominance),related=ifelse(matriline1==matriline,TRUE,FALSE),agediff=abs(agecat1-agecat))


all_overlaps_95 %>% 
  #filter(period=="total research period") %>%  
  ggplot(aes(overlap_jaccard,agediff,group=agediff)) + 
  geom_boxplot(aes(overlap_jaccard ,agediff))+
  geom_point(aes(color=as.character(paste0(focal," : ",focal.1))),size=7)+
  facet_wrap(~ algorithm)

all_overlaps_95 %>% 
  #filter(period=="total research period") %>%  
  ggplot(aes(overlap_jaccard,dominancediff,group=dominancediff)) + 
  geom_boxplot(aes(overlap_jaccard ,dominancediff))+
  geom_point(aes(color=as.character(paste0(focal," : ",focal.1))),size=7)+
  facet_wrap(~ algorithm)

all_overlaps_95 %>% 
  #filter(period=="total research period") %>%  
  ggplot(aes(overlap_jaccard,related)) + 
  geom_boxplot(aes(overlap_jaccard ,related))+
  geom_point(aes(color=as.character(paste0(focal," : ",focal.1))),size=7)+
  facet_wrap(~ algorithm)

ggplot() + 
  geom_point(data=all_overlaps,aes(focal,fruittree_normalized,color=hrprcnt))+
  geom_jitter(data=all_homeranges_sf_selected,aes(focal,fruittree_normalized))

all_overlaps %>% ggplot(aes(overlap_VI,overlap_jaccard,colour=algorithm))+
  geom_point()

all_overlaps %>% dplyr::select(area,,focal,algorithm,overlap,overlap_jaccard,overlap_relative,overlap_BA,overlap_HD,overlap_HRpartof,overlap_HRshared,overlap_PHRotherself,overlap_PHRselfother,overlap_UDOI,overlap_VI,fruittree_normalized) %>% GGally::ggpairs()


```

```{r Homeranges & Overlaps (With trees) - load created full datasets ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# Load datasets if already available and adding right colnames because they are automatically cut probably by st_write function
all_overlaps_sf<- st_read(dsn="/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/all_overlaps.shp")
all_overlaps_sf <- all_overlaps_sf%>%  mutate(algrthm=ifelse(algrthm=="ctmm","akde",algrthm),algrt_1=ifelse(algrt_1=="ctmm","akde",algrt_1))
colnames<- read.csv("/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/all_overlaps.csv")
colnames<- as.vector(colnames$x[!colnames$x %in% c("geometry")])
colnames <- c(colnames,c("geometry"))
colnames(all_overlaps_sf) <- colnames
all_overlaps <- all_overlaps_sf %>% st_drop_geometry() %>% filter(bndwthm %in% c(NA, "HSCV")) %>% filter(period %in% c("total research period")) %>% filter(hminfac %in% c(NA,1))%>% filter(modelbase %in% c(NA,"unpooled")) ## overlaps for hminfac 0.8 are not yet calculated but it takes too much time
all_overlaps_allperiods <-  all_overlaps_sf  %>% filter(bndwthm %in% c(NA, "HSCV")) %>% filter(hminfac %in% c(NA,1))%>% filter(modelbase %in% c(NA,"unpooled")) %>% st_drop_geometry()
all_overlaps_sf <- all_overlaps_sf  %>% filter(bndwthm %in% c(NA, "HSCV")) %>% filter(period %in% c("total research period")) %>% filter(hminfac %in% c(NA,1))%>% filter(modelbase %in% c(NA,"unpooled")) ## overlaps for hminfac 0.8 are not yet calculated but it takes too much time


# Load results from homerange creation and results of trees in homeranges
all_homeranges_sf<- st_read(dsn="/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/all_homeranges_sf.shp")
all_homeranges_sf <- all_homeranges_sf%>% ungroup() %>%
  mutate(algrthm=ifelse(algrthm=="ctmm","akde",algrthm)) %>% 
  mutate(n_fllws=ifelse(algrthm=="akde",Mode(all_homeranges_sf[((all_homeranges_sf$hrprcnt==hrprcnt)&(all_homeranges_sf$period==period)&&(all_homeranges_sf$focal==focal)),]$n_fllws),n_fllws),
         n_gps=ifelse(algrthm=="akde",Mode(all_homeranges_sf[((all_homeranges_sf$hrprcnt==hrprcnt)&(all_homeranges_sf$period==period)&(all_homeranges_sf$focal==focal)),]$n_gps),n_gps)) # add number of follows and gps for akde algorithm
colnames<- read.csv("/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/all_homeranges_sf_colnames.csv")
colnames<- as.vector(colnames$x[!colnames$x %in% c("geometry")])
colnames <- c(colnames,c("geometry"))
colnames(all_homeranges_sf) <- colnames
### Create a non sf object aswell
explanatoryvars <- SUAQ_rangepoints_11all20_loc_females_10[,c("focal","SUAQ_orangutans.matriline", "SUAQ_orangutans.agecategory","SUAQ_orangutans.dominancecat")] %>% group_by(focal,SUAQ_orangutans.matriline,SUAQ_orangutans.agecategory,SUAQ_orangutans.dominancecat) %>% summarise()
colnames(explanatoryvars) <- c("focal","matriline","agecat","dominance")
DJL_follows<- read_csv("data/Processed_data/DJL_follows.csv")
overview_djl <- DJL_follows %>% 
  dplyr::select(focal,DJL,trj_sinuosity,RR,ageOfCurrentOffspring) %>% 
  filter(focal %in%selected_females) %>% 
  group_by(focal) %>% 
  summarise(DJL_mean=mean(DJL,na.rm=TRUE),SIN_mean=mean(trj_sinuosity,na.rm=TRUE),SI_mean=mean(RR,na.rm=TRUE),ageOfCurrentOffspring_mean=mean(ageOfCurrentOffspring,na.rm=TRUE))
all_homeranges_sf <- all_homeranges_sf %>% left_join(overview_djl,by=c("focal"="focal"))
all_homeranges_sf_selected <- all_homeranges_sf %>% filter(bndwthm %in% c(NA, "HSCV")) %>%filter(hminfac %in% c(NA, "0.8")) %>%filter(modelbase %in% c(NA,"unpooled"))
all_homeranges <- all_homeranges_sf %>% st_drop_geometry() %>% left_join(explanatoryvars, by=c("focal"="focal"))
all_homeranges_selected <- all_homeranges %>% filter(bndwthm %in% c(NA, "HSCV")) %>%filter(hminfac %in% c(NA, "0.8")) %>%filter(modelbase %in% c(NA,"unpooled"))
  
### Create Homerange dataframe with additional variables
all_homeranges_50 <- all_homeranges_sf_selected %>% st_drop_geometry() %>%  left_join(explanatoryvars, by=c("focal"="focal")) %>% filter(hrprcnt=="50%")
all_homeranges_95 <- all_homeranges_sf_selected %>% st_drop_geometry() %>% left_join(explanatoryvars, by=c("focal"="focal")) %>% filter(hrprcnt=="95%")
all_homeranges_50_sf <- all_homeranges_sf_selected %>% filter(hrprcnt=="50%")
all_homeranges_95_sf <- all_homeranges_sf_selected   %>% filter(hrprcnt=="95%")

### additional information
temp_matriline<- SUAQ_orangutans %>% mutate(SUAQ_orangutans.dominancecat=ifelse(SUAQ_orangutans.orangutanname=="tiara",3,SUAQ_orangutans.dominancecat)) %>%  group_by(focal=SUAQ_orangutans.orangutanname,matriline=SUAQ_orangutans.matriline) %>% summarise() %>% dplyr::select(focal,matriline) %>% 
  mutate(matriline=ifelse(focal=="tiara",3,matriline)) %>% 
  mutate(matriline=ifelse(focal=="trident",3,matriline))

specs_orangutan_tot_num_of_gps_NN<- SUAQ_rangepoints_11all20_loc %>% filter(followtype=="NN") %>% group_by(focal,follow) %>% summarise(number_of_gps=n()) %>% group_by(focal) %>% summarise(number_of_gps=sum(number_of_gps,na.rm=TRUE),n_follows=n())

### Creating overlap dataframe with additional variables
explanatoryvars <- SUAQ_rangepoints_11all20_loc_females_10[,c("focal","SUAQ_orangutans.matriline", "SUAQ_orangutans.agecategory","SUAQ_orangutans.dominancecat")] %>% group_by(focal,SUAQ_orangutans.matriline,SUAQ_orangutans.agecategory,SUAQ_orangutans.dominancecat) %>% summarise()
colnames(explanatoryvars) <- c("focal","matriline","agecat","dominance")

all_overlaps_50 <- all_overlaps %>% left_join(explanatoryvars, by=c("focal"="focal")) %>% filter(hrprcnt=="50%")
all_overlaps_allperiods_50 <- all_overlaps_allperiods %>% left_join(explanatoryvars, by=c("focal"="focal")) %>% filter(hrprcnt=="50%")
all_overlaps_50_sf <- all_overlaps_sf %>% left_join(explanatoryvars, by=c("focal"="focal")) %>% filter(hrprcnt=="50%")

all_overlaps_95 <- all_overlaps %>% left_join(explanatoryvars, by=c("focal"="focal")) %>% filter(hrprcnt=="95%")
all_overlaps_allperiods_95 <- all_overlaps_allperiods %>% left_join(explanatoryvars, by=c("focal"="focal")) %>% filter(hrprcnt=="95%")
all_overlaps_95_sf <- all_overlaps_sf %>% left_join(explanatoryvars, by=c("focal"="focal")) %>% filter(hrprcnt=="95%")

colnames(explanatoryvars) <- c("focal1","matriline1","agecat1","dominance1")
all_overlaps_50 <- all_overlaps_50 %>% left_join(explanatoryvars, by=c("focal.1"="focal1")) %>% filter(hrprcnt=="50%")
all_overlaps_allperiods_50 <- all_overlaps_allperiods_50 %>% left_join(explanatoryvars, by=c("focal.1"="focal1")) %>% filter(hrprcnt=="50%")
all_overlaps_allperiods_95 <- all_overlaps_allperiods_95 %>% left_join(explanatoryvars, by=c("focal.1"="focal1")) %>% filter(hrprcnt=="95%")
all_overlaps_95 <- all_overlaps_95 %>% left_join(explanatoryvars, by=c("focal.1"="focal1")) %>% filter(hrprcnt=="95%")
all_overlaps_50 <- all_overlaps_50 %>% mutate(dominancediff=abs(dominance1-dominance),related=ifelse(matriline1==matriline,TRUE,FALSE),agediff=abs(agecat1-agecat))
all_overlaps_allperiods_50 <- all_overlaps_allperiods_50 %>% mutate(dominancediff=abs(dominance1-dominance),related=ifelse(matriline1==matriline,TRUE,FALSE),agediff=abs(agecat1-agecat))
all_overlaps_95 <- all_overlaps_95 %>% mutate(dominancediff=abs(dominance1-dominance),related=ifelse(matriline1==matriline,TRUE,FALSE),agediff=abs(agecat1-agecat))
all_overlaps_allperiods_95 <- all_overlaps_allperiods_95 %>% mutate(dominancediff=abs(dominance1-dominance),related=ifelse(matriline1==matriline,TRUE,FALSE),agediff=abs(agecat1-agecat))


### Additional analysis data
#### Homerange sizes overview
overview_homerange50 <- all_homeranges_selected %>% 
  filter(hrprcnt%in%c("50%")) %>% 
  filter(algorithm%in%c("brb")) %>% 
  filter(period%in%c("total research period"))%>% 
  dplyr::select(focal,value=area) %>% 
  mutate(result="home range: BRB 50% [km^2]")
overview_homerange95 <- all_homeranges_selected %>% 
  filter(hrprcnt%in%c("95%")) %>% 
  filter(algorithm%in%c("brb")) %>% 
  filter(period%in%c("total research period"))%>% 
  dplyr::select(focal,value=area) %>% 
  mutate(result="home range: BRB 95% [km^2]")
overview_overlaps_related <- all_overlaps %>% 
  filter(hrprcnt%in%c("95%")) %>% 
  filter(algorithm%in%c("brb")) %>% 
  filter(period%in%c("total research period")) %>% 
  dplyr::select(focal,focal.1,value=overlap_HRshared)%>% 
  left_join(temp_matriline,by=c("focal"="focal")) %>% 
  left_join(temp_matriline,by=c("focal.1"="focal")) %>% 
  mutate(related=ifelse(matriline.x==matriline.y,"related","unrelated")) %>% dplyr::select(focal,focal.1,value,related) %>% 
  mutate(result="average overlaps related [UDOI]") %>% 
  filter(related=="related") %>% 
  group_by(focal,result) %>% 
  summarise(value=mean(value,na.rm=TRUE))
overview_overlaps_unrelated <- all_overlaps %>% 
  filter(hrprcnt%in%c("95%")) %>% 
  filter(algorithm%in%c("brb")) %>% 
  filter(period%in%c("total research period")) %>% 
  dplyr::select(focal,focal.1,value=overlap_HRshared)%>% 
  left_join(temp_matriline,by=c("focal"="focal")) %>% 
  left_join(temp_matriline,by=c("focal.1"="focal")) %>% 
  mutate(related=ifelse(matriline.x==matriline.y,"related","unrelated")) %>% dplyr::select(focal,focal.1,value,related) %>% 
  mutate(result="average overlaps unrelated [UDOI]") %>% 
  filter(related=="unrelated") %>% 
  group_by(focal,result) %>% summarise(value=mean(value,na.rm=TRUE))
overview_djl <- DJL_follows %>% 
  dplyr::select(focal,value=DJL) %>% 
  mutate(result="DJL [m]") %>% 
  filter(focal %in%selected_females) %>% 
  group_by(focal,result) %>% 
  summarise(value=mean(value,na.rm=TRUE))
overview_RR <- DJL_follows %>% 
  dplyr::select(focal,value=RR) %>% 
  mutate(result="SI [0-1]") %>% 
  dplyr::filter(focal %in%selected_females)%>% 
  group_by(focal,result) %>% 
  summarise(value=mean(value,na.rm=TRUE))
overview_SIN <- DJL_follows %>% 
  dplyr::select(focal,value=trj_sinuosity) %>% 
  mutate(result="SIN [0-1]")%>% 
  dplyr::filter(focal %in% selected_females)%>% 
  group_by(focal,result) %>% 
  summarise(value=mean(value,na.rm=TRUE))

```


(TODELETE --> integrated above)
## Overlaps calculated from UD of algorithms (TODELETE)
```{r Homeranges overlaps: recalculate UD from BRB - HR per-researchperiods and all - HR sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# Filter research periods if only one of the periods should be calculated
# period_list <- period_list[1] # keep only the total research period

# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/BRB/periods/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/BRB/periods/",format(Sys.Date(), "%Y%m%d"), "/", sep="")

#### retrieve sampling intervals
mainSI <- rep(30,length(selected_females))

brb_list <- data.frame() # results
brb_overlap_UD <- list() # only for tital research period activate filter above
for (samplinginterval in c(1:length(period_list))){
  print(paste("brb for period: ",samplinginterval))
  ##### Determine the smoothing parameters
  selected_females <- period_list[[samplinginterval]] %>% group_by(focal) %>% summarise()
  selected_females <- as_vector(selected_females)
  
  iterator <- 1
  indexitter <- 0
  for (i in selected_females) { # do the following for every animal in the list
    print(paste("brb for focal: ",i))
    n_follows <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
        group_by(follow) %>% summarise() %>% nrow()

    xy_selected <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>%
      dplyr::select(E,N,timelag_lead,manualDatetime)
    n_gps <- xy_selected %>% nrow()

    colnames(xy_selected) <- c("x","y","timelag_lead","timestamp") #adjust column names
    xy_selected <- xy_selected %>%  mutate(timelag_lead = round(timelag_lead,digits=0))
  
    # only select points where timegaps are between 20-40min --> To do pretty bad selection we would need a function which selects points automatically by subsampling if mean timegap is too high or by interpolating if too small. But how much does it really affect the result of HR --> because we mainly compare HR sizes.
    #xy_selected <- xy_selected %>% filter((timelag_lead/60)>20) #select which SI to remove (xy_selected$timelag_lead/60 < (mainSI[[iterator]]-10))
    #xy_selected <- xy_selected %>% filter((timelag_lead/60)<40)
    #xy_selected <- xy_selected[!(is.na(xy_selected$y)),]
    
    # check if enough gps points are still here otherwise make NA's
    xy_selected_toolessdata <- TRUE
    if(nrow(xy_selected)<30){xy_selected_toolessdata <- FALSE}
    
    # samplingI <- vector()
    # samplingI <- xy_selected$timelag_lead/60
    # samplingI <- samplingI[2:length(samplingI)] # First value of timelag_lead is NA
    # plot(table(samplingI), type="h", xlim=c(20,40),col=4, ylab="frequency", xlab="sampling interval [min]")
    
    xy_selected <- xy_selected[order(xy_selected$timestamp , decreasing = FALSE ),] 
    moveObj <- move(x=xy_selected$x, y=xy_selected$y, time=xy_selected$timestamp, proj=CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " ),animal=i)
    ##########################################################################################
    relUn <- 12 # relocation uncertainty [m]
    ##########################################################################################
    velocity <- unname(quantile(speed(moveObj), 0.99)) * 60 # unit: [m/min]
    hmin <- relUn + (0.5 * velocity * 30) # meters, smoothing
    iterator <- iterator+1
    
    
    traj <- as.ltraj(xy=xy_selected[,c("x", "y")], date=xy_selected$timestamp, id=i)
  
    ##########################################################################################
    tmax <- 70*60 # seconds, maximum time span for a segment
    lmin <- 12 # meters, minimal distance of a segment in order to count as movement
    tau <- 1*60 #seconds, approx. duration of one interpolated interval -> defines the number of intervals per step 
    extVal <- 15
    gridVal <- 2000
    hminRef <- hmin # computed through "BRB_leo_hmin computation.R"
    hminFactor <- c(0.6, 0.8, 1,1.2,1.4,  1.6, 1.8)
    ##########################################################################################
  
    vv <- BRB.D(traj, Tmax=tmax, Lmin=lmin) #estimate the diffusion coefficient
    for (l in seq(1:length(hminFactor))) {
      start_time <- Sys.time()
      hmin <- hminFactor[[l]]*hminRef
      if(xy_selected_toolessdata){# only execute when enough data
      UD <- BRB(traj, D=vv, Tmax=tmax, Lmin=lmin, hmin=hmin, b=T,  grid=grid, extent=extentfactor, filtershort=T, type="UD")

      tryCatch(
            expr = {
              hr95 <- getverticeshr(UD, percent=95, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr95_sf <- st_as_sf(hr95)
            },
            error = function(e){ 
              hr95 <- NA
              hr95_sf <- NA
              message()
              message(paste(i,hminFactor[[l]],n_gps,n_follows,samplinginterval,sep = " : "))
            }
        )
      tryCatch(
            expr = {
              hr99 <- getverticeshr(UD, percent=99, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr99_sf <- st_as_sf(hr99)
            },
            error = function(e){ 
              hr99 <- NA
              hr99_sf <- NA
              message()
              message(paste(i,hminFactor[[l]],n_gps,n_follows,samplinginterval,sep = " : "))
            }
        )
      tryCatch(
            expr = {
              hr50 <- getverticeshr(UD, percent=50, standardize=TRUE,unin = c("m"),unout = c("km2"))
              hr50_sf <- st_as_sf(hr50)
            },
            error = function(e){ 
              hr50 <- NA
              hr50_sf <- NA
              message(paste(i,hminFactor[[l]],n_gps,n_follows,samplinginterval," getting hr percentage polygon didn't work",sep = " : "))
            }
        )

      
      ########## save UD ##########
      brb_overlap_UD[[1+indexitter]] <- list(i,UD,"brb",hminFactor[[l]],n_gps,n_follows,samplinginterval)
      indexitter <- indexitter+1
      }
      
      end_time <- Sys.time()
      duration <- end_time-start_time
      
      ########## plots ##########
      hminTxt <- gsub(".", "_", as.character(hminFactor[[l]]), fixed=T)
      
      ########## export results ############
      if(xy_selected_toolessdata) {
        resultList_50 <-
          data.frame(
            focal = i,
            homerange = hr50$area,
            hrpercentage ="50%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr50_sf$geometry
          )
        resultList_95 <-
          data.frame(
            focal = i,
            homerange = hr95$area,
            hrpercentage ="95%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr95_sf$geometry
          )
        resultList_99 <-
          data.frame(
            focal = i,
            homerange = hr99$area,
            hrpercentage ="99%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=hr99_sf$geometry
          )
      }
      if (!xy_selected_toolessdata) {
                resultList_50 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="50%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
        resultList_95 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="95%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
        resultList_99 <-
          data.frame(
            focal = i,
            homerange = NA,
            hrpercentage ="99%",
            n_gps = n_gps,
            n_follows = n_follows,
            Velocity_percentile99 = velocity,
            GPSuncertainty = relUn,
            hmin = hmin,
            tmax = tmax,
            lmin = lmin,
            tau = tau,
            hminfac = hminFactor[[l]],
            hminRef = hminRef,
            period = names(period_list)[samplinginterval],
            processingtime = duration,
            geometry=NA
          )
      }
      brb_list <- brb_list %>% rbind(resultList_50,resultList_95,resultList_99)
      
      print(paste(hminTxt, ": Calculation finished", sep=""))
    }
  }
}

st_write(brb_list, dsn = paste(
  paste(
    imdir,
    "brb_values_allperiods",
    sep = ""
  ),
  "shp",
  sep = "."
))
system("say alle kernel distanzen berechnet für die verschiedenen Untersuchungsperioden")


```

```{r Homeranges overlaps: recalculate UD from KDE - HR per-researchperiods and all - HR sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# Filter research periods if only one of the periods should be calculated
# period_list <- period_list[1] # keep only the total research period

# createa directory for kde periods calculation (named by the current date)
dir.create(paste(
    "output/Homeranges/KDE/periods/",
    format(Sys.Date(), "%Y%m%d"),
    sep = ""
  ))
imdir <- paste("output/Homeranges/KDE/periods/",format(Sys.Date(), "%Y%m%d"), "/", sep="")

kde_results_perperiod <- data.frame() # results
kde_overlap_UD <- list() # only for tital research period activate filter above

for (samplinginterval in c(1:length(period_list))){
print(paste("kdes for period: ",samplinginterval))
##### Determine the smoothing parameters
selected_females <- period_list[[samplinginterval]] %>% group_by(focal) %>% summarise()
selected_females <- as_vector(selected_females)

bandwiths <-  data.frame(focal=as_vector(selected_females),
                 hpi=vector(mode="numeric", length=length(selected_females)),hbcv=vector(mode="numeric", length=length(selected_females)),hscv=vector(mode="numeric", length=length(selected_females)),
                 stringsAsFactors=FALSE)
iterator <- 1
indexitter <- 0
for (i in selected_females){
  print(paste("kdes for focal: ",i))
  xy_selected <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>% dplyr::select(E,N)
  colnames(xy_selected) <- c("x","y") #adjust column names
  hpi <- sqrt(prod(sqrt(diag(Hpi.diag(xy_selected[,1:2], nstage=2))))) # using diagonal bandwith not full bandwith? why?
  hbcv <- sqrt(prod(sqrt(diag(Hbcv.diag(xy_selected[,1:2], whichbcv=1)))))
  hscv <- sqrt(prod(sqrt(diag(Hscv.diag(xy_selected[,1:2], nstage=2)))))
  bandwiths[iterator,"focal"] <- i
  bandwiths[iterator,"hpi"] <- as.numeric(hpi)
  bandwiths[iterator,"hbcv"] <- as.numeric(hbcv)
  bandwiths[iterator,"hscv"] <- as.numeric(hscv)

  iterator <- iterator+1
}
rownames(bandwiths) <- c(1:length(selected_females))

### KDE: Calculate UD, HR
iterator <- 1
results_focal <- data.frame()
for (i in selected_females){ # compute KDE home range for every individual
  n_follows <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>% group_by(follow) %>% summarise() %>% nrow()
  xy_selected <- period_list[[samplinginterval]] %>% filter(focal%in%c(i)) %>% dplyr::select(E,N)
  n_gps <- xy_selected %>% nrow()
  
  colnames(xy_selected) <- c("x","y") #adjust column names
  resultList <- list()
  methListTitle <- list("REF", "PI", "BCV", "SCV")
  methList <- list("HREF", "HPI", "HBCV", "HSCV")
  
  xy_selected <- SpatialPoints(xy_selected,proj4string = CRS( "+proj=utm +zone=47 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs " )) # Converts SpatialPointDataFrame to SpatialPoint (only x & y)
  
  extVal <- 15 #0.3 How much bigger the UD should be calculated than the research are (minimum bounding box). The higher the more Computation
  gridVal <- 2000 #700 How much cells or pixels should be considered for UD calculation. The higher the more Computation

  for (j in seq(1, length(methList))) { # compute one home range for each bandwidth method and individual
    if (j == 1) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extVal, h="href"))
    }
    else if (j == 2) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extVal, h=bandwiths[iterator,"hpi"]))
    }
    else if (j == 3) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extVal, h=bandwiths[iterator,"hbcv"]))
    }
    else if (j == 4) {
      UD <- (kernelUD(xy_selected, grid=grid, extent=extVal, h=bandwiths[iterator,"hscv"])) 
    }
    else {
      print("Error")
    }
    hr99 <- getverticeshr(UD, percent=99,unin = c("m"),unout = c("km2"))
    hr95 <- getverticeshr(UD, percent=95,unin = c("m"),unout = c("km2"))
    hr50 <- getverticeshr(UD, percent=50,unin = c("m"),unout = c("km2"))

    hr99_sf <- st_as_sf(hr99)
    hr95_sf <- st_as_sf(hr95)
    hr50_sf <- st_as_sf(hr50)
    
    ########## save UD ##########
    kde_overlap_UD[[1+indexitter]] <- list(i,UD,"kde",methList[[j]],n_gps,n_follows,samplinginterval)
    indexitter <- indexitter+1

    
    results_selectedmethod <- data.frame(bandwithmethod=c(methList[[j]],methList[[j]],methList[[j]]),
            hrpercentage=c("50%","95%","99%"),
            area=c(hr50_sf$area,hr95_sf$area,hr99_sf$area),
            n_gps=c(n_gps,n_gps,n_gps),
            n_follows=c(n_follows,n_follows,n_follows),
            geometry=c(hr50_sf$geometry,hr95_sf$geometry,hr99_sf$geometry))

    results_selectedfocal<- results_selectedmethod %>% mutate(focal=selected_females[[iterator]])
    
    results_focal <- rbind(results_focal,results_selectedfocal)
  }

  

  print(paste(selected_females[[iterator]], ": Calculation finished", sep=""))
  iterator <- iterator+1
}
results_focal <- results_focal %>% mutate(period=names(period_list)[samplinginterval])
kde_results_perperiod <- kde_results_perperiod %>% rbind(results_focal)


}
st_write(kde_results_perperiod, dsn = paste(
  paste(imdir,
    "kde_values_allperiods",
    sep = ""
  ),
  "shp",
  sep = "."
))
system("say alle kernel distanzen berechnet für die verschiedenen Untersuchungsperioden")


```

(TODELETE)



# Visualizations
```{r Homerange - VISUALS - Estimators evaluation,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}


#### HRE evaluation KDE
kde_evaluation<- all_homeranges %>% dplyr::filter(algorithm=="kde") %>% dplyr::filter(period =="total research period")%>%   group_by(focal,hrprcnt,bndwthm) %>% 
  summarise(area=(mean(area,na.rm=TRUE)),
            Comp_holes=(mean(Comp_holes,na.rm=TRUE)),
            Comp_polycount=(mean(Comp_polycount,na.rm=TRUE)),
            Comp_compactness=(mean(Comp_compactness,na.rm=TRUE)),
            AUC=(mean(AUC,na.rm=TRUE))
)
kde_evaluation_temp <- kde_evaluation %>% ungroup() %>%  group_by(focal, hrprcnt) %>% summarise(bndwthm,area=area/max(as.numeric(area), na.rm = TRUE),Comp_holes=Comp_holes/max(as.numeric(Comp_holes), na.rm = TRUE),
            Comp_polycount=Comp_polycount/max(as.numeric(Comp_polycount), na.rm = TRUE),
            Comp_compactness=Comp_compactness/max(as.numeric(Comp_compactness), na.rm = TRUE),
            AUC=AUC,
)
colnames(kde_evaluation_temp) <- c("focal","hrprcnt","bndwthm","norm_area","norm_holes","norm_polygons","norm_compactness","norm_AUC")
kde_evaluation <- kde_evaluation %>% 
  left_join(kde_evaluation_temp,by=c("hrprcnt"="hrprcnt","focal"="focal","bndwthm"="bndwthm")) %>% dplyr::select(focal,hrprcnt,bndwthm, norm_area,norm_holes,norm_polygons,norm_compactness,norm_AUC)

kde_evaluation<- gather(kde_evaluation,"evaltype","norm_value",4:8)

plot_kdeeval<- kde_evaluation %>% ggplot(aes(focal, norm_value,color=as.factor(bndwthm)))+
  geom_point(shape= 1,position = position_dodge(width = 0.2),size=2)+
  facet_grid(evaltype~hrprcnt,labeller = labeller(evaltype=as_labeller(
     c(norm_AUC="AUC",norm_area="area",norm_compactness="compactness",norm_holes="holes",norm_polygons="polygons"))),scales="free")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 7))+
  labs(color=element_blank(), y="normalized values",x=element_blank())
plot_kdeeval
plot_kdeeval %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_kdeeval",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=150,width = 24,height = 12,units="cm")

#### HRE evaluation BRB
brb_evaluation<- all_homeranges %>% dplyr::filter(algorithm=="brb") %>% dplyr::filter(period =="total research period") %>%  group_by(focal,hrprcnt,hminfac) %>% 
  summarise(area=(mean(area,na.rm=TRUE)),
            Comp_holes=(mean(Comp_holes,na.rm=TRUE)),
            Comp_polycount=(mean(Comp_polycount,na.rm=TRUE)),
            Comp_compactness=(mean(Comp_compactness,na.rm=TRUE)),
            AUC=(mean(AUC,na.rm=TRUE))
)
brb_evaluation_temp<- brb_evaluation %>% ungroup() %>%  group_by(focal, hrprcnt) %>% summarise(hminfac,area=area/max(as.numeric(area), na.rm = TRUE),Comp_holes=Comp_holes/max(as.numeric(Comp_holes), na.rm = TRUE),
            Comp_polycount=Comp_polycount/max(as.numeric(Comp_polycount), na.rm = TRUE),
            Comp_compactness=Comp_compactness/max(as.numeric(Comp_compactness), na.rm = TRUE),
            AUC=AUC
)
colnames(brb_evaluation_temp) <- c("focal","hrprcnt","hminfac","norm_area","norm_holes","norm_polygons","norm_compactness","norm_AUC")
brb_evaluation <- brb_evaluation %>% 
  left_join(brb_evaluation_temp,by=c("hrprcnt"="hrprcnt","focal"="focal","hminfac"="hminfac")) %>% dplyr::select(focal,hrprcnt,hminfac, norm_area,norm_holes,norm_polygons,norm_compactness,norm_AUC)

brb_evaluation<- gather(brb_evaluation,"evaltype","norm_value",4:8)

plot_brbeval<- brb_evaluation %>% ggplot(aes(focal, norm_value,color=as.factor(hminfac)))+
  geom_point(shape= 1,position = position_dodge(width = 0.2),size=2)+
  facet_grid(evaltype~hrprcnt,labeller = labeller(evaltype=as_labeller(
     c(norm_AUC="AUC",norm_area="area",norm_compactness="compactness",norm_holes="holes",norm_polygons="polygons"))),scales="free")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 7))+
  labs(color=element_blank(), y="normalized values",x=element_blank())
plot_brbeval

plot_brbeval %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_brbeval",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=150,width = 24,height = 12,units="cm")

#### AKDE compare pooled and unpooled data
akde_evaluation<- all_homeranges %>% filter(algorithm =="akde")%>% dplyr::filter(period =="total research period") %>%  group_by(focal,hrprcnt,modelbase) %>% 
  summarise(area=(mean(area,na.rm=TRUE)),
            Comp_holes=(mean(Comp_holes,na.rm=TRUE)),
            Comp_polycount=(mean(Comp_polycount,na.rm=TRUE)),
            Comp_compactness=(mean(Comp_compactness,na.rm=TRUE)),
            AUC=(mean(AUC,na.rm=TRUE))
)
akde_evaluation_temp<- akde_evaluation %>% ungroup() %>%  group_by(focal, hrprcnt) %>% summarise(area=area/max(as.numeric(area), na.rm = TRUE),Comp_holes=Comp_holes/max(as.numeric(Comp_holes), na.rm = TRUE),
            Comp_polycount=Comp_polycount/max(as.numeric(Comp_polycount), na.rm = TRUE),
            Comp_compactness=Comp_compactness/max(as.numeric(Comp_compactness), na.rm = TRUE),
            AUC=AUC
)
colnames(akde_evaluation) <- c("focal","hrprcnt","modelbase","norm_area","norm_holes","norm_polygons","norm_compactness","norm_AUC")
akde_evaluation <- akde_evaluation %>% 
  left_join(akde_evaluation_temp,by=c("hrprcnt"="hrprcnt","focal"="focal")) %>% dplyr::select(focal,hrprcnt,modelbase, norm_area,norm_holes,norm_polygons,norm_compactness,norm_AUC)

akde_evaluation<- gather(akde_evaluation,"evaltype","norm_value",4:8)

plot_akdeeval<- akde_evaluation %>% ggplot(aes(focal,norm_value ,color=modelbase))+
  geom_point(shape= 1,position = position_dodge(width = 0.2),size=2)+
  facet_grid(evaltype~hrprcnt,labeller = labeller(evaltype=as_labeller(
     c(norm_AUC="AUC",norm_area="area",norm_compactness="compactness",norm_holes="holes",norm_polygons="polygons"))),scales="free")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 7))+
  labs(color=element_blank(), y="normalized values",x=element_blank())
plot_akdeeval
plot_akdeeval %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_akdeeval",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=150,width = 24,height = 12,units="cm")

#### Comparison of HRE
all_evaluation<- all_homeranges_selected %>% 
  filter(hrprcnt!="100%") %>% 
  #filter(algorithm!="akde") %>% 
  dplyr::filter(period =="total research period")%>% 
  group_by(focal,algorithm,hrprcnt) %>%
  summarise(area=(mean(area,na.rm=TRUE)),
            Comp_holes=(mean(Comp_holes,na.rm=TRUE)),
            Comp_polycount=(mean(Comp_polycount,na.rm=TRUE)),
            Comp_compactness=(mean(Comp_compactness,na.rm=TRUE)),
            AUC=(mean(AUC,na.rm=TRUE))
)
all_evaluation_temp<- all_evaluation %>% ungroup() %>%  
  group_by(focal, hrprcnt) %>% 
  summarise(algorithm,
            area=area/max(as.numeric(area), na.rm = TRUE),
            Comp_holes=Comp_holes/max(as.numeric(Comp_holes), na.rm = TRUE),
            Comp_polycount=Comp_polycount/max(as.numeric(Comp_polycount), na.rm = TRUE),
            Comp_compactness=Comp_compactness/max(as.numeric(Comp_compactness), na.rm = TRUE),
            AUC=AUC/max(as.numeric(AUC), na.rm = TRUE)
)
colnames(all_evaluation_temp) <- c("focal","hrprcnt","algorithm","norm_area","norm_holes","norm_polygons","norm_compactness","norm_AUC")
all_evaluation <- all_evaluation %>% 
  left_join(all_evaluation_temp,by=c("hrprcnt"="hrprcnt","focal"="focal","algorithm"="algorithm")) %>% dplyr::select(focal,hrprcnt,algorithm, norm_area,norm_holes,norm_polygons,norm_compactness,norm_AUC)

all_evaluation<- gather(all_evaluation,"evaltype","norm_value",4:8)

plot_alleval<- all_evaluation %>% ggplot(aes(focal, norm_value,color=algorithm))+
  geom_point(shape= 8,position = position_dodge(width = 0.2),size=2.5)+
  facet_grid(evaltype~hrprcnt,labeller = labeller(evaltype=as_labeller(
     c(norm_AUC="AUC",norm_area="area",norm_compactness="compactness",norm_holes="holes",norm_polygons="polygons"))),scales="free")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 7))+
  labs(color=element_blank(), y="normalized values",x=element_blank())
plot_alleval



plot_alleval %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_alleval_noakde",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=150,width = 24,height = 12,units="cm")

##### Quick statistcs HRE evaluation
hre_evaluation_brb<- all_evaluation[all_evaluation$algorithm=="brb",] %>% filter(hrprcnt=="95%")
hre_evaluation_kde<- all_evaluation[all_evaluation$algorithm=="kde",]%>% filter(hrprcnt=="95%")
hre_evaluation_akde<- all_evaluation[all_evaluation$algorithm=="akde",]%>% filter(hrprcnt=="95%")
hre_evaluation_mcp<- all_evaluation[all_evaluation$algorithm=="mcp",]%>% filter(hrprcnt=="95%")
all_evaluation$algorithm
all_evaluation_noakde <- all_evaluation %>% filter(algorithm!="akde")  %>% filter(hrprcnt=="50%") %>% filter(evaltype=="norm_area")
test<- kruskal.test(norm_value ~ algorithm,data=all_evaluation_noakde)
pairwise.t.test(all_evaluation_noakde$norm_value,all_evaluation_noakde$algorithm,p.adj="none")
autoplot(test)
test

```

```{r Homerange - VISUALS - STABILITY BOOTSTRAPPING sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# Homerange stability: BOOTSTRAPPING METHODS
### KDE temporal
kde_temporal_bootstrap_monthly<- read_csv("output/Homeranges/KDE/bootstrap/sampling/20210713/kde_temporal_bootstrap_monthly.csv")
kde_bootstrap_monthly_perfollow<- read_csv("output/Homeranges/KDE/bootstrap/sampling/20210714/kde_bootstrap_monthly_perfollow.csv")
kde_bootstrap_monthly_perfollow_HSCV<- read_csv("output/Homeranges/KDE/bootstrap/sampling/20210714/kde_bootstrap_monthly_perfollow_HSCV.csv")
kde_bootstrap_monthly_perfollow_HBCV<- read_csv("output/Homeranges/KDE/bootstrap/sampling/20210714/kde_bootstrap_monthly_perfollow_HBCV.csv")
kde_bootstrap_monthly_perfollow_HPI<- read_csv("output/Homeranges/KDE/bootstrap/sampling/20210714/kde_bootstrap_monthly_perfollow_HPI.csv")


### make less breaks x axis
period_vec<-kde_temporal_bootstrap_monthly %>% group_by(period) %>%summarise() %>%  pull(period) 
breaks_vec<-period_vec[seq(1, length(period_vec), 6)]

kde_temporal_bootstrap_monthly_ptsize <- kde_temporal_bootstrap_monthly %>% group_by(focal,n_gps) %>% summarise() %>% arrange(desc(n_gps)) %>% ungroup()
kde_temporal_bootstrap_monthly_ptsize<- kde_temporal_bootstrap_monthly_ptsize%>%  group_by(focal) %>%
  top_n(n = 1)%>% rename(n_gps_total=n_gps)
kde_temporal_bootstrap_monthly <- kde_temporal_bootstrap_monthly  %>% 
  #left_join(kde_temporal_bootstrap_monthly_ptsize, by=c("focal"="focal")) %>% 
  mutate(relativeamount=n_gps/n_gps_tot)

plot_kde_temporal_bootstrap_monthly<- kde_temporal_bootstrap_monthly %>% 
  ggplot(aes(period,area,colour=hrpercentage)) + geom_point(aes(size=relativeamount))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 7))+
  facet_grid(focal  ~   bandwithmethod)+
  scale_x_discrete(breaks=breaks_vec)+
  scale_colour_manual(values = c("50%" = "#1b9e77", "95%" = "#d95f02", "99%" = "#7570b3"))+
  scale_size_continuous(range = c(0.1, 1.5))+
  labs(size="amount of data",colour="range delineation")
plot_kde_temporal_bootstrap_monthly
plot_kde_temporal_bootstrap_monthly %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_kde_temporal_bootstrap_monthly_withamountofdata",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=600,width = 21,height = 29.7,units="cm")

### KDE temporal double bootstrapping
kde_temporal_bootstrap_monthly <- read_csv("output/Homeranges/KDE/bootstrap/sampling/20210713_iteratedbootstrap/kde_bootstrap_monthly_iterated.csv")
colnames(kde_temporal_bootstrap_monthly) <- c("focal","percentagedata","homerange","iteration","hrpercentage","algorithm")

kde_temporal_bootstrap_monthly <- kde_temporal_bootstrap_monthly %>% mutate(algorithm = "KDE HSCV",percentagedata=percentagedata/100) %>% left_join(temp_ndata, by=c("focal"="focal","hrpercentage"="hrpercentage","percentagedata"="percentagedata"))
kde_temporal_bootstrap_monthly <- kde_temporal_bootstrap_monthly %>% mutate(n_follows_tot=ifelse(focal=="tiara",10,n_follows_tot)) %>%  mutate(title=as.factor(paste0(focal," (n: ",n_follows_tot,")")))

plot_kde_bootstrap_monthly<- kde_temporal_bootstrap_monthly %>% 
  ggplot(aes(n_follows,homerange,colour=hrpercentage,group=hrpercentage)) + geom_jitter(alpha=0.2)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 7))+
  facet_wrap(.~ title ,ncol=6,nrow=2,scales="free")+
  labs(colour=element_blank(),x="number of follows", y= expression("area [km"^2*"]"))+
  #geom_smooth(level=0.95,se=TRUE)+
  expand_limits(y = 0)
plot_kde_bootstrap_monthly
plot_kde_bootstrap_monthly %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_kde_iterated_bootstrap_HSCV_perPoint2",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=600,width = 29.7,height = 21,units="cm")


### BRB
brb_bootstrap_monthly<- read_csv("output/Homeranges/BRB/bootstrap/sampling/20210712/brb_list_bootstrap.csv")

### make less breaks x axis
period_vec<-brb_bootstrap_monthly %>% group_by(percentagedata) %>%summarise() %>%  pull(percentagedata) 
breaks_vec<-period_vec[seq(1, length(period_vec), 6)]

brb_temporal_bootstrap_monthly_ptsize <- brb_bootstrap_monthly %>% group_by(focal,n_gps) %>% summarise() %>% arrange(desc(n_gps)) %>% ungroup()
brb_temporal_bootstrap_monthly_ptsize<- brb_temporal_bootstrap_monthly_ptsize%>%  group_by(focal) %>%
  top_n(n = 1)%>% rename(n_gps_tot=n_gps)
brb_bootstrap_monthly <- brb_bootstrap_monthly  %>% 
  left_join(brb_temporal_bootstrap_monthly_ptsize, by=c("focal"="focal")) %>% 
  mutate(relativeamount=n_gps/n_gps_tot)

# quick explanation the case that sometimes the percentage of data subsampled is higher but the amount of data is lesser than another with a lower subsampling percentage, is due to the fact that I subsampled percentage of follows from the WHOLE dataset. Not only from one individual. Therefore sometimes a lot of follows of one individual are included an sometimes less. Whats better? depends because subsampling the whole dataset would more adjusting for sampling differences or so.
plot_brb_bootstrap_monthly<- brb_bootstrap_monthly %>% 
  filter(hminfac==0.8) %>%
  arrange(desc(relativeamount)) %>% 
  ggplot(aes(relativeamount,homerange,colour=focal)) + geom_jitter(aes(size=n_gps_tot,shape=as.factor(hminfac)))+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 10))+
  scale_fill_viridis()+
  #scale_x_discrete(breaks=breaks_vec)+
  #scale_colour_manual(values = c("50%" = "#1b9e77", "95%" = "#d95f02", "99%" = "#7570b3"))+
  scale_size_continuous(range = c(0.6, 7))+
  labs(y=expression("area [km"^2*"]"),title = "BRB homeranges per subset of dataset", x= "percentage of data",color="Orangutan",size="Total GPS per focal",shape="Variation of hmin parametrization")
  #geom_path()
plot_brb_bootstrap_monthly
plot_brb_bootstrap_monthly %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_brb_sampling_bootstrap_monthly_95all_hminparametrization",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=600,width = 29.7,height = 21,units="cm")



### MCP bootstrapping per point
mcp_bootstrap_monthly<- read_csv("output/Homeranges/MCP/bootstrap/sampling/20210712/mcp_list_bootstrap.csv")


plot_mcp_bootstrap_monthly<- mcp_bootstrap_monthly %>% 
  ggplot(aes(n_gps ,area,colour=focal)) + geom_jitter()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 10))+
  scale_fill_viridis()+
  #scale_x_discrete(breaks=breaks_vec)+
  #scale_colour_manual(values = c("50%" = "#1b9e77", "95%" = "#d95f02", "99%" = "#7570b3"))+
  scale_size_continuous(range = c(0.6, 7))+
  labs(y=expression("area [km"^2*"]"),title = "MCP homeranges per subset of dataset", x= "percentage of data",color="Orangutan",size="Total GPS per focal")+
  facet_wrap(.~hrpercentage,nrow = 3,scales = "free")+
  geom_smooth(se = FALSE)
  #geom_path()
plot_mcp_bootstrap_monthly
ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_mcp_bootstrap_monthly",
    sep = ""
  ),
  "pdf",
  sep = "."
), plot = plot_mcp_bootstrap_monthly, width = 24,height = 15,units="cm")

### MCP bootstrapping per follow
mcp_bootstrap_monthly_perfollow<- read_csv("output/Homeranges/MCP/bootstrap/sampling/20210714/mcp_list_bootstrap_percfollow_01.csv")
plot_mcp_bootstrap_perfollow<- mcp_bootstrap_monthly_perfollow %>% 
  ggplot(aes(n_follows ,area,colour=focal)) + geom_jitter()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 10))+
  scale_fill_viridis()+
  #scale_x_discrete(breaks=breaks_vec)+
  #scale_colour_manual(values = c("50%" = "#1b9e77", "95%" = "#d95f02", "99%" = "#7570b3"))+
  scale_size_continuous(range = c(0.6, 7))+
  labs(y=expression("area [km"^2*"]"),title = "MCP homeranges per subset of dataset", x= "n follows")+
  facet_wrap(.~hrpercentage,nrow = 3,scales = "free")+
  geom_smooth(se = FALSE)
  #geom_path()
plot_mcp_bootstrap_perfollow
ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_mcp_bootstrap_perfollow_perpercent",
    sep = ""
  ),
  "pdf",
  sep = "."
), plot = plot_mcp_bootstrap_perfollow, width = 24,height = 15,units="cm")

### Combining all estimators
kde_bootstrap_monthly_perfollow_HSCV<- read_csv("output/Homeranges/KDE/bootstrap/sampling/20210716/kde_bootstrap_monthly_perfollow_HSCV.csv")
mcp_bootstrap_monthly_perfollow<- read_csv("output/Homeranges/MCP/bootstrap/sampling/20210716/mcp_list_bootstrap_percfollow.csv")
brb_bootstrap_monthly_perfollow<- read_csv("output/Homeranges/BRB/bootstrap/sampling/20210716/brb_list_bootstrap_perfollow.csv")


colnames(kde_bootstrap_monthly_perfollow_HSCV) <- c("focal","percentagedata","homerange","iteration","hrpercentage","algorithm")
brb_bootstrap_monthly_perfollow <- brb_bootstrap_monthly_perfollow %>% mutate(algorithm = "BRB hmin factor 0.8") %>% left_join(specs_orangutan_tot_num_of_gps,by=c("focal"="focal")) 
colnames(mcp_bootstrap_monthly_perfollow)[colnames(mcp_bootstrap_monthly_perfollow) == 'percentagedate'] <- 'percentagedata'
colnames(brb_bootstrap_monthly_perfollow)[colnames(brb_bootstrap_monthly_perfollow) == 'homerange'] <- 'area'
colnames(kde_bootstrap_monthly_perfollow_HSCV)[colnames(kde_bootstrap_monthly_perfollow_HSCV) == 'homerange'] <- 'area'
temp_ndata<- mcp_bootstrap_monthly_perfollow[,c(1,3:7)] %>% group_by(focal) %>% mutate(n_follows_tot=max(n_follows)) %>% ungroup()

kde_bootstrap_monthly_perfollow_HSCV <- kde_bootstrap_monthly_perfollow_HSCV %>% mutate(algorithm = "KDE HSCV",percentagedata=percentagedata/100) %>% left_join(temp_ndata, by=c("focal"="focal","hrpercentage"="hrpercentage","percentagedata"="percentagedata"))
mcp_bootstrap_monthly_perfollow <- mcp_bootstrap_monthly_perfollow %>% mutate(algorithm = "MCP")

all_bootstrapped<- brb_bootstrap_monthly_perfollow %>% bind_rows(kde_bootstrap_monthly_perfollow_HSCV)%>% bind_rows(mcp_bootstrap_monthly_perfollow)

plot_brb_temporal_bootstrap_monthly<- all_bootstrapped %>% 
  filter(hrpercentage!="99%") %>% 
  arrange(desc(n_follows)) %>% 
  ggplot(aes(n_follows,area,colour=focal)) + 
  geom_point(size=0.5,alpha=0.4)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 10))+
  scale_fill_viridis()+
  geom_smooth(se = FALSE)+
  #scale_x_discrete(breaks=breaks_vec)+
  #scale_colour_manual(values = c("50%" = "#1b9e77", "95%" = "#d95f02", "99%" = "#7570b3"))+
  scale_size_continuous(range = c(0.6, 7))+
  labs(y=expression("area [km"^2*"]"),x= "number of follows",color="Orangutan")+
  facet_grid(hrpercentage~ algorithm,scale="free_y")
  #geom_path()
plot_brb_temporal_bootstrap_monthly
plot_brb_temporal_bootstrap_monthly %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_brb_sampling_bootstrap_monthly_95all_hminparametrization",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=600,width = 29.7,height = 21,units="cm")
```

```{r Homeranges - VISUALS ANALYSIS fruittrees + specs HR ratio ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
### Finding: In core areas the number of trees increase linear with area in 95% area it increases faster but then flattens
all_homeranges_sf  %>%  ggplot(aes(area,number_of_trees,color=algorithm)) +geom_point()
all_homeranges_sf %>% ggplot(aes(area,fruittree_normalized,color=hrprcnt)) + geom_point()

### Fruittreeindex
all_homeranges_sf %>%
  #filter(algorithm=="brb") %>% 
  #filter(hminfac==1) %>%  
  ggplot(aes(focal,fruittree_normalized))+
  geom_jitter(aes(color=hrprcnt),size=3)+
  geom_smooth()+
  labs(x="focal",y=expression("normalized trees [tree/tot gps effort]"),color="HR [%]") +
  scale_fill_viridis()

### Fruittreeindex
fruittrees_brb_08<- all_homeranges_sf %>%filter(algorithm=="brb") %>% filter(period=="total research period") %>% 
  filter(hminfac==0.8) %>%  
  ggplot(aes(focal,fruittree_normalized))+
  geom_jitter(aes(color=hrprcnt),size=3,shape=8,width=0,height = 0.001)+
  geom_smooth()+
  labs(x="focal",y=expression("normalized trees [tree/tot gps effort]"),color="HR [%]") +
  scale_fill_viridis()
fruittrees_brb_08
fruittrees_brb_08 %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "fruittrees_brb_08",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=150,width = 12.5,height = 10,units="cm")

##### Home range ratio to core range
test<- all_homeranges[(all_homeranges$hrprcnt=="100%"),] %>% filter(period=="total research period")
sd(test$area)
temp_hrtoadd<- all_homeranges_95[,c(1,3,7:9,16,28)] %>% rename("area_95"="area")

specs_homeranges <- all_homeranges_50 %>% ungroup() %>% 
  left_join(temp_hrtoadd,by=c("period"="period","focal"="focal","algorithm"="algorithm","bndwthm"="bndwthm","hminfac"="hminfac")) %>% 
  mutate(hr_to_core_ratio_area=area/area_95,hr_to_core_ratio_fruittree=fruittree_normalized.x/fruittree_normalized.y)
specs_homeranges <- specs_homeranges %>% 
  group_by(focal,algorithm,period) %>% summarise(mean_hr_to_core_ratio_area=mean(hr_to_core_ratio_area,na.rm=TRUE),fruittree_core_normalized=mean(fruittree_normalized.x,na.rm=TRUE),fruittree_full_normalized=mean(fruittree_normalized.y,na.rm=TRUE))
specs_homeranges$period <- factor(specs_homeranges$period, levels = c("before 2012", "2012 until 2016", "left", "2016 until August 2018", "Since August 2018","total research period"))

plot_specsratio_homeranges <- specs_homeranges %>% 
  ggplot(aes(focal,mean_hr_to_core_ratio_area,color=focal))+
  geom_boxplot()+
  geom_point(aes(y=fruittree_core_normalized),color="IndianRed")+
  geom_point(aes(y=fruittree_full_normalized),color="cadetblue2")+
  facet_wrap(.~period)+
  theme(legend.position = "none")+
  scale_y_continuous(
    "home range (HR) to core range (CR) ratio", 
    sec.axis = sec_axis(~ .*3, name = "ratio of normalized fruittrees (CR/HR)")
  )
plot_specsratio_homeranges
plot_specsratio_homeranges %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_specsratio_homeranges_fruittree",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=600,width = 29.7,height = 21,units="cm")

#### Is there a significant difference between HR ratio
specs_HRtoCR_ratio_perfocal<-specs_homeranges %>% 
  filter(period!="total research period") %>% 
  filter(algorithm=="brb")
lmm_hrRatio <- lmer(mean_hr_to_core_ratio_area ~ focal+(1|period),data=specs_HRtoCR_ratio_perfocal)
lmm_hrRatio <- pairwise.t.test(specs_HRtoCR_ratio_perfocal$mean_hr_to_core_ratio_area,specs_HRtoCR_ratio_perfocal$focal)
lmm_hrRatio

summary(lmm_hrRatio)

```

```{r Overlaps - VISUALS ANALYSIS fruittrees ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
### Finding: In core areas the number of trees increase linear with area in 95% area it increases faster but then flattens
all_overlaps  %>%  ggplot(aes(overlap,overlap_HRshared,color=overlap)) +geom_point()
all_homeranges_sf %>% ggplot(aes(area,fruittree_normalized,color=hrprcnt)) + geom_point()
all_overlaps%>% filter() GGally::ggpairs(echo=FALSE, message=FALSE)

### Fruittreeindex
fruittreeindex_inoverlaps<- all_overlaps %>%
  #filter(algorithm=="brb") %>% 
  #filter(hminfac==1) %>%  
  ggplot(aes(overlap,fruittree_normalized))+
  geom_point(aes(color=hrprcnt),size=3)+
  geom_point(data=all_homeranges_sf,aes(area,fruittree_normalized),alpha=0.2)+
  labs(x="overlap or area",y=expression("normalized trees [tree/tot gps effort]"),color="HR [%]") +
  scale_fill_viridis()+
  scale_x_log10()
fruittreeindex_inoverlaps

### Range sharing
test <- all_overlaps_sf %>%
  mutate(period = fct_relevel(period, 
            "before 2012", "2012 until 2016", "2016 until August 2018", 
            "Since August 2018", "total research period")) %>%
  #filter(algorithm=="brb") %>% 
  filter(hminfac%in%c(0.8,NA)) %>% # filter only brb with 1 --> reduce redundancy
  filter(bndwthm%in%c("HBCV",NA)) %>% # filter only kde with hbcv method
  filter(modelbase%in%c("pooled",NA)) %>% 
  filter(algorithm=="brb")

range_sharing<- all_overlaps_sf %>%
  mutate(period = fct_relevel(period, 
            "before 2012", "2012 until 2016", "2016 until August 2018", 
            "Since August 2018", "total research period")) %>%
  #filter(algorithm=="brb") %>% 
  filter(hminfac%in%c(0.8,NA)) %>% # filter only brb with 1 --> reduce redundancy
  filter(bndwthm%in%c("HBCV",NA)) %>% # filter only kde with hbcv method
  filter(modelbase%in%c("pooled",NA)) %>% # filter only ctmm with pooled method
  ggplot(aes(area_shared,algorithm))+
  geom_point(aes(color=hrprcnt,alpha=0.3),size=4)+
  labs(x="area shared",y=element_blank(),color="HR [%]") +
  scale_fill_viridis()+
  scale_x_log10()+
  facet_grid(period ~ focal)
range_sharing
range_sharing %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "range_sharing",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=150,width = 29.7,height = 21,units="cm")

### Range volume shared
range_sharing<- all_overlaps_sf %>%
  mutate(period = fct_relevel(period, 
            "before 2012", "2012 until 2016", "2016 until August 2018", 
            "Since August 2018", "total research period")) %>%
  filter(algorithm=="kde") %>% 
  filter(period=="total research period") %>% 
  filter(hminfac%in%c(0.8,NA)) %>% # filter only brb with 1 --> reduce redundancy
  filter(bndwthm%in%c("HBCV",NA)) %>% # filter only kde with hbcv method
  filter(modelbase%in%c("pooled",NA)) %>% # filter only ctmm with pooled method
  ggplot(aes(overlap_VI,period))+
  geom_point(aes(color=hrprcnt,alpha=0.3),size=4)+
  labs(x="Utilization Distribution Overlap Index",y=element_blank(),color="HR [%]") +
  scale_fill_viridis()+
  facet_grid(focal.1 ~ focal)+
  theme(legend.position = "none")+
  geom_rect(data = subset(all_overlaps_sf, 
                          focal %in% c("cissy","cissy","cissy","lilly","lilly","lilly","lisa","lisa","lisa","sarabi","sarabi","sarabi") & 
                          focal.1 %in% c("lilly","lisa","sarabi","cissy","lisa","sarabi","cissy","lilly","sarabi","cissy","lilly","lisa")), 
                          colour = "LightSkyBlue",aes(xmin =-Inf, xmax = Inf, ymin = -Inf, ymax = Inf,alpha=0.01),fill=NA,
             inherit.aes = FALSE,size=1)+
  geom_rect(data = subset(all_overlaps_sf, 
                          focal %in% c("ellie","ellie","ellie","friska","friska","friska","raffi","raffi","raffi","yulia","yulia","yulia") & 
                          focal.1 %in% c("friska","raffi","yulia","ellie","raffi","yulia","ellie","friska","yulia","ellie","friska","raffi")), 
                          colour = "IndianRed",aes(xmin =-Inf, xmax = Inf, ymin = -Inf, ymax = Inf,alpha=0.01),size=0.8,fill=NA,
             inherit.aes = FALSE)
range_sharing
g <- ggplot_gtable(ggplot_build(range_sharing))
strip_both <- which(grepl('strip-', g$layout$name))
fills <- c("deepskyblue2","IndianRed","IndianRed","deepskyblue2","deepskyblue2","IndianRed","deepskyblue2","Gainsboro","Gainsboro","IndianRed","deepskyblue2","IndianRed","IndianRed","deepskyblue2","deepskyblue2","IndianRed","deepskyblue2","Gainsboro","Gainsboro","IndianRed")
k <- 1
for (i in strip_both) {
j <- which(grepl('rect', g$grobs[[i]]$grobs[[1]]$childrenOrder))
g$grobs[[i]]$grobs[[1]]$children[[j]]$gp$fill <- fills[k]
k <- k+1
}
grid.draw(g) # have to be called in console

range_sharing %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "range_sharing",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=150,width = 29.7,height = 21,units="cm")


#### Overlap as boxplots

range_sharing_perfocal<- all_overlaps_sf %>%
  mutate(period = fct_relevel(period, 
            "before 2012", "2012 until 2016", "2016 until August 2018", 
            "Since August 2018", "total research period")) %>%
  
  filter(algorithm=="kde") %>% 
  filter(period=="total research period") %>% 
  filter(hminfac%in%c(0.8,NA)) %>% # filter only brb with 1 --> reduce redundancy
  filter(bndwthm%in%c("HBCV",NA)) %>% # filter only kde with hbcv method
  filter(modelbase%in%c("pooled",NA)) %>% # filter only ctmm with pooled method
  left_join(temp_matriline,by=c("focal"="focal")) %>% 
  left_join(temp_matriline,by=c("focal.1"="focal")) %>% 
  mutate(related=ifelse(matriline.x==matriline.y,"related","unrelated")) %>% 
  filter(!is.na(related))
range_sharing_perfocal<- range_sharing_perfocal %>%
  ggplot(aes(x=overlap_UDOI,y=related,fill=related))+
  geom_boxplot(size=1)+
  facet_grid(focal ~ .)+
  #theme(axis.title.y=element_blank(),
        #axis.text.y=element_blank(),
        #axis.ticks.y=element_blank())+
  labs(x="UDOI")+
  theme(legend.position = "none")
range_sharing_perfocal

range_sharing_perfocal %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "range_sharing_perfocal",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=150,width = 29.7,height = 21,units="cm")



### Testing make overlap dynamics visible
share_overlaps <- all_overlaps %>% 
  filter(hrprcnt%in%c("95%")) %>% 
  filter(algorithm%in%c("brb")) %>% 
  filter(period%in%c("total research period")) %>% 
  dplyr::select(focal,focal.1,value=overlap_HRshared)%>% 
  mutate(result="overlaps")

# Package
library(networkD3)
all_overlaps_50_naomit <- all_overlaps_95%>% filter(algorithm=="brb") %>% filter(period=="total research period") %>%  
dplyr::select(n_fllws,overlap_relative,focal,focal.1,related,algorithm) %>% na.omit() %>% ungroup()

# I need a long format
data_long<- all_overlaps_50_naomit  %>%  dplyr::select(focal,focal.1,overlap_relative,related)
colnames(data_long) <- c("source", "target", "value","related")
data_long$source <- factor(data_long$source, levels = c("cissy","lilly","lisa","sarabi","ellie","friska","raffi","yulia","tiara","trident"))
data_long$target <- factor(data_long$target, levels = c("cissy","lilly","lisa","sarabi","ellie","friska","raffi","yulia","tiara","trident"))
data_long$target <- paste(data_long$target, " ", sep="")

# From these flows we need to create a node data frame: it lists every entities involved in the flow
nodes <- data.frame(name=c(as.character(data_long$source), as.character(data_long$target)) %>% unique())

# With networkD3, connection must be provided using id, not using real name like in the links dataframe.. So we need to reformat it.

data_long$IDsource=match(data_long$source, nodes$name)-1 
data_long$IDtarget=match(data_long$target, nodes$name)-1


nodes$group <- as.factor(c("2","2","1","1","2","1","3","3","2","1","1","2","2","1","1","2","1","3","3","2"))
nodes$group <- as.factor(c("2","2","1","1","2","1","3","3","2","1"))

 
# Give a color for each group:
# Add a 'group' column to each connection:
data_long$group <-  as.factor(data_long$related)
 
# Give a color for each group:
my_color <- 'd3.scaleOrdinal() .domain(["1", "2", "3","TRUE","FALSE"]) .range(["#69b3a2", "steelblue", "grey","green","darkred"])'
 
# Make the Network
sankey<- sankeyNetwork(Links = data_long, Nodes = nodes, Source = "IDsource", Target = "IDtarget", 
                   Value = "value", NodeID = "name", 
                   colourScale=my_color, LinkGroup="group", NodeGroup="group",nodeWidth=40, fontSize=17,fontFamily="Arial", nodePadding=20)


# render with js
sankey_rendered <- htmlwidgets::onRender(sankey,
  'function(el, x) {
    d3.selectAll(".node text")
        .style("fill", "white");
  }'
)

sankey_rendered


### Chord diagram
all_overlaps_95$focal <- factor(all_overlaps_95$focal,levels = c("cissy", "lisa", "lilly", "sarabi", "ellie", "friska", "raffi", "yulia", "tiara","trident"))
all_overlaps_95$focal.1 <- factor(all_overlaps_95$focal.1,levels = c("cissy", "lisa", "lilly", "sarabi", "ellie", "friska", "raffi", "yulia", "tiara","trident"))
all_overlaps_50_naomit <- all_overlaps_95 %>% filter(algorithm=="brb") %>% filter(period=="total research period") %>%  dplyr::select(overlap_HRshared,focal,focal.1) %>% na.omit() %>% ungroup() %>% spread(key=focal,value = overlap_HRshared)
rownames(all_overlaps_50_naomit) <- all_overlaps_50_naomit$focal.1
all_overlaps_50_naomit <- all_overlaps_50_naomit[,2:11]
m <- as.matrix(all_overlaps_50_naomit)

colors <- all_overlaps_95 %>% filter(algorithm=="brb") %>% filter(period=="total research period") %>%  
dplyr::select(related,focal,focal.1)  %>% ungroup() %>% spread(key=focal,value = related)
rownames(all_overlaps_50_naomit) <- all_overlaps_50_naomit$focal.1
colors <- colors[,2:11]
colors <- as.matrix(colors)
colors[colors ==TRUE] <- "lightgreen"
colors[colors ==FALSE] <- "lightpink"

## For age or 
# colors[is.na(colors)] <- "mistyrose2"
# colors[colors ==0] <- "lightgoldenrod1"
# colors[colors ==1] <- "lightgoldenrod2"
# colors[colors ==2] <- "lightgoldenrod3"
# colors[colors ==3] <- "lightgoldenrod4"
# colors[colors ==4] <- "red"



# A vector of 4 colors for 4 groups
chordDiagram(m, grid.col = c("darkslategray3", "darkslategray3", "darkslategray3","darkslategray3", "salmon2", "salmon2", "salmon2","salmon2","grey","grey"),col=colors)

# save the widget
# library(htmlwidgets)
# saveWidget(p, file=paste0( getwd(), "/HtmlWidget/chord_interactive.html"))


### Visualize Overlaps per period compared to each other
temp_trees<- SUAQ_rangepoints_11all20_loc[SUAQ_rangepoints_11all20_loc$PtType=="tree",] %>% st_as_sf(coords = c("E","N"),crs = 23867)
all_overlaps_50_sf$period <- factor(all_overlaps_50_sf$period, levels = c("before 2012", "2012 until 2016", "left", "2016 until August 2018", "Since August 2018","total research period"))
cr<- all_overlaps_50_sf %>% filter(period=="total research period") %>% 
  #filter(focal%in%c("cissy","lisa","ellie","friska")) %>% 
  filter(algorithm=="brb") %>% 
  ggplot()+geom_sf(aes(colour=focal,fill="grey",alpha=0.01),alpha=0.03)+facet_wrap(.~period)+
  geom_sf(data=temp_trees,size=0.1)+
  ggtitle("Home ranges (BRB hmin factor 0.8)")
cr
cr %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "cr_brb_08_totalperiod",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=600,width = 29.7,height = 21,units="cm")


```

```{r Homerange - VISUALS - HR sizes,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
#### Homerange sizes overview
temp_HRallperiods<- all_homeranges_sf_selected[all_homeranges_sf_selected$hrprcnt=="50%",] %>% filter(period!="total research period") 
plot_all50_area_perfemale<- all_homeranges_sf_selected %>% 
  filter(hrprcnt=="50%") %>% 
  filter(period=="total research period") %>% 
  mutate(focal_name=paste0(focal," (n=",n_fllws,")")) %>% 
  ggplot( aes(x=focal, y=area, colour=algorithm)) +
    geom_point(size=3, alpha=1) +
    geom_boxplot(data=temp_HRallperiods,mapping=aes(x=focal, y=area),color = "black",width=0.3,alpha=0.1)+
    scale_fill_viridis(discrete = TRUE) +
    #geom_jitter(color="black", size=0.4, alpha=0.3) +
    theme_ipsum() +
    theme(
      #legend.position="none",
      plot.title = element_text(size=18),
      axis.title.x = element_blank()
    ) +
    ggtitle(expression("core range areas"^"50%"*"")) +
    ylab(expression("area [km"^2*"]"))+
  labs(colour=expression("algorithm"^"total period"*""),alpha="all periods boxplot")
plot_all50_area_perfemale


plot_all50_area_perfemale %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_50range_BRB_KDE_MCP_area_totalperiod_perfemale",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=150,units="cm")

#### Table of home ranges and their correspondent parametrization
table_HR50 <- all_homeranges_50 %>% dplyr::select(focal,n_fllws,hrprcnt,algorithm,bndwthm,tmax,tau,lmin,model,modeltype,hminRef,area,dominance,agecat,matriline,)





overview<- overview_homerange50 %>% 
  rbind(overview_homerange95) %>% 
  rbind(overview_overlaps_related) %>% 
  rbind(overview_overlaps_unrelated) %>% 
  rbind(overview_djl) %>% 
  rbind(overview_RR) %>% 
  rbind(overview_SIN) %>% 
  left_join(specs_orangutan_tot_num_of_gps_NN,by=c("focal"="focal"))

overview$result <- factor(overview$result,c( 
            "DJL [m]" ,"SI [0-1]","SIN [0-1]","home range: BRB 95% [km^2]","home range: BRB 50% [km^2]","average overlaps related [UDOI]","average overlaps unrelated [UDOI]"))
p_overview <- overview %>%
  #filter(focal%in%c("cissy","lisa","friska","ellie")) %>% 
  group_by(result) %>%
  mutate(color_value=normalize(value)) %>% ungroup() %>% 
  mutate(focal=as.factor(paste0(focal," (n = ",n_follows,")"))) %>% 
  ggplot( aes(x=focal, y=value,fill=color_value)) +
  geom_bar(stat = "identity")+
  scale_fill_viridis(discrete = FALSE, alpha=1,option="rocket") +
    theme_ipsum()+
  theme(
      legend.position="none",
      plot.title = element_text(size=18),
      axis.title.x = element_blank()
    ) +
  facet_wrap(.~result,nrow=7,scale="free")
p_overview

ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),
    "_plot_overview_focal_all",
    sep = ""
  ),
  "png",
  sep = "."
), plot = p_overview,width = 30,height =40,units="cm")

#### Analyze ??: distribution of weather?
plot_anypoints <- SUAQ_waypoints_11all20_loc[order(SUAQ_waypoints_11all20_loc$manualDatetime , decreasing = FALSE ),] %>%
  filter(PtType=="nightnest") %>% 
  filter(SUAQ_weather.temperature_min_evening>0) %>% 
  group_by(follow) %>%
  ggplot()+
  geom_point(aes(E,N,color=log10(SUAQ_weather.temperature_min_evening)),size=2.5)+
  #geom_path(aes(E,N), alpha = 0.7,size=0.5)+
  geom_sf(data = SUAQ_pathnetwork_sf_loc,
                                               aes(colour = "black", alpha = 1),
                                               fill = NA,colour = "black")
  
ggplotly(plot_anypoints)

#### Analyze edges: Missing Homeranges?
SUAQ_waypoints_11all20_loc_lost <- SUAQ_waypoints_11all20_loc %>% filter(PtType%in%c("lost"))
SUAQ_waypoints_11all20_loc_lost

plot_lostpoints<-SUAQ_waypoints_11all20_loc_lost[order(SUAQ_waypoints_11all20_loc_lost$manualDatetime , decreasing = FALSE ),] %>%
  group_by(follow) %>%
  filter(focal%in%c(selected_females)) %>% 
  ggplot()+
  #geom_point(data=SUAQ_waypoints_11all20_loc[order(SUAQ_waypoints_11all20_loc$manualDatetime , decreasing = FALSE ),], aes(E,N),size=0.2,fill="azure4",color="azure4",alpha=0.3)+
  geom_point(aes(E,N,color=focal),size=0.8)+
  geom_text(aes(E,N+40,label=focal,color=focal),size=3.5)+
  #geom_path(aes(E,N), alpha = 0.7,size=0.5)+
  geom_sf(data = SUAQ_pathnetwork_sf_loc,
                                               aes(colour = "black", alpha = 1),
                                               fill = NA,colour = "black")
  
ggplotly(plot_lostpoints)

#### Analyze weather: distribution of weather?
plot_weatherpoints<-SUAQ_waypoints_11all20_loc[order(SUAQ_waypoints_11all20_loc$manualDatetime , decreasing = FALSE ),] %>%
  filter(SUAQ_weather.rainfall_ml_evening!=0) %>% 
  #filter(PtType=="mornnest") %>% 
  group_by(follow) %>%
  ggplot()+
  geom_point(aes(E,N,color=log10(SUAQ_weather.rainfall_ml_evening)),size=1)+
  #geom_path(aes(E,N), alpha = 0.7,size=0.5)+
  geom_sf(data = SUAQ_pathnetwork_sf_loc,
                                               aes(colour = "black", alpha = 1),
                                               fill = NA,colour = "black")
  
ggplotly(plot_weatherpoints)

#### BRB: Find most recent folder
mostrecent <- list.dirs(path = "output/Homeranges/KDE/periods/", full.names = FALSE, recursive = FALSE)
mostrecent <- as.data.frame(mostrecent)
colnames(mostrecent) <- c("date")
mostrecent <- mostrecent %>% filter(date!="_archive") %>%  arrange(desc(date)) %>% top_n(1,date)
imdir <-paste("output/Homeranges/KDE/periods/",mostrecent$date[1], "/", sep="")
kde_values_allperiods <- read_csv(paste0(imdir,"kde_values_allperiods.csv"))

#### BRB: Find most recent folder
mostrecent <- list.dirs(path = "output/Homeranges/BRB/periods/", full.names = FALSE, recursive = FALSE)
mostrecent <- as.data.frame(mostrecent)
colnames(mostrecent) <- c("date")
mostrecent <- mostrecent %>% filter(date!="_archive") %>%  arrange(desc(date)) %>% top_n(1,date)
imdir <-paste("output/Homeranges/BRB/periods/",mostrecent$date[1], "/", sep="")

#### Load homerange results
brb_list <- read_csv(paste0(imdir,"brb_values_allperiods.csv"))

test<- SUAQ_rangepoints_11all20_loc %>% filter(focal%in%c("friska")) %>% filter(year(manualDate)<2012)
year(SUAQ_waypoints_11all20_loc$manualDate[1])

brb_selected_periods<- brb_list %>% 
  #filter(focal %in%c("ellie","lisa","friska","cissy"))%>% 
  mutate(period=fct_relevel(period, 
            "before 2012" ,"2012 until 2016","2016 until August 2018","Since August 2018","total research period"))
  #filter(hminfac==1)

brb_list_selected_err<-  brb_selected_periods %>% 
  mutate(hminfac=as.numeric(hminfac)) %>%  
  filter(hminfac %in% c(0.8,1.2))  %>% 
  spread(hminfac,hr95) %>%
  group_by(focal,nGPS,period) %>%
  summarise_each(funs(first(.[!is.na(.)]))) %>% 
  rename(hminfac_0_8=`0.8`,hminfac_1_2=`1.2`)



png(file=paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "brb_selected_periods",
    sep = ""
  ),
  "png",
  sep = "."
),width=900, height=700, res=120, units="px") # or other device
brb_selected_periods %>% filter(hminfac==1) %>% ggplot() + 
  geom_errorbar(data=brb_list_selected_err,aes(x=period,ymin=hminfac_0_8, ymax=hminfac_1_2,color=focal),width=0.2)+
  geom_point(aes(period,hr95,group=interaction(focal),color=focal),size=3)+
  geom_line(aes(period,hr95,group=interaction(focal),color=focal),size=0.5)+
  scale_color_brewer(palette="Set1") +
  theme_minimal()+
  geom_text(aes(x=period,y=hr95,label=nGPS),check_overlap = TRUE,hjust=1.5)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  theme(axis.title.x=element_blank())+
  labs(y=expression("Homerange 95% [km"^2*"]"))
dev.off()


### Visualize HR per period compared to each other
view(all_homeranges_selected)
sd(all_homeranges_selected[(all_homeranges_selected$hrprcnt=="95%")&all_homeranges_selected$period=="total research period",]$area)
all_homeranges_50_sf$period <- factor(all_homeranges_50_sf$period, levels = c("before 2012", "2012 until 2016", "left", "2016 until August 2018", "Since August 2018","total research period"))
cr<- all_homeranges_50_sf %>% filter(period=="total research period") %>% 
  filter(focal%in%c("cissy","lisa","ellie","friska")) %>% 
  filter(algorithm=="brb") %>% 
  ggplot()+geom_sf(aes(colour=focal),fill=NA)+facet_wrap(.~period)+
  ggtitle("Home ranges (BRB hmin factor 0.8)")
cr
cr %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "cr_brb_08_totalperiod_four",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=600,width = 29.7,height = 21,units="cm")

#### Table of all HR and estimator
table_HR <- all_homeranges_selected %>% filter(period=="total research period") %>% filter(hrprcnt %in% c("50%","95%")) %>% mutate(area=round(area,2),AUC=round(AUC,3),Comp_compactness=round(Comp_compactness,2),Comp_holearea=round(Comp_holearea,2),fruittree_normalized=round(fruittree_normalized,3)) %>% 
  dplyr::select(focal,matriline,agecat,dominance,"nF"=n_fllws,"nGPS"=n_gps,"HR"=hrprcnt,"Algo"=algorithm,area,"n Tree"=number_of_trees,"norm Tree"=fruittree_normalized,AUC,"Compact."=Comp_compactness,"Holes"=Comp_holes,"nPoly"=Comp_polycount,"area holes"=Comp_holearea) %>% gather()
  


print(xtable(bandwiths, type = "latex",caption=c("Overview of derived bandwidths for different bandwidth estimators")), include.rownames = FALSE, booktabs = TRUE, file = "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/tables/table_overview_bandwidth.tex")

```

# Statistics
```{r Homerange - Statistics, Explanatory variables,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
### Simple descriptive statistics
sd(as.numeric(all_homeranges_50[all_homeranges_50$period=="total research period",]$area))
view(all_homeranges_50[all_homeranges_50$period=="total research period",])



### Simple table outputs for thesis
#-latex output
print(xtable(bandwiths, type = "latex",caption=c("Overview of derived bandwidths for different bandwidth estimators")), include.rownames = FALSE, booktabs = TRUE, file = "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/tables/table_overview_bandwidth.tex")


### Matriline
all_homeranges_50_naomit <- all_homeranges_50 %>% dplyr::select(area,matriline,period,focal,n_gps,n_fllws,algorithm) %>%  na.omit()
all_homeranges_95_naomit <- all_homeranges_95 %>% dplyr::select(area,matriline,period,focal,n_gps,n_fllws,algorithm) %>% na.omit()
hr_all_nullmodell_95 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
hr_all_nullmodell_50 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
all_homeranges_50_naomit %>% ggplot(aes(as.factor(matriline),area,colour=period))+
  geom_boxplot() +
  geom_jitter(alpha=0.5)
# which sample indicator is more correlated with area
all_homeranges_50 %>% ggplot(aes(n_gps,area,colour=period))+
  geom_boxplot() +
  geom_jitter(alpha=0.5)
test_samplesize <- lm(area ~ n_gps+n_fllws,all_homeranges_50_naomit,REML=FALSE)
anova(test_samplesize) # n-gps has higher explanatory power
#### core area
lmer_numOfPoints50_matriline <- lmer(area ~ matriline+n_fllws+(1|focal)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
lmer_numOfPoints50
summary(lmer_numOfPoints50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### core area
lmer_numOfPoints95 <- lmer(area ~ matriline+(1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95,hr_all_nullmodell_95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
### Age
all_homeranges_50_naomit <- all_homeranges_50 %>% dplyr::select(area,agecat,period,focal,n_gps,n_fllws,algorithm) %>%  na.omit() 
all_homeranges_95_naomit <- all_homeranges_95 %>% dplyr::select(area,agecat,period,focal,n_gps,n_fllws,algorithm) %>% na.omit()
hr_all_nullmodell_95 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
hr_all_nullmodell_50 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
all_homeranges_50_naomit %>% ggplot(aes(as.factor(agecat),area,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
all_homeranges_95_naomit %>% ggplot(aes(as.factor(agecat),area,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
#### core area
lmer_numOfPoints50 <- lmer(area ~ agecat+(1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
anova(lmer_numOfPoints50,hr_all_nullmodell_50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### core area
lmer_numOfPoints95 <- lmer(area ~ agecat+(1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95,hr_all_nullmodell_95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
### Dominance
all_homeranges_50_naomit <- all_homeranges_50 %>% dplyr::select(area,dominance,period,focal,n_gps,n_fllws,algorithm) %>%  na.omit() 
all_homeranges_95_naomit <- all_homeranges_95 %>% dplyr::select(area,dominance,period,focal,n_gps,n_fllws,algorithm) %>% na.omit()
hr_all_nullmodell_95 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
hr_all_nullmodell_50 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
all_homeranges_50_naomit %>% ggplot(aes(as.factor(dominance),area,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
all_homeranges_95_naomit %>% ggplot(aes(as.factor(dominance),area,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
#### core area
lmer_numOfPoints50 <- lmer(area ~ dominance+(1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
anova(lmer_numOfPoints50,hr_all_nullmodell_50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### core area
lmer_numOfPoints95 <- lmer(area ~ dominance+(1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95,hr_all_nullmodell_95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs


# TREES
### Dominance
all_tree_naomit_50 <- all_homeranges_50 %>% dplyr::select(fruittree_normalized,area,dominance,period,focal,n_gps,n_fllws,algorithm) %>%  na.omit() 
all_tree_naomit_95 <- all_homeranges_95 %>% dplyr::select(fruittree_normalized,area,dominance,period,focal,n_gps,n_fllws,algorithm) %>% na.omit()
hr_all_nullmodell_95 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_tree_naomit_95,REML=FALSE)
hr_all_nullmodell_50 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_tree_naomit_50,REML=FALSE)
all_tree_naomit_50 %>% ggplot(aes(as.factor(dominance),fruittree_normalized,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
all_tree_naomit_95 %>% ggplot(aes(as.factor(dominance),fruittree_normalized,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
#### core area
lmer_numOfPoints50 <- lmer(area ~ dominance+(1 | focal)+(1| n_gps)+(1| algorithm),all_tree_naomit_50,REML=FALSE)
anova(lmer_numOfPoints50,hr_all_nullmodell_50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### home area
lmer_numOfPoints95 <- lmer(area ~ dominance+(1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95,hr_all_nullmodell_95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs

### Age of current offspring
all_homeranges_50_naomit <- all_homeranges_50 %>% dplyr::select(area,SUAQ_orangutans.dominancecat,period,focal,n_gps,n_fllws,algorithm) %>%  na.omit() 
all_homeranges_95_naomit <- all_homeranges_95 %>% dplyr::select(area,SUAQ_orangutans.dominancecat,period,focal,n_gps,n_fllws,algorithm) %>% na.omit()
hr_all_nullmodell_95 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
hr_all_nullmodell_50 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
all_homeranges_50_naomit %>% ggplot(aes(as.factor(SUAQ_orangutans.dominancecat),area,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
all_homeranges_95_naomit %>% ggplot(aes(as.factor(SUAQ_orangutans.dominancecat),area,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
#### core area
lmer_numOfPoints50 <- lmer(area ~ SUAQ_orangutans.dominancecat+(1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
anova(lmer_numOfPoints50,hr_all_nullmodell_50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### core area
lmer_numOfPoints95 <- lmer(area ~ SUAQ_orangutans.dominancecat+(1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95,hr_all_nullmodell_95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs

### Dominance
all_homeranges_50_naomit <- all_homeranges_50$ageOfCurrentOffspring_mean %>% dplyr::select(area,SUAQ_orangutans.dominancecat,period,focal,n_gps,n_fllws,algorithm) %>%  na.omit() 
all_homeranges_95_naomit <- all_homeranges_95 %>% dplyr::select(area,SUAQ_orangutans.dominancecat,period,focal,n_gps,n_fllws,algorithm) %>% na.omit()
hr_all_nullmodell_95 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
hr_all_nullmodell_50 <- lmer(area ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
all_homeranges_50_naomit %>% ggplot(aes(as.factor(SUAQ_orangutans.dominancecat),area,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
all_homeranges_95_naomit %>% ggplot(aes(as.factor(SUAQ_orangutans.dominancecat),area,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
#### core area
lmer_numOfPoints50 <- lmer(area ~ SUAQ_orangutans.dominancecat+(1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
anova(lmer_numOfPoints50,hr_all_nullmodell_50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### core area
lmer_numOfPoints95 <- lmer(area ~ SUAQ_orangutans.dominancecat+(1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95,hr_all_nullmodell_95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs


###### FINAL STATISTICS
### SCATTERS
plot_FRUITREExAREA_HR50<-
  all_homeranges_50 %>% ggplot(aes(area,fruittree_normalized)) +
  #scale_y_log10(labels=fancy_scientific) +
  geom_point(binwidth = 1) + 
  labs(y = "normalized fruit trees", x = expression("core range [km"^2*"]"))+
  geom_smooth(method="lm")+
  facet_wrap(.~period)
  
plot_FRUITREExAREA_HR50

plot_MATRILINExAREA_HR50 %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_MATRILINExAREA_HR50",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=300)

plot_FRUITREExAREA_HR95<-
  all_homeranges_95 %>% ggplot(aes(area,fruittree_normalized)) +
  #scale_y_log10(labels=fancy_scientific) +
  geom_point(binwidth = 1) + labs(y = "normalized fruit trees", x = expression("home range [km"^2*"]"))+
  geom_smooth(method="lm")+
  facet_wrap(.~period)
plot_FRUITREExAREA_HR95

plot_MATRILINExAREA_HR95 %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_MATRILINExAREA_HR95",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=300)

plot_MATRILINExAREA_HR95<-
  all_homeranges_95 %>% ggplot(aes(matriline,area,group=matriline)) +
  #scale_y_log10(labels=fancy_scientific) +
  geom_boxplot(binwidth = 1) + labs(y = expression("home range [km"^2*"]"),x = "matriline")+
  geom_smooth(method="lm")
plot_MATRILINExAREA_HR95

plot_MATRILINExAREA_HR50<-
  all_homeranges_50 %>% ggplot(aes(matriline,area,group=matriline)) +
  #scale_y_log10(labels=fancy_scientific) +
  geom_boxplot(binwidth = 1) + 
  labs(y = expression("home range [km"^2*"]",x = "matriline"))+
  geom_smooth(method="lm")
plot_MATRILINExAREA_HR50

plot_DOMINANCExAREA_HR50<-
  all_homeranges_50 %>%
  ggplot(aes(dominance,area,group=dominance)) +
  #scale_y_log10(labels=fancy_scientific) +
  labs(x = "dominance category [1-4]", y = expression("core range [km"^2*"]"))+
  geom_boxplot()+
  geom_jitter(aes(colour=focal))+
  facet_wrap(algorithm~.)
plot_DOMINANCExAREA_HR50

plot_DOMINANCExAREA_HR95<-
  all_homeranges_95 %>%
  ggplot(aes(dominance,area,group=dominance)) +
  #scale_y_log10(labels=fancy_scientific) +
  labs(x = "dominance category [1-4]", y = expression("home range [km"^2*"]"))+
  geom_boxplot()+
  geom_jitter(aes(colour=focal))+
  facet_wrap(algorithm~.)
plot_DOMINANCExAREA_HR95

plot_NFOLLOWSxAREA_HR50<-
  all_homeranges_50 %>%
  ggplot(aes(n_fllws,area)) +
  #scale_y_log10(labels=fancy_scientific) +
  labs(x = "number of follows", y = expression("home range [km"^2*"]"))+
  geom_jitter(aes(colour=focal))+
  facet_wrap(algorithm~.)
plot_NFOLLOWSxAREA_HR50

plot_NFOLLOWSxAREA_HR50<-
  all_homeranges_50 %>%
  ggplot(aes(n_fllws,area)) +
  #scale_y_log10(labels=fancy_scientific) +
  labs(x = "number of follows", y = expression("home range [km"^2*"]"))+
  geom_jitter(aes(colour=focal))+
  facet_wrap(algorithm~.)
plot_NFOLLOWSxAREA_HR50

### LMMs home range
all_homeranges_50_naomit <-all_homeranges_50 %>% filter(period=="total research period") %>%  dplyr::select(area,agecat,dominance,matriline,period,focal,n_gps,n_fllws,algorithm,DJL_mean,SI_mean,SIN_mean,fruittree_normalized) %>% filter(matriline!=3) %>%  na.omit()
all_homeranges_50_naomit_kde <- all_homeranges_50_naomit %>%filter(algorithm=="kde")
all_homeranges_50_naomit_brb <- all_homeranges_50_naomit %>%filter(algorithm=="brb")
all_homeranges_50_naomit_akde <- all_homeranges_50_naomit %>%filter(algorithm=="akde")
all_homeranges_50_naomit_mcp <- all_homeranges_50_naomit %>%filter(algorithm=="mcp")

all_homeranges_95_naomit <- all_homeranges_95 %>% filter(period=="total research period") %>%  dplyr::select(area,agecat,dominance,matriline,period,focal,n_gps,n_fllws,algorithm,DJL_mean,SI_mean,SIN_mean,fruittree_normalized) %>% na.omit()

### Core range
hr_all_nullmodell_50_focal <- lmer(area ~ (1 | focal),all_homeranges_50_naomit)
r.squaredGLMM(hr_all_nullmodell_50_focal)
hr_all_nullmodell_50_algo <- lmer(area ~ (1| algorithm),all_homeranges_50_naomit)
r.squaredGLMM(hr_all_nullmodell_50_algo)


hr_all_nullmodell_50 <- lmer(area ~ (1 | focal) + (1| algorithm),all_homeranges_50_naomit)

summary(hr_all_nullmodell_50)
anova(hr_all_nullmodell_50_focal,hr_all_nullmodell_50_algo,hr_all_nullmodell_50)
r.squaredGLMM(hr_all_nullmodell_50)

### Simple descriptive statistics
test_data<- all_homeranges_50_naomit %>% group_by(focal,agecat,dominance) %>% summarise()
test<- kruskal.test(agecat ~ dominance,data=test_data)
test

# lm for each algorithm
lmm_cr_full_HR50_kde <- lm(area ~dominance+fruittree_normalized+n_fllws+DJL_mean+(1 | focal) ,all_homeranges_50_naomit,REML=FALSE)
lmm_cr_full_HR50_brb <- lm(area ~dominance+fruittree_normalized+n_fllws+DJL_mean+(1 | focal),all_homeranges_50_naomit,REML=FALSE)
lmm_cr_full_HR50_akde <- lm(area ~dominance+fruittree_normalized+n_fllws+DJL_mean+(1 | focal),all_homeranges_50_naomit,REML=FALSE)
lmm_cr_full_HR50_mcp <- lm(area ~dominance+fruittree_normalized+n_fllws+DJL_mean+(1 | focal),all_homeranges_50_naomit,REML=FALSE)

lmm_cr_full_HR50 <- lmer(area ~dominance+fruittree_normalized+n_fllws+DJL_mean+(1 | focal) + (1| algorithm),all_homeranges_50_naomit,REML=FALSE)
anova(hr_all_nullmodell_50,lmm_cr_full_HR50)
summary(lmm_cr_full_HR50)
vif.mer(lmm_cr_full_HR50)
r.squaredGLMM(lmm_cr_full_HR50)
?r.squaredGLMM
#### Quick automatic selection
step_result_backward<- step(lmm_cr_full_HR50)
glm_HR50_selected_backward<- get_model(step_result_backward,direction="backward")
summary(glm_HR50_selected_backward)
vif.mer(glm_HR50_selected_backward)
r.squaredGLMM(glm_HR50_selected_backward)

##### 95% Homerange
hr_all_nullmodell_95 <- lmer(area ~ (1 | focal) + (1| algorithm),all_homeranges_95_naomit)
summary(hr_all_nullmodell_95)
r.squaredGLMM(hr_all_nullmodell_95)

hr_all_nullmodell_95_focal <- lmer(area ~ (1 | focal),all_homeranges_95_naomit)
r.squaredGLMM(hr_all_nullmodell_95_focal)
hr_all_nullmodell_95_algo <- lmer(area ~ (1| algorithm),all_homeranges_95_naomit)
r.squaredGLMM(hr_all_nullmodell_95_algo)



hr_all_nullmodell_95 <- lmer(area ~ (1 | focal) + (1| algorithm),all_homeranges_95_naomit)
anova(hr_all_nullmodell_95_focal,hr_all_nullmodell_95_algo,hr_all_nullmodell_95)
summary(hr_all_nullmodell_95)
r.squaredGLMM(hr_all_nullmodell_95)

### Simple descriptive statistics
lmm_cr_full_HR95 <- lmer(area ~ dominance+fruittree_normalized+n_fllws+DJL_mean+(1 | focal) + (1| algorithm),all_homeranges_95_naomit,REML=FALSE)
anova(hr_all_nullmodell_95,lmm_cr_full_HR95)
summary(lmm_cr_full_HR95)
vif.mer(lmm_cr_full_HR95)
r.squaredGLMM(lmm_cr_full_HR95)
?r.squaredGLMM
#### Quick automatic selection
step_result_backward<- step(lmm_cr_full_HR95)
glm_HR95_selected_backward<- get_model(step_result_backward,direction="backward")
summary(glm_HR95_selected_backward)
vif.mer(glm_HR95_selected_backward)
r.squaredGLMM(glm_HR95_selected_backward)

###### OVERVIEW OF MODEL RESULTS
screenreg(list(hr_all_nullmodell_50,lmm_cr_full_HR50,hr_all_nullmodell_95,lmm_cr_full_HR95),digits=4)


summary(lmm_cr_full_HR50)
sjPlot::tab_model(lmm_cr_full_HR95, digits=4,
                  show.re.var= TRUE, 
                  pred.labels =c("intercept", "dominance","fruit trees normalized", "n follows", "average DJL"),
                  dv.labels= "Effects of internal and external factors on DJL")
ranova(lmm_cr_full_HR50)
view(as.data.frame(vif.mer(lmm_cr_full_HR50)))
r.squaredGLMM(lmm_cr_full_HR50)
anova(hr_all_nullmodell_50,lmm_cr_full_HR50)

###### TEXTREG --> LATEX EXPORT
texreg(list(hr_all_nullmodell_50,lmm_cr_full_HR50,hr_all_nullmodell_95,lmm_cr_full_HR95),
       digits=4,
          custom.model.names = c("Only random (CR)","Selected model (CR)","(Only random (HR 95%)","Selected model (HR 95%"),
          custom.coef.names = c("intercept", "dominance","fruit trees normalized", "n follows", "average DJL"),
          return.string=TRUE,
          use.packages=FALSE,
          single.row=TRUE,
       stars = c(0.001, 0.01, 0.05, 0.1))



```

```{r Trees in Homerange - Statistics, Explanatory variables,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
## MATRILINE
all_homeranges_50_naomit <- all_homeranges_50 %>% dplyr::select(area,matriline,period,focal,n_gps,n_fllws,algorithm,fruittree_normalized,dominance) %>%  na.omit()
all_homeranges_95_naomit <- all_homeranges_95 %>% dplyr::select(area,matriline,period,focal,n_gps,n_fllws,algorithm,fruittree_normalized,dominance) %>% na.omit()
hr_all_nullmodell_95 <- lmer(fruittree_normalized ~ (1 | focal)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
hr_all_nullmodell_50 <- lmer(fruittree_normalized ~ (1 | focal)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
hr_all_fullmodell_95 <- lmer(fruittree_normalized ~ area+matriline+dominance+(1 | focal)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
hr_all_fullmodell_50 <- lmer(fruittree_normalized ~ area+matriline+dominance+(1 | focal)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)

all_homeranges_50_naomit %>% ggplot(aes(as.factor(matriline),fruittree_normalized,colour=period))+
  geom_boxplot() +
  geom_jitter(alpha=0.5)
# which sample indicator is more correlated with area
all_homeranges_50 %>% ggplot(aes(n_gps,fruittree_normalized,colour=period))+
  geom_boxplot() +
  geom_jitter(alpha=0.5)
test_samplesize <- lm(fruittree_normalized ~ n_gps+n_fllws,all_homeranges_50_naomit,REML=FALSE)
anova(test_samplesize) # n-gps has higher explanatory power

#### core area
lmer_numOfPoints50 <- lmer(fruittree_normalized ~ area+matriline+(1 | focal)+(1| n_fllws)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
anova(lmer_numOfPoints50,hr_all_nullmodell_50)
anova(lmer_numOfPoints50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### 95% area
lmer_numOfPoints95 <- lmer(fruittree_normalized ~ area+matriline+(1 | focal)+(1| n_fllws)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95,hr_all_nullmodell_95)
anova(lmer_numOfPoints95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs



## DOMINANCE
all_homeranges_50_naomit <- all_homeranges_50 %>% dplyr::select(area,dominance,period,focal,n_gps,n_fllws,algorithm,fruittree_normalized) %>%  na.omit()
all_homeranges_95_naomit <- all_homeranges_95 %>% dplyr::select(area,dominance,period,focal,n_gps,n_fllws,algorithm,fruittree_normalized) %>% na.omit()
hr_all_nullmodell_95 <- lmer(fruittree_normalized ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
hr_all_nullmodell_50 <- lmer(fruittree_normalized ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)

all_homeranges_50_naomit %>% ggplot(aes(as.factor(dominance),fruittree_normalized,colour=period))+
  geom_boxplot() +
  geom_jitter(alpha=0.5)
# which sample indicator is more correlated with area
all_homeranges_50 %>% ggplot(aes(n_gps,fruittree_normalized,colour=period))+
  geom_boxplot() +
  geom_jitter(alpha=0.5)
test_samplesize <- lm(fruittree_normalized ~ n_gps+n_fllws,all_homeranges_50_naomit,REML=FALSE)
anova(test_samplesize) # n-gps has higher explanatory power

#### core area
lmer_numOfPoints50 <- lmer(fruittree_normalized ~ area+dominance+(1 | focal)+(1| n_fllws)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
anova(lmer_numOfPoints50,hr_all_nullmodell_50)
anova(lmer_numOfPoints50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### 95% area
lmer_numOfPoints95 <- lmer(fruittree_normalized ~ area+dominance+(1 | focal)+(1| n_fllws)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95,hr_all_nullmodell_95)
anova(lmer_numOfPoints95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs

## AGE
all_homeranges_50_naomit <- all_homeranges_50 %>% dplyr::select(area,agecat,period,focal,n_gps,n_fllws,algorithm,fruittree_normalized) %>%  na.omit()
all_homeranges_95_naomit <- all_homeranges_95 %>% dplyr::select(area,agecat,period,focal,n_gps,n_fllws,algorithm,fruittree_normalized) %>% na.omit()
hr_all_nullmodell_95 <- lmer(fruittree_normalized ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
hr_all_nullmodell_50 <- lmer(fruittree_normalized ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)

all_homeranges_50_naomit %>% ggplot(aes(as.factor(agecat),fruittree_normalized,colour=period))+
  geom_boxplot() +
  geom_jitter(alpha=0.5)
# which sample indicator is more correlated with area
all_homeranges_50 %>% ggplot(aes(n_gps,fruittree_normalized,colour=period))+
  geom_boxplot() +
  geom_jitter(alpha=0.5)
test_samplesize <- lm(fruittree_normalized ~ n_gps+n_fllws,all_homeranges_50_naomit,REML=FALSE)
anova(test_samplesize) # n-gps has higher explanatory power

#### core area
lmer_numOfPoints50 <- lmer(fruittree_normalized ~ area+agecat+(1 | focal)+(1| n_fllws)+(1| algorithm),all_homeranges_50_naomit,REML=FALSE)
anova(lmer_numOfPoints50,hr_all_nullmodell_50)
anova(lmer_numOfPoints50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### 95% area
lmer_numOfPoints95 <- lmer(fruittree_normalized ~ area+agecat+(1 | focal)+(1| n_fllws)+(1| algorithm),all_homeranges_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95,hr_all_nullmodell_95)
anova(lmer_numOfPoints95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs

summary(hr_all_fullmodell_95)
sjPlot::tab_model(hr_all_fullmodell_50, digits=4,
                  show.re.var= TRUE,
                  dv.labels= "Effects of internal and external factors on DJL")
ranova(hr_all_fullmodell_95)
view(as.data.frame(vif.mer(hr_all_fullmodell_95)))
r.squaredGLMM(hr_all_fullmodell_95)
anova(hr_all_nullmodell_50,hr_all_fullmodell_95)


```

```{r Homerange overlaps - Statistics, Explanatory variables,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
### Descriptive overlaps
all_overlaps_50_naomit <- all_overlaps_50 %>% filter(period=="total research period") %>%  
dplyr::select(area,n_gps,overlap,overlap_relative,area_shared,overlap_jaccard,period,focal,focal.1,related,algorithm) %>% na.omit() %>% ungroup()
all_overlaps_95_naomit <- all_overlaps_95 %>% dplyr::select(area,n_gps,overlap,area_shared,overlap_jaccard,overlap_BA,overlap_UDOI,overlap_VI,overlap_HRshared,related,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup()

### Simple descriptive statistics 
# Area shared
test <- specs_areashared_95 %>% filter(algorithm=="brb")
mean(as.numeric(test$area_shared),na.rm=TRUE)
specs_areashared_95<- all_overlaps_95_naomit %>% group_by(focal,algorithm,area_shared) %>% summarise(n())

specs_areashared_50<- all_overlaps_50_naomit %>% group_by(focal,algorithm,area_shared,overlap_relative) %>% summarise(n())
plot_specs_areashared_50<- specs_areashared_50 %>% ggplot(aes(focal,area_shared,colour=focal,shape=algorithm)) + 
  geom_point(size=4) +
  labs(y="area shared [%]",x="")
plot_specs_areashared_50
plot_specs_areashared_50 %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_specs_areashared_50",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=300,width = 10,height = 10,units="cm")
specs_areashared_95<- all_overlaps_95_naomit %>% group_by(focal,algorithm,area_shared) %>% summarise(n())
plot_specs_areashared_95<- specs_areashared_95 %>% ggplot(aes(focal,area_shared,colour=focal,shape=algorithm)) + 
  geom_point(size=4) +
  labs(y="area shared [%]",x="")+
  theme(legend.position = "none")+
  ylim(0.35,1)
 plot_specs_areashared_95 %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_specs_areashared_95",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=300,width = 10,height = 10,units="cm")

# Undirected overlaps
specs_areashared_50_undirected<- all_overlaps_50_naomit %>% group_by(focal,algorithm,overlap_relative,overlap_jaccard) %>% summarise(n())
plot_specs_areashared_50_undirected<- specs_areashared_50_undirected %>% 
  ggplot(aes(focal,overlap_relative,overlap_jaccard,colour=focal,shape=algorithm)) + 
  geom_point(size=4) +
  labs(y="area shared [%]",x="")
plot_specs_areashared_50
plot_specs_areashared_50 %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_specs_areashared_50",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=300,width = 10,height = 10,units="cm")
specs_areashared_95_undirected<- all_overlaps_95_naomit %>% group_by(focal,algorithm,area_shared) %>% summarise(n())
plot_specs_areashared_95<- specs_areashared_95 %>% ggplot(aes(focal,area_shared,colour=focal,shape=algorithm)) + 
  geom_point(size=4) +
  labs(y="area shared [%]",x="")+
  theme(legend.position = "none")+
  ylim(0.35,1)
 plot_specs_areashared_95 %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_specs_areashared_95",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=300,width = 10,height = 10,units="cm")

 
### Comparison between estimators
all_overlaps_95_naomit <- all_overlaps_95 %>% dplyr::select(area,n_gps,overlap,overlap_jaccard,overlap_BA,overlap_UDOI,overlap_VI,overlap_HRshared,related,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup() %>% gather("overlap_calculation","value",3:8)
all_overlaps_95_selected <- all_overlaps_95 %>% dplyr::select(focal,focal.1,overlap,related,algorithm,overlap_jaccard,overlap_BA,overlap_UDOI,overlap_VI,overlap_HRshared) %>% na.omit() %>% ungroup() %>% rename(overlap=overlap,"Jaccard index"=overlap_jaccard,"BA index"=overlap_BA,"UDOI"=overlap_UDOI,VI=overlap_VI,"relative HR shared"=overlap_HRshared)
all_overlaps_95_selected <- all_overlaps_95 %>% dplyr::select(overlap,overlap_jaccard,overlap_BA,overlap_UDOI,overlap_VI,overlap_HRshared) %>% na.omit() %>% ungroup() %>% rename(overlap=overlap,"Jaccard index"=overlap_jaccard,"BA index"=overlap_BA,"UDOI"=overlap_UDOI,VI=overlap_VI,"relative HR shared"=overlap_HRshared)

plot_specs_overlapindices<- all_overlaps_95_naomit %>% ggplot(aes(focal,value)) + 
  geom_boxplot() +
  labs(y="value",x="overlap index used")+
  theme(legend.position = "none")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 7))+
  facet_wrap(period~overlap_calculation)
plot_specs_overlapindices


specs_correlation_overlapindices <- cor(all_overlaps_95_selected)
print(xtable(specs_correlation_overlapindices, type = "latex",caption=c("Overview of derived bandwidths for different bandwidth estimators")), include.rownames = FALSE, booktabs = TRUE, file = "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/tables/table_overview_overlapindices.tex")


# Jaccard
## MATRILINE Explain jaccard overlap
all_overlaps_50_naomit <- all_overlaps_50 %>%  dplyr::select(area,n_gps,overlap,overlap_jaccard,related,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup()
all_overlaps_95_naomit <- all_overlaps_95 %>%  dplyr::select(area,n_gps,overlap,overlap_jaccard,overlap_UDOI,related,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup()
lmer_overlap_all_nullmodell_95 <- lmer(overlap_jaccard ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1|algorithm),all_overlaps_95_naomit,REML=FALSE)
lmer_overlap_all_nullmodell_95 <- lmer(overlap_UDOI ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1|algorithm),all_overlaps_95_naomit,REML=FALSE)
lmer_overlap_all_nullmodell_50 <- lmer(overlap_jaccard ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)

#### Core area
lmer_jaccard_50_related <- lmer(overlap_jaccard ~ related+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)
anova(lmer_jaccard_50_related,lmer_overlap_all_nullmodell_50)
anova(lmer_jaccard_50_related)

##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_jaccard_50_related)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs

#### 95% Area
lmer_jaccard_95_related <- lmer(overlap_jaccard ~ related+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95_jaccard,lmer_jaccard_95_related)
summary(lmer_numOfPoints95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_jaccard_95_related)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs



## AGE
all_overlaps_50_naomitage <- all_overlaps_50 %>% dplyr::select(area,n_gps,overlap,overlap_jaccard,agediff,period,focal,focal.1,algorithm) %>%  na.omit() 
all_overlaps_95_naomitage <- all_overlaps_95 %>% dplyr::select(area,n_gps,overlap,overlap_jaccard,agediff,period,focal,focal.1,algorithm) %>% na.omit()
lmer_overlap_nullmodell_95 <- lmer(overlap_jaccard ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomitage,REML=FALSE)
lmer_overlap_nullmodell_50 <- lmer(overlap_jaccard ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomitage,REML=FALSE)

all_overlaps_50_naomitage %>% ggplot(aes(as.factor(agediff),overlap_jaccard,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
all_overlaps_95_naomitage %>% ggplot(aes(as.factor(agediff),overlap_jaccard,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()

#### Core Area
lmer_jaccard_50_agediff <- lmer(overlap_jaccard ~ agediff+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomitage,REML=FALSE)
anova(lmer_jaccard_50_agediff,lmer_overlap_nullmodell_50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### 95% Area
lmer_jaccard_95_agediff <- lmer(overlap_jaccard ~ agediff+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomitage,REML=FALSE)
anova(lmer_jaccard_95_agediff,lmer_overlap_nullmodell_95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs


## DOMINANCE
all_overlaps_50_naomit_dominance <- all_overlaps_50 %>% dplyr::select(area,n_gps,overlap,overlap_jaccard,dominancediff,period,focal,focal.1,algorithm) %>%  na.omit() 
all_overlaps_95_naomit_dominance <- all_overlaps_95 %>% dplyr::select(area,n_gps,overlap,overlap_jaccard,dominancediff,period,focal,focal.1,algorithm) %>% na.omit()
lmer_overlap_nullmodell_95 <- lmer(overlap_jaccard ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomit_dominance,REML=FALSE)
lmer_overlap_nullmodell_50 <- lmer(overlap_jaccard ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomit_dominance,REML=FALSE)

all_overlaps_50_naomit_dominance %>% ggplot(aes(as.factor(dominancediff),overlap_jaccard,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
all_overlaps_95_naomit_dominance %>% ggplot(aes(as.factor(dominancediff),overlap_jaccard,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()

#### Core area
lmer_jaccard_50_dominance <- lmer(overlap_jaccard ~ dominancediff+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomit_dominance,REML=FALSE)
anova(lmer_jaccard_50_dominance,lmer_overlap_nullmodell_50)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_jaccard_50_dominance)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### 95% Area
lmer_jaccard_95_dominance <- lmer(overlap_jaccard ~ dominancediff+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomit_dominance,REML=FALSE)
anova(lmer_jaccard_95_dominance,lmer_overlap_nullmodell_95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs


# Relative overlap
## MATRILINE Explain relative overlap
all_overlaps_50_naomit <- all_overlaps_50 %>% dplyr::select(area,n_gps,overlap,overlap_relative,related,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup()
all_overlaps_95_naomit <- all_overlaps_95 %>% dplyr::select(area,n_gps,overlap,overlap_relative,related,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup()
lmer_overlap_all_nullmodell_95 <- lmer(overlap_relative ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1|algorithm),all_overlaps_95_naomit,REML=FALSE)
lmer_overlap_all_nullmodell_50 <- lmer(overlap_relative ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)

all_overlaps_50_naomit %>% ggplot(aes(as.factor(related),overlap_relative,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
all_overlaps_95_naomit %>% ggplot(aes(as.factor(related),overlap_relative,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()

#### Core area
lmer_relative_50 <- lmer(overlap_relative ~ area+ related+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)
anova(lmer_relative_50,lmer_overlap_all_nullmodell_50)
anova(lmer_relative_50)

##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_relative_50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs

#### 95% Area
lmer_numOfPoints95 <- lmer(overlap_relative ~ area+ related+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomit,REML=FALSE)
anova(lmer_numOfPoints95,lmer_overlap_all_nullmodell_95)
anova(lmer_numOfPoints95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs



## AGE
all_overlaps_50_naomitage <- all_overlaps_50 %>% dplyr::select(area,n_gps,overlap,overlap_relative,agecat,period,focal,focal.1,algorithm) %>%  na.omit() 
all_overlaps_95_naomitage <- all_overlaps_95 %>% dplyr::select(area,n_gps,overlap,overlap_relative,agecat,period,focal,focal.1,algorithm) %>% na.omit()
lmer_overlap_nullmodell_95 <- lmer(overlap_relative ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomitage,REML=FALSE)
lmer_overlap_nullmodell_50 <- lmer(overlap_relative ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomitage,REML=FALSE)

all_overlaps_50_naomitage %>% ggplot(aes(as.factor(agecat),overlap_relative,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
all_overlaps_95_naomitage %>% ggplot(aes(as.factor(agecat),overlap_relative,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()

#### Core Area
lmer_relative_50_age <- lmer(overlap_relative ~ area+agecat+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomitage,REML=FALSE)
anova(lmer_relative_50_age,lmer_overlap_nullmodell_50)
anova(lmer_relative_50_age)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_relative_50_age)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### 95% Area
lmer_relative_95_age <- lmer(overlap_relative ~ area+agecat+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomitage,REML=FALSE)
anova(lmer_relative_95_age,lmer_overlap_nullmodell_95)
anova(lmer_relative_95_age)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs


## DOMINANCE
all_overlaps_50_naomit_dominance <- all_overlaps_50 %>% dplyr::select(area,n_gps,overlap,overlap_relative,dominance,period,focal,focal.1,algorithm) %>%  na.omit() 
all_overlaps_95_naomit_dominance <- all_overlaps_95 %>% dplyr::select(area,n_gps,overlap,overlap_relative,dominance,period,focal,focal.1,algorithm) %>% na.omit()
lmer_overlap_nullmodell_95 <- lmer(overlap_relative ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomit_dominance,REML=FALSE)
lmer_overlap_nullmodell_50 <- lmer(overlap_relative ~ (1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomit_dominance,REML=FALSE)

all_overlaps_50_naomit_dominance %>% ggplot(aes(as.factor(dominance),overlap_relative,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()
all_overlaps_95_naomit_dominance %>% ggplot(aes(as.factor(dominance),overlap_relative,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()

#### Core area
lmer_relative_50_dominance <- lmer(overlap_relative ~ area+dominance+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomit_dominance,REML=FALSE)
anova(lmer_relative_50_dominance,lmer_overlap_nullmodell_50)
anova(lmer_relative_50_dominance)

##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_relative_50_dominance)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs
#### 95% Area
lmer_relative_95_dominance <- lmer(overlap_relative ~ area+dominance+(1 | focal.1)+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomit_dominance,REML=FALSE)
anova(lmer_relative_95_dominance,lmer_overlap_nullmodell_95)
anova(lmer_relative_95_dominance)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_numOfPoints95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs




########### FINAL Statistics ################
# loading data all periods
allp_overlaps_95_naomit_long <- all_overlaps_allperiods_95 %>% filter(algorithm%in%c("brb")) %>% dplyr::select(area,n_gps,overlap,overlap_jaccard,overlap_relative,related,agediff,dominancediff,period,focal,focal.1,algorithm,fruittree_normalized,fruittree_per_sqkm)%>% rename(overlap=overlap,"Jaccard index"=overlap_jaccard,"relative overlap"=overlap_relative) %>%  na.omit() %>% ungroup()  %>% gather("overlap_calculation","value",3:5)

allp_overlaps_50_naomit_long <- all_overlaps_allperiods_50 %>% filter(algorithm%in%c("brb")) %>% dplyr::select(area,n_gps,overlap,overlap_jaccard,overlap_relative,related,agediff,dominancediff,overlap,period,focal,focal.1,algorithm,fruittree_normalized,fruittree_per_sqkm) %>% rename(overlap=overlap,"Jaccard index"=overlap_jaccard,"relative overlap"=overlap_relative) %>%  na.omit() %>% ungroup() %>% gather("overlap_calculation","value",3:5)

allp_overlaps_50_naomit <- all_overlaps_allperiods_50 %>% dplyr::select(area,n_gps,period,related,agediff,dominancediff,overlap,overlap_relative,area_shared,overlap_jaccard,period,focal,focal.1,related,algorithm,fruittree_normalized,fruittree_per_sqkm) %>% na.omit() %>% ungroup()

allp_overlaps_95_naomit <- all_overlaps_allperiods_95 %>%   dplyr::select(overlap,period,related,agediff,dominancediff,area_shared,overlap_jaccard,overlap_relative,related,period,focal,focal.1,algorithm,n_gps,fruittree_normalized,fruittree_per_sqkm) %>% na.omit() %>% ungroup()

# loading data
all_overlaps_95_naomit_long <- all_overlaps_95 %>%filter(period =="total research period") %>%  dplyr::select(area,n_gps,overlap,overlap_jaccard,overlap_BA,overlap_UDOI,overlap_VI,overlap_HRshared,related,agediff,dominancediff,overlap,period,focal,focal.1,algorithm,fruittree_normalized)  %>% ungroup() %>% rename(overlap=overlap,"Jaccard index"=overlap_jaccard,"BA index"=overlap_BA,"UDOI"=overlap_UDOI,VI=overlap_VI,"relative HR shared"=overlap_HRshared) %>% gather("overlap_calculation","value",3:8)

all_overlaps_50_naomit_long <- all_overlaps_50 %>%filter(period=="total research period") %>%  dplyr::select(area,n_gps,overlap,overlap_jaccard,overlap_relative,related,agediff,dominancediff,overlap,period,focal,focal.1,algorithm,fruittree_normalized) %>% rename(overlap=overlap,"Jaccard index"=overlap_jaccard,"relative overlap"=overlap_relative) %>%  na.omit() %>% ungroup() %>% gather("overlap_calculation","value",3:5)

all_overlaps_50_naomit <- all_overlaps_50 %>% filter(period=="total research period") %>%  filter(algorithm%in%c("brb","kde")) %>% dplyr::select(area,n_gps,related,agediff,dominancediff,overlap,overlap_relative,area_shared,overlap_jaccard,period,focal,focal.1,algorithm,fruittree_normalized) %>% na.omit() %>% ungroup()

all_overlaps_95_naomit <- all_overlaps_95 %>% filter(period=="total research period") %>%  filter(algorithm%in%c("brb","kde")) %>%  dplyr::select(overlap,n_fllws,n_gps,agediff,dominancediff,area_shared,overlap_jaccard,overlap_relative,overlap_BA,overlap_UDOI,overlap_VI,overlap_HRshared,related,period,focal,focal.1,algorithm,fruittree_normalized) %>% na.omit() %>% ungroup()

# visuals
all_overlaps_95_naomit_long %>% ggplot(aes(as.factor(related),value,colour=n_gps))+
  geom_boxplot()+
  geom_jitter()+
  facet_grid(algorithm~ overlap_calculation,scale="free")+
  labs(colour="n GPS",x="")

all_overlaps_95_naomit_long %>% 
  ggplot(aes(as.factor(agediff),value,colour=n_gps))+
  geom_boxplot()+
  geom_jitter()+
  labs(colour="n GPS",x="dominance difference")+
  facet_grid(algorithm ~ overlap_calculation,scale="free")

all_overlaps_50_naomit_long %>% ggplot(aes(as.factor(related),value,colour=n_gps))+
  geom_boxplot() +
  geom_jitter()+
  facet_grid(algorithm ~ overlap_calculation,scale="free")+
  labs(colour="n GPS",x="")

allp_overlaps_95_naomit_long %>% ggplot(aes(as.factor(related),value,colour=n_gps))+
  geom_boxplot()+
  geom_jitter()+
  facet_grid(period ~ overlap_calculation,scale="free")+
  labs(colour="n GPS",x="related")

allp_overlaps_95_naomit_long %>% ggplot(aes(as.factor(dominancediff),value,colour=n_gps))+
  geom_boxplot()+
  geom_jitter()+
  facet_grid(period ~ overlap_calculation,scale="free")+
  labs(colour="n GPS",x="difference in dominance category")

allp_overlaps_95_naomit_long %>% ggplot(aes(as.factor(round(fruittree_normalized,2)),related,group=related,colour=n_gps))+
  geom_boxplot()+
  facet_grid(period ~ overlap_calculation,scale="free")+
  labs(colour="n GPS",x="normalized fruit trees")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1,size = 7))

## OVERLAP
lmer_overlap_nullmodell_50 <- lmer(overlap ~ (1|algorithm)+(1 | focal)+(1|period),allp_overlaps_50_naomit,REML=FALSE)
lmer_overlap_nullmodell_95 <- lmer(overlap ~ (1|algorithm)+(1 | focal)+(1|period),allp_overlaps_95_naomit,REML=FALSE)
lmer_overlap_50<- lmer(overlap ~ dominancediff+related+(1|algorithm)+(1 | focal)+(1|period),allp_overlaps_50_naomit,REML=FALSE)
lmer_overlap_95 <- lmer(overlap ~ dominancediff+related+(1|algorithm)+(1 | focal)+(1|period),allp_overlaps_95_naomit,REML=FALSE)

anova(lmer_overlap_50,lmer_overlap_nullmodell_50)
anova(lmer_overlap_nullmodell_95,lmer_overlap_95)
vif.mer(lmer_overlap_50)
summary(lmer_overlap_50)
summary(lmer_overlap_50)

r.squaredGLMM(lmer_overlap_50)
r.squaredGLMM(lmer_overlap_95)

## JACCARD
lmer_jaccard_nullmodell_50 <- lmer(overlap_jaccard ~ (1|algorithm)+(1|period)+(1 | focal),allp_overlaps_50_naomit,REML=FALSE)
lmer_jaccard_nullmodell_95 <- lmer(overlap_jaccard ~ (1|algorithm)+(1|period)+(1 | focal),allp_overlaps_95_naomit,REML=FALSE)
lmer_jaccard_50<- lmer(overlap_jaccard ~ dominancediff+related+(1|algorithm)+(1 | focal)+(1|period),allp_overlaps_50_naomit,REML=FALSE)
lmer_jaccard_95 <- lmer(overlap_jaccard ~ dominancediff+related+(1|algorithm)+(1 | focal)+(1|period),allp_overlaps_95_naomit,REML=FALSE)

anova(lmer_jaccard_50,lmer_jaccard_nullmodell_50)
anova(lmer_jaccard_nullmodell_95,lmer_jaccard_95)
vif.mer(lmer_jaccard_50)
summary(lmer_jaccard_50)
summary(lmer_jaccard_50)
r.squaredGLMM(lmer_jaccard_95)

## RELATIVE OVERLAP
lmer_relativeov_nullmodell_50 <- lmer(overlap_relative ~ (1|algorithm)+(1 | focal)+(1|period),allp_overlaps_50_naomit,REML=FALSE)
lmer_relativeov_nullmodell_95 <- lmer(overlap_relative ~ (1|algorithm)+(1 | focal)+(1|period),allp_overlaps_95_naomit,REML=FALSE)
lmer_reltiveov_50<- lmer(overlap_relative ~ dominancediff+related++(1 | focal)+(1|algorithm)+(1|period),allp_overlaps_50_naomit,REML=FALSE)
lmer_relativeov_95 <- lmer(overlap_relative ~ dominancediff+related+(1 | focal)+(1|algorithm)+(1|period),allp_overlaps_95_naomit,REML=FALSE)

anova(lmer_reltiveov_50,lmer_relativeov_nullmodell_50)
anova(lmer_relativeov_nullmodell_95,lmer_relativeov_95)
vif.mer(lmer_reltiveov_50)
summary(lmer_reltiveov_50)
summary(lmer_relativeov_95)
r.squaredGLMM(lmer_relativeov_95)

## UDOI
lmer_UDOI_nullmodell_95 <- lmer(overlap_UDOI ~ (1|algorithm)+(1 | focal),all_overlaps_95_naomit,REML=FALSE)
lmer_UDOI_95 <- lmer(overlap_UDOI ~ dominancediff+related+(1|algorithm)+(1 | focal),all_overlaps_95_naomit,REML=FALSE)

anova(lmer_UDOI_nullmodell_95,lmer_UDOI_95)
vif.mer(lmer_UDOI_95)
summary(lmer_UDOI_95)
r.squaredGLMM(lmer_UDOI_95)


screenreg(list(lmer_overlap_50,lmer_overlap_95,lmer_jaccard_50,lmer_jaccard_95,lmer_reltiveov_50,lmer_relativeov_95,lmer_UDOI_95),digits=4)
texreg(list(lmer_overlap_50,lmer_overlap_95,lmer_jaccard_50,lmer_jaccard_95,lmer_reltiveov_50,lmer_relativeov_95,lmer_UDOI_95),
       digits=4,
          custom.model.names = c("absolute overlap (CR)","absolute overlap (HR)","Jaccard (CR)","Jaccard (HR)","relative overlap (CR)","relative overlap (HR)","UDOI (UD)"),
          custom.coef.names = c("intercept", "difference dominance","related"),
          return.string=TRUE,
          use.packages=FALSE,
          single.row=TRUE,
       stars = c(0.001, 0.01, 0.05, 0.1))

summary(lmer_UDOI_95)
sjPlot::tab_model(lmer_UDOI_95, 
                  show.re.var= TRUE, 
                  pred.labels =c("intercept", "dominance","fruit trees normalized", "n follows", "average DJL"),
                  dv.labels= "Effects of internal and external factors on DJL")
ranova(lmer_UDOI_95)
view(as.data.frame(vif.mer(lmer_UDOI_95)))
r.squaredGLMM(lmer_UDOI_95)
anova(lmer_UDOI_nullmodell_95,lmer_UDOI_95)


## TREES IN OVERLAPS
lmer_ntree_nullmodell_50 <- lmer(fruittree_normalized ~ (1|algorithm)++(1 | focal.1)+(1 | focal)+(1|period),allp_overlaps_50_naomit,REML=FALSE)
lmer_ntree_nullmodell_95 <- lmer(fruittree_normalized ~ (1|algorithm)++(1 | focal.1)+(1 | focal)+(1|period),allp_overlaps_95_naomit,REML=FALSE)
lmer_ntree_50<- lmer(fruittree_normalized ~ dominancediff+related+(1 | focal.1)+(1 | focal)+(1|algorithm)+(1|period),allp_overlaps_50_naomit,REML=FALSE)
lmer_ntree_95 <- lmer(fruittree_normalized ~ dominancediff+related+(1 | focal.1)+(1 | focal)+(1|algorithm)+(1|period),allp_overlaps_95_naomit,REML=FALSE)

anova(lmer_ntree_50,lmer_ntree_nullmodell_50)
anova(lmer_ntree_95,lmer_ntree_nullmodell_95)
vif.mer(lmer_ntree_95)
summary(lmer_ntree_50)
summary(lmer_ntree_95)
r.squaredGLMM(lmer_ntree_95)



```

```{r Homerange Trees in overlaps - Statistics, Explanatory variables,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
# Tree in overlap
## MATRILINE Explain tree normalized
all_overlaps_50_naomit <- all_overlaps_50%>%  dplyr::select(area,n_gps,overlap,dominancediff,fruittree_normalized,related,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup() 
all_overlaps_95_naomit <- all_overlaps_95 %>% dplyr::select(area,n_gps,dominancediff,overlap,fruittree_normalized,related,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup()
lmer_overlap_all_nullmodell_95 <- lmer(fruittree_normalized ~ (1 | focal)+(1|algorithm),all_overlaps_95_naomit,REML=FALSE)
lmer_overlap_all_nullmodell_50 <- lmer(fruittree_normalized ~ (1 | focal)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)
lmer_overlap_all_fullmodell_50 <- lmer(fruittree_normalized ~ area+related+dominancediff+(1 | focal)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)
lmer_overlap_all_fullmodell_95 <- lmer(fruittree_normalized ~ area+related+dominancediff+(1 | focal)+(1| algorithm),all_overlaps_95_naomit,REML=FALSE)



all_overlaps_50_naomit %>% ggplot(aes(as.factor(dominancediff),fruittree_normalized,colour=area))+
  geom_boxplot() +
  geom_jitter()


#### Core area
lmer_fruittree_overlap50 <- lmer(fruittree_normalized ~ area+related+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)
anova(lmer_fruittree_overlap50,lmer_overlap_all_nullmodell_50)
summary(lmer_fruittree_overlap50)

##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_fruittree_overlap50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs

#### 95% Area
lmer_fruittree_overlap95 <- lmer(fruittree_normalized ~ area+related+(1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_95_naomit,REML=FALSE)
anova(lmer_fruittree_overlap95,lmer_overlap_all_nullmodell_95)
summary(lmer_fruittree_overlap95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_fruittree_overlap95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs

## DOMINANCE Explain tree normalized
all_overlaps_50_naomit <- all_overlaps_50 %>%  dplyr::select(area,n_fllws,overlap,fruittree_normalized,dominance,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup() 
all_overlaps_95_naomit <- all_overlaps_95 %>% dplyr::select(area,n_fllws,overlap,fruittree_normalized,dominance,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup()
lmer_overlap_all_nullmodell_95 <- lmer(fruittree_normalized ~ (1 | focal)+(1| n_fllws)+(1|algorithm),all_overlaps_95_naomit,REML=FALSE)
lmer_overlap_all_nullmodell_50 <- lmer(fruittree_normalized ~ (1 | focal)+(1| n_gps)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)

all_overlaps_95_naomit %>% ggplot(aes(as.factor(dominance),fruittree_normalized,colour=area))+
  geom_boxplot() +
  geom_jitter()


#### Core area
lmer_fruittree_overlap50 <- lmer(fruittree_normalized ~ area+dominance+(1 | focal)+(1| n_fllws)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)
anova(lmer_fruittree_overlap50,lmer_overlap_all_nullmodell_50)
summary(lmer_fruittree_overlap50)

##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_fruittree_overlap50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs

#### 95% Area
lmer_fruittree_overlap95 <- lmer(fruittree_normalized ~ area+dominance+(1 | focal)+(1| n_fllws)+(1| algorithm),all_overlaps_95_naomit,REML=FALSE)
anova(lmer_fruittree_overlap95,lmer_overlap_all_nullmodell_95)
summary(lmer_fruittree_overlap95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_fruittree_overlap95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs


## AGECAT Explain tree normalized
all_overlaps_50_naomit <- all_overlaps_50 %>%  dplyr::select(area,n_fllws,overlap,fruittree_normalized,agecat,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup() 
all_overlaps_95_naomit <- all_overlaps_95 %>% dplyr::select(area,n_fllws,overlap,fruittree_normalized,agecat,period,focal,focal.1,algorithm) %>% na.omit() %>% ungroup()
lmer_overlap_all_nullmodell_95 <- lmer(fruittree_normalized ~ (1 | focal)+(1| n_fllws)+(1|algorithm),all_overlaps_95_naomit,REML=FALSE)
lmer_overlap_all_nullmodell_50 <- lmer(fruittree_normalized ~ (1 | focal)+(1| n_fllws)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)

all_overlaps_95_naomit %>% ggplot(aes(as.factor(agecat),fruittree_normalized,colour=area))+
  geom_boxplot() +
  geom_jitter()


#### Core area
lmer_fruittree_overlap50 <- lmer(fruittree_normalized ~ area+agecat+(1 | focal)+(1| n_fllws)+(1| algorithm),all_overlaps_50_naomit,REML=FALSE)
anova(lmer_fruittree_overlap50,lmer_overlap_all_nullmodell_50)
summary(lmer_fruittree_overlap50)

##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_fruittree_overlap50)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs

#### 95% Area
lmer_fruittree_overlap95 <- lmer(fruittree_normalized ~ area+agecat+(1 | focal)+(1| n_fllws)+(1| algorithm),all_overlaps_95_naomit,REML=FALSE)
anova(lmer_fruittree_overlap95,lmer_overlap_all_nullmodell_95)
summary(lmer_fruittree_overlap95)
##### Create P values for lm
coefs <- data.frame(coef(summary(lmer_fruittree_overlap95)))
# use normal distribution to approximate p-value
coefs$p.z <- 2 * (1 - pnorm(abs(coefs$t.value)))
coefs


summary(lmer_overlap_all_fullmodell_50)
sjPlot::tab_model(lmer_overlap_all_fullmodell_50, digits=4,
                  show.re.var= TRUE,
                  dv.labels= "Effects of internal and external factors on DJL")
ranova(lmer_overlap_all_fullmodell_50)
view(as.data.frame(vif.mer(lmer_overlap_all_fullmodell_50)))
r.squaredGLMM(lmer_overlap_all_fullmodell_50)
anova(lmer_overlap_all_nullmodell_50,lmer_overlap_all_fullmodell_50)

summary(hr_all_fullmodell_50)
sjPlot::tab_model(hr_all_fullmodell_50, digits=4,
                  show.re.var= TRUE,
                  dv.labels= "Effects of internal and external factors on DJL")
ranova(hr_all_fullmodell_50)
view(as.data.frame(vif.mer(hr_all_fullmodell_50)))
r.squaredGLMM(hr_all_fullmodell_50)
anova(hr_all_nullmodell_50,hr_all_fullmodell_50)


# See if overlap and homeranges are significantly different. Explaining normalized fruittree count
### Fruittreeindex
temp_fruittreediffoverlaps<- all_overlaps_allperiods %>% filter(algorithm=="brb") %>%   dplyr::select(area=overlap,hrprcnt,fruittree_normalized,algorithm) %>% mutate(type="overlap") 
temp_fruittreediffoverlaps2<- all_homeranges_sf %>% filter(algorithm=="brb")  %>% filter(hminfac==0.8) %>%  dplyr::select(area,hrprcnt,fruittree_normalized,algorithm)%>% mutate(type="range")%>% st_drop_geometry()
temp_fruittreediffoverlaps <- temp_fruittreediffoverlaps %>% rbind(temp_fruittreediffoverlaps2)


plot_comparisonfruittrees_50<- temp_fruittreediffoverlaps %>% filter(hrprcnt!="99%") %>%  ggplot(aes(as.factor(type),fruittree_normalized,colour=area))+
  geom_jitter(alpha=0.2)+
  geom_boxplot(alpha=0.6)+
  #ylim(0,0.2)+
  facet_grid(.~hrprcnt)+
  labs(y="normalized trees [tree/tot gps effort]",x="")
plot_comparisonfruittrees_50
plot_comparisonfruittrees_50 %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "plot_comparisonfruittrees_brb08",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=300,width = 21,height = 15,units="cm")

lmer_diff_overlap_hr_zero <- lmer(fruittree_normalized ~ (1| algorithm),temp_fruittreediffoverlaps,REML=FALSE)
lmer_diff_overlap_hr <- lmer(fruittree_normalized ~ area+type+(1| algorithm),temp_fruittreediffoverlaps,REML=FALSE)
anova(lmer_diff_overlap_hr_zero,lmer_diff_overlap_hr)
summary(lmer_diff_overlap_hr)


FTC_overlaps_HR_comaparison<- all_overlaps %>%
  #filter(algorithm=="brb") %>% 
  #filter(hminfac==1) %>%  
  ggplot(aes(overlap,fruittree_normalized))+
  geom_point(aes(color=hrprcnt),size=2,shape=8)+
  geom_point(data=temp_fruittreediffoverlaps2,aes(area,fruittree_normalized,color=hrprcnt),alpha=0.8)+
  labs(x=expression("overlap or area [km"^2*"]"),y=expression("normalized trees [tree/tot gps effort]"),color="HR [%]") +
  scale_fill_viridis()
FTC_overlaps_HR_comaparison
FTC_overlaps_HR_comaparison %>% ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis/figures/",
    format(Sys.Date(), "%Y%m%d"),"_",
    "FTC_overlaps_HR_comaparison",
    sep = ""
  ),
  "png",
  sep = "."
),dpi=600,width = 21,height = 21,units="cm")



#### Comparison boxplot core range home range


all_homeranges_sf %>% 
  filter(algorithm=="kde")  %>% 
  #filter(hminfac==0.8) %>%  
  filter(bndwthm=="HSCV") %>% 
  dplyr::select(area,fruittree_normalized,hrprcnt) %>% 
  st_drop_geometry() %>% 
  ggplot(aes(as.factor(hrprcnt),fruittree_normalized,colour=area))+
  geom_jitter(alpha=0.2)+
  geom_boxplot(alpha=0.6)+
  ylim(0,0.2)+
  labs(y="normalized trees [tree/tot gps effort]",x="")

```

```{r DELETE Homerange - Normalized fruit tree points,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE}
SUAQ_waypoints_11all20_loc_tree <- SUAQ_waypoints_11all20_loc %>% filter(PtType=="tree")
SUAQ_waypoints_11all20_loc_tree_sf <-  st_as_sf(SUAQ_waypoints_11all20_loc_tree, 
                          coords = c("E","N"), 
                          crs = 23867) # can also do that in the new sricpt
SUAQ_waypoints_11all20_loc_tree_sf_xy <- SUAQ_waypoints_11all20_loc_tree_sf %>% dplyr::select(geometry)
#### Create a agggregated tree dataset. Distance of trees minimum 20m to be aggregated
data(meuse)
pts <- st_as_sf(meuse, coords = c("x", "y"),remove=FALSE)

# This will give lots of warnings since there are non-numeric columns
pts_agg <- aggregate.sf(pts, pts, mean, 
     join = function(x, y) st_is_within_distance(x, y, dist = 100))


#### Create a raster over research area with resolution in meter
resolution <- 25
r <- raster(xmn=xmin, ymn=ymin, xmx=xmax, ymx=ymax, res=resolution)
r[] <- 0

# note that you should use (lon, lat), in that order!
SUAQ_waypoints_11all20_loc_tree_xy <- SUAQ_waypoints_11all20_loc_tree %>% dplyr::select(E,N)
r_trees <- rasterize(SUAQ_waypoints_11all20_loc_tree_xy, r, fun="count")
plot(r_trees)

# note that you should use (lon, lat), in that order!
SUAQ_waypoints_11all20_loc_xy <- SUAQ_waypoints_11all20_loc %>% dplyr::select(E,N)
r_allGPS <- rasterize(SUAQ_waypoints_11all20_loc_xy, r, fun="count")
plot(r_allGPS)


normalized_tree <- overlay(r_trees, r_allGPS, fun="/")
plot(normalized_tree)



#### Visuals
#### Analyze ??: distribution of weather?
test<- ggplot()+
  #geom_path(aes(E,N), alpha = 0.7,size=0.5)+
  geom_sf(data = pts_agg,
                                               aes(colour = "green"),
                                               colour = "green")+
  geom_sf(data = pts,
                                               aes(colour = "black"),
                                               colour = "black",size=0.5)
  
ggplotly(test)


```


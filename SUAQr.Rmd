---
title: "Projekt"
author: "Stefan Graf"
date: "28 3 2020"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### GITHUB 
## Loading environment / libraries

# Todo:
# Doppelte GPS Dateien löschen
# Follows wo mehr als 30% der Punkte nicht in den hauptbeobachtungsphasen sind 7h nach vorne schieben.


# Activity mittels Liste aus word herauslesen oder die levels des 2017/18 sheets nutzen. Mittels grepl etc. dann wird es auch automatisch mit activity in 2017/18 verknüpft

# Follow Type --> Besser umschreiben bis jetzt mit regex gearbeitet. Grosse 2 Buchstaben geparsed vielleicht eher mit grepl arbeiten. Siehe abschnitt beim einlesen des Followtypes --> bereits entwurf vorhanden.

# Auseinandernehmen von FoodtypeOrIndividualOrDirection /SpeciesOrDistance  attribute in 2017/18 daten

# Data handling
# Zeiten kontrollieren ob bei Originaldatei in den Tracks (anhand Dateiname) teilweise GPS Messungen mit viel späterem Zeitpunkt zwischendrin vorkommen


# Get rid of points in camp

# Maybe find out whats wrong with points which are not in bounding box (see Processing script end) --> Probably Northing and easting is the same but why and which follow?

# Filter out impossible steplengths and steps



# Update Todo:
# Follows where focal names of followlog and GPS doesnt match after processing
# Follows where multiple focal names occur for one follownumber FN720 1102, 2915, 9999, and all FN of automatically given numbers above 1100019
# Looking at edges and distances of over 100, 200, 300m maybe some of them getting rid of by solving the above






# Markings:
#### Quality check: --> are quality checks of chunks executed before
########### DELETE ############--> are chunks to delete
## Title --> are titles for sections
### explanations of the following chunk
##### SUAQ TRACKS 2018 & 2019 ##### --> Code sections to understand code better

```{r import, echo= 'F',results='hide'}
# CLASSICAL PACKAGE IMPORTER (Stefan Graf & Tobias Frey)
packages_checker <- function(packages_list){
  for (package in packages_list){
    if (!require(package, character.only = T)) {
      install.packages(package)
    }
    library(package, character.only = T)
  }
}
packages_checker(
  c('tmaptools',# read_gpx function
    'plotKML',# read GPX to dataframe
    'lubridate',
    'zoo',
    'data.tree',
    'hR',# making realtionships of orangutans
    'dbplyr',
    'plyr',
    'dplyr',
    'tidyr',
    'tidyverse',
    'sf', # Simple feature --> super spatial data handling structure
    'raster', # For raster data
    'ggspatial',
    'rgdal',
    'data.table',
    'RColorBrewer', # color schemas from color brewer web
    'ggraph', # visualization
    'igraph',
    'tmap',
    'scales',
    'trajr',
    'plotly', # zoomable, pannable ggplot
    'mapview',
    'ggmap', # easier interactive ggmaps 
    'leaflet', # Javascript library (originally) for plotting on a maptile interactive map
    'tmap',
    'stringr',
    'remotes', # geom_convexhull function
    'magrittr',
    'ggridges',
    'forcats',
    'move',# Brownian Bridge Movement Model
    'adehabitatHR',
    'ggpubr',
    'htmlwidgets',
    'gridExtra',# additional to ggplot, can add a density plot on the side of a histogram "marginal plot"
    'grid',
    'ggExtra'
    ))
rm(list = ls())
getwd()





### CUSTOM FUNCTIONS ###

# Function for displaying scale labels in ggplot not as f.e. 4e+05
fancy_scientific <- function(l) {
     # turn in to character string in scientific notation
     l <- format(l, scientific = TRUE)
     # quote the part before the exponent to keep all the digits
     l <- gsub("^(.*)e", "'\\1'e", l)
     # turn the 'e+' into plotmath format
     l <- gsub("e", "%*%10^", l)
     # return this as an expression
     parse(text=l)
}


clockS = function(t){hour(t)*3600+minute(t)*60+second(t)}
st_kde <- function(points,cellsize, bandwith, extent = NULL){
  require(MASS)
  require(raster)
  require(sf)
  if(is.null(extent)){
    extent_vec <- st_bbox(points)[c(1,3,2,4)]
  } else{
    extent_vec <- st_bbox(extent)[c(1,3,2,4)]
  }
  
  n_y <- ceiling((extent_vec[4]-extent_vec[3])/cellsize)
  n_x <- ceiling((extent_vec[2]-extent_vec[1])/cellsize)
  
  extent_vec[2] <- extent_vec[1]+(n_x*cellsize)-cellsize
  extent_vec[4] <- extent_vec[3]+(n_y*cellsize)-cellsize
  
  coords <- st_coordinates(points)
  matrix <- kde2d(coords[,1],coords[,2],h = bandwith,n = c(n_x,n_y),lims = extent_vec)
  raster(matrix)
}



st_read_GPX_followertracks <- function(flnm){
    out <- tryCatch(
        { message("Try to read file")
            file <- data.frame()
            start <- Sys.time()
            file <- as.data.frame(st_read(flnm,layer = "track_points")) # better than read_GPX
            #if(class(file)[1]=="list"){file <- file$waypoints} # only use if read_GPX is used
            end <- Sys.time()
            processduration <- end-start
            file <- file %>% #Skip the first 16 rows because see below
              mutate(fileN=substr(flnm, 33,(nchar(flnm)+1)-5))
            
            return(file)
        },
        error=function(cond) {
            message(paste("File seems not to exist: ", flnm))
            message("Here's the original error message:")
            message(cond)
            # Choose a return value in case of error
            return(data.frame()) # use dataframe as return instead of NA --> See here why, without it throws an error. https://stackoverflow.com/questions/48512461/error-in-bind-rows-x-id-argument-1-must-have-names-using-map-df-in-purrr
        },
        warning=function(cond) {
            message(paste("Loading file didn't work", flnm))
            message("Here's the original warning message:")
            message(cond)
            # Choose a return value in case of warning
            return(data.frame())
        },
        finally={
            message(paste("Processed URL: ", flnm," Duration: ",processduration))
            message("Finished")
        }
    )    
    return(out)
}


st_read_GPX_waypoints <- function(flnm){
    out <- tryCatch(
        { message("Try to read file")
            file <- data.frame()
            start <- Sys.time()
            file <- st_read(flnm,layer = "waypoints") # better than read_GPX
            #if(class(file)[1]=="list"){file <- file$waypoints} # only use if read_GPX is used
            end <- Sys.time()
            processduration <- end-start
            file <- file %>% #Skip the first 16 rows because see below
              mutate(fileN=substr(flnm, 33,(nchar(flnm)+1)-5))
            temp_id <- rownames(file)
            file <- cbind(originalFileRownumber=as.integer(temp_id), file)
            
            return(file)
        },
        error=function(cond) {
            message(paste("File seems not to exist", flnm))
            message("Here's the original error message:")
            message(cond)
            # Choose a return value in case of error
            return(data.frame()) # use dataframe as return instead of NA --> See here why, without it throws an error. https://stackoverflow.com/questions/48512461/error-in-bind-rows-x-id-argument-1-must-have-names-using-map-df-in-purrr
        },
        warning=function(cond) {
            message(paste("Loading file didn't work", flnm))
            message("Here's the original warning message:")
            message(cond)
            # Choose a return value in case of warning
            return(data.frame())
        },
        finally={
            message(paste("Processed URL: ", flnm," Duration: ",processduration))
            message("Finished")
        }
    )    
    return(out)
}



#### Custom functions for analysis
clockS = function(t){hour(t)*3600+minute(t)*60+second(t)}


euclid <- function(x1,y1,x2,y2){
  return(sqrt((x1-x2)^2+(y1-y2)^2))
}

turning_angle <- function(x,y,lead_lag = 1){ 
  if(length(x) < 3){return(NA)}
  if(length(x) != length(y)){stop("x and y must be of the same length")}
  p1x <- lag(x,lead_lag)
  p1y <- lag(y,lead_lag)
  p2x <- x
  p2y <- y
  p3x <- lead(x,lead_lag)
  p3y <- lead(y,lead_lag)
  p12 <- euclid(p1x,p1y,p2x,p2y)
  p13 <- euclid(p1x,p1y,p3x,p3y)
  p23 <- euclid(p2x,p2y,p3x,p3y)
  rad <- acos((p12^2+p23^2-p13^2)/(2*p12*p23))
  grad <- (rad*180)/pi
  grad[p12 == 0 | p23 == 0] <- NA
  d <-  (p3x-p1x)*(p2y-p1y)-(p3y-p1y)*(p2x-p1x)
  d <- ifelse(d == 0,1,d)
  d[d>0] <- 1
  d[d<0] <- -1
  d[d==0] <- 1
  turning <- grad*d*-1+180
  return(turning)
}

# Source https://exploratory.io/note/kanaugust/1701090969905358
calculate_mode <- function(x) {
  uniqx <- unique(na.omit(x))
  uniqx[which.max(tabulate(match(x, uniqx)))]
}

mutate_cond <- function(.data, condition, ..., envir = parent.frame()) {
  condition <- eval(substitute(condition), .data, envir)
  .data[condition, ] <- .data[condition, ] %>% mutate(...)
  .data
}

# credit: https://stackoverflow.com/questions/37610056/how-to-treat-nas-like-values-when-comparing-elementwise-in-r/37610515
`%!=na%` <- function(e1, e2) (e1 != e2 | (is.na(e1) & !is.na(e2)) | (is.na(e2) & !is.na(e1))) & !(is.na(e1) & is.na(e2))
```

#### SUAQ research site
## Preprocessing
1. Getting data from excel/csv files
2. Getting data from gpx files, clean and order it
3. Merge Files
```{r GPS Processing}
# ,echo=FALSE, message=FALSE,comment=FALSE, warning=FALSE
start<- Sys.time()

## 0. Loading metadatasets
### 0.1 FollowLog
SUAQ_followlog <- read_csv2("data/202003_SUAQ_FollowLog.csv")
SUAQ_followlog <-
  SUAQ_followlog %>%
  mutate(
    Date = as.Date(Date, format = "%d.%m.%Y"),
    FocalName = tolower(FocalName),
    SexFocal = tolower(SexFocal),
    ClassFocal = tolower(ClassFocal),
    Observer1 = tolower(Observer1),
    Observer2 = tolower(Observer2),
    Observer3 = tolower(Observer3),
    Observer4 = tolower(Observer4),
    Observer5 = tolower(Observer5),
    ClassFocal = if_else(ClassFocal == "fl. male", "flanged male", ClassFocal),
    FocalName = if_else(
      grepl("\\(prob\\)", FocalName),
      str_remove(FocalName, "\\(prob\\)"),
      FocalName
    ),
    ClassFocal = if_else(ClassFocal == "unk", "", ClassFocal)
  )
SUAQ_followlog <- SUAQ_followlog %>%
  mutate(Date = if_else(is.na(Date), as.Date(
    paste(as.numeric(Day), as.numeric(Month), as.numeric(Year)), format = "%d %m %Y"
  ), Date))
SUAQ_followlog <-
  SUAQ_followlog %>% filter(!is.na(FollowNumber) &
                              !is.na(Date)) ## only keep if one of the 2 attributes are available
SUAQ_followlog <-
  SUAQ_followlog[, (colSums(is.na(SUAQ_followlog)) < nrow(SUAQ_followlog))]

#### Manually correcting followlog (See dateeckdaten focal GPS is not same as focal followlog --> Caro Kommentar)
SUAQ_followlog <- SUAQ_followlog %>% # replaces the found focal names of the GPS data which are better specified in the followlog.
  mutate(FocalName=if_else(FollowNumber ==717,"karma",FocalName))
SUAQ_followlog <- SUAQ_followlog %>% # replaces the found focal names of the GPS data which are better specified in the followlog.
  mutate(FocalName=if_else(FollowNumber ==2811,"friska",FocalName))
SUAQ_followlog <- SUAQ_followlog %>% # replaces the found focal names of the GPS data which are better specified in the followlog.
  mutate(FocalName=if_else(FollowNumber ==2599,"tiara",FocalName))

### 0.2 Orangutans names and information
SUAQ_orangutans<- read_csv2("data/20200920_Orangutan_ID.csv")

SUAQ_matriline<- read_csv2("data/20201117_matriline.csv")
SUAQ_matriline <- SUAQ_matriline %>% rename_all(tolower) %>% mutate(focal=tolower(focal))

SUAQ_dob<- read_csv2("data/20201117_offspring.csv")
SUAQ_dob <- SUAQ_dob %>% rename_all(tolower) %>% mutate(focal=tolower(focal))

SUAQ_dob2<- read_csv2("data/20200128_DOB_Suaq.csv")
SUAQ_dob2 <- SUAQ_dob2 %>% rename_all(tolower) %>% mutate(name=tolower(name))
SUAQ_dob <- SUAQ_dob2 %>% left_join(SUAQ_dob,by=c("name"="focal")) 
SUAQ_dob <- SUAQ_dob %>% dplyr::select(-dateofbirth) %>% rename(c("dateofbirth"="setbirthdate","focal"="name"))


SUAQ_orangutans<- SUAQ_orangutans[rowSums(is.na(SUAQ_orangutans)) != ncol(SUAQ_orangutans),]
#### delete empty collumns of orangutan list
SUAQ_orangutans <- SUAQ_orangutans[,(colSums(is.na(SUAQ_orangutans))<nrow(SUAQ_orangutans))]
#### make list lowercase especially names
SUAQ_orangutans %<>% 
  mutate(`Orangutan name`= tolower(`Orangutan name`),
         Sex=tolower(Sex),
         Mother=tolower(.$Mother),
         Class=tolower(.$Class),
         `Age class`=tolower(`Age class`))
SUAQ_orangutans <- SUAQ_orangutans %>% 
  rename(c("AgeClass"="Age class",
           "orangutanname"="Orangutan name",
           "KeyFeatures"="Key features",
           "Facecolour"="Face colour",
           "FaceColour"="Face colour",
           "FaceShape"="Face shape",
           "facialMarks"="facial marks",
           "ThroatSac"="Throat sac",
           "hairOnTopOfHead"="hair on top of head",
           "hairOnSideOfHead"="hair on side of head",
           "HairOnChin"="Hair on chin",
           "OverallBodyColour"="Overall body colour",
           "OverallBodyShape"="Overall body shape",
           "BaldPatches"="Bald patches",
           "FirstRecordedBy"="First recorded by",
           "FirstTrailSeenOn"="First trail seen on",
           "DateFirstSeen"="Date First seen",
           "EstimatedBirthFromFileOnCampHD"="Estimated birth from file on camp HD",
           "SetBirthDateForAnalyses"="Set birth date for analyses",
           "FeetOrToes"="Feet/toes")
         )
##### Attribute additional to orangutan info add matriline infos and focal date of births info
SUAQ_orangutans <- 
  SUAQ_orangutans %>% left_join(SUAQ_matriline, by = c("orangutanname" =
                                                         "focal")) 
SUAQ_orangutans <- SUAQ_orangutans %>% left_join(SUAQ_dob, by=c("orangutanname"="focal"))
SUAQ_orangutans <- SUAQ_orangutans %>% rename(matriline = matriline.x) %>% mutate(
                                                           matriline = if_else( # replacing existing matriline with new infos
                                                             is.na(matriline),
                                                             matriline.y,
                                                             matriline
                                                           )
                                                         )


#### Adding occurences of other unofficial orangutannames written in the followlog
##### Look what combinations are available for sex and name combinations. Result has f.e. double occuring OU where the sex was falsly categorized but also general annotations like "infant, male" & "infant, female" therefore we wanna keep the alias which were used for f.e. infant both male and female but we wanna get rid of double occuring names with two sexes.
SUAQ_followlog_orangutanlevels_sex<-SUAQ_followlog %>% 
  mutate(FocalName=tolower(.$FocalName),SexFocal=tolower(.$SexFocal)) %>% 
  filter(!grepl("(prob)|(guess)",FocalName)) %>% 
  group_by(FocalName,SexFocal) %>% 
  summarise(n=n())
SUAQ_OUnames_uniquetofollowlog<-as.data.frame(
    setdiff(
      SUAQ_followlog_orangutanlevels_sex$FocalName,
      SUAQ_orangutans$orangutanname
    )
  ) %>% rename(FocalName = 1) %>% mutate(SUAQ_nameonlyoccurredinfollowlog =
                                           TRUE) %>% right_join(SUAQ_followlog_orangutanlevels_sex,
                                                                by = c("FocalName" = "FocalName") ) %>% 
filter(.$SUAQ_nameonlyoccurredinfollowlog) # if new NAME (not any alias which mainly descirbes orangutan like infant, adoloscent etc) occur with two types of sexes it takes just the second gender it doesn't control on number of occurences.

##### Adding all orangutannames and sexes which are not in the official orangutan list. If two names and 
for(i in c(1:nrow(SUAQ_OUnames_uniquetofollowlog))) {
  if (!(SUAQ_OUnames_uniquetofollowlog$FocalName[i] %in% SUAQ_orangutans$orangutanname)) {
    print(
      paste(
        "Adding Orangutan: ",
        SUAQ_OUnames_uniquetofollowlog$FocalName[i],
        "with sex: ",
        SUAQ_OUnames_uniquetofollowlog$SexFocal[i]
      )
    )
    SUAQ_orangutans <-
      SUAQ_orangutans %>% add_row(orangutanname = SUAQ_OUnames_uniquetofollowlog$FocalName[i],
                                  Sex = SUAQ_OUnames_uniquetofollowlog$SexFocal[i],
                                  Comments = "automatically added from followlog")
  }
}
SUAQ_OUnames_uniquetofollowlog <- NA
SUAQ_followlog_orangutanlevels_ex <- NA

SUAQ_orangutans<- SUAQ_orangutans %>% drop_na(orangutanname) %>% 
  mutate(Class=if_else(Class=="flanging","flanged male", Class)) %>% 
  mutate(Class=if_else(Class=="adolescent","juvenile",Class))

### 0.3 GPX of path network in SUAQ
SUAQ_pathnetwork<- as.data.frame(read_GPX(file="data/SUAQ_Peta_WithLines.GPX",layers = c("routes")))
colnames(SUAQ_pathnetwork)[15]<- "geometry"
SUAQ_pathnetwork_sf<- st_as_sf(SUAQ_pathnetwork,crs=4326)
SUAQ_pathnetwork_sf_loc <- st_transform(SUAQ_pathnetwork_sf,crs = 32647)


SUAQ_locationnetwork_sf <- st_read("data/20201201_StudyBalimbingStudyArea_points.GPX")
SUAQ_locationnetwork_sf_loc <- st_transform(SUAQ_locationnetwork_sf,crs = 32647)

##### for locale coordinate system
coordinates_tmp <- st_coordinates(SUAQ_locationnetwork_sf)
colnames(coordinates_tmp) <- c("E","N")
SUAQ_locationnetwork_sf <- cbind(SUAQ_locationnetwork_sf,coordinates_tmp)
SUAQ_locationnetwork <- st_drop_geometry(SUAQ_locationnetwork_sf)

##### for locale coordinate system
coordinates_tmp <- st_coordinates(SUAQ_locationnetwork_sf_loc)
colnames(coordinates_tmp) <- c("E","N")
SUAQ_locationnetwork_sf_loc <- cbind(SUAQ_locationnetwork_sf_loc,coordinates_tmp)
SUAQ_locationnetwork_loc <- st_drop_geometry(SUAQ_locationnetwork_sf_loc)



### 0.4 FAI data 
SUAQ_fai<- read_csv2("data/20201117_FAI.csv")
SUAQ_fai <- SUAQ_fai %>% rename_all(tolower)
names(SUAQ_fai) <- paste0("SUAQ_fai.", names(SUAQ_fai))

### 0.4 Weather data 
SUAQ_weather<- read_delim("data/20201117_SUAQ_weather.csv",delim=";")
SUAQ_weather <- SUAQ_weather %>% rename_all(tolower) %>% filter(!(is.na(year)|is.na(daymonthyear)|is.na(month)))
SUAQ_weather <- SUAQ_weather %>% rowwise() %>% 
  mutate(avg_temperature_tot=mean(c(min_temp_average,max_temp_average),na.rm=TRUE),
         rainfall_avg=mean(c(as.numeric(rainfall_ml_morning),as.numeric(rainfall_ml_evening)),na.rm=TRUE))
names(SUAQ_weather) <- paste0("SUAQ_weather.", names(SUAQ_weather))

## 1. Getting data from excel/csv files for year 2017/18
SUAQ_waypoints_17_18 <- read_csv2("data/20201231_Master_GPS_Suaq_2017_Mar18_SG.csv")
SUAQ_waypoints_17_18<- SUAQ_waypoints_17_18[,1:16] # drop last collumns

originalFileRownumber <- rownames(SUAQ_waypoints_17_18)
SUAQ_waypoints_17_18 <- cbind(originalFileRownumber=as.integer(originalFileRownumber), SUAQ_waypoints_17_18)


SUAQ_waypoints_17_18 <- SUAQ_waypoints_17_18 %>% 
  mutate(Focal=tolower(Focal), 
         gpsextraction="Steven Hayward",
         gpsextractionquality = "very bad. GPS file as GPX with no metadata, FN already indicated, timezones sometimes different but not indicated, then joined further info (attribute states from where with '.')",
         Age.Sex = if_else(`Age Sex`=="adolescent","juvenile",`Age Sex`),
         automaticDatetime=dmy_hms(paste(.$Date,.$`Actual Time`), tz = "Asia/Pontianak"),
         manualDatetime=dmy_hms(paste(.$Date,.$Time), tz = "Asia/Pontianak"),
         manualDate=date(dmy(paste(.$Date), tz = "Asia/Pontianak")),
         manualTime=hms::as_hms(.$Time), # returns a difftime as hopefully the tz isn't important or its saved in the right way.
         automaticDate=date(dmy(paste(.$Date), tz = "Asia/Pontianak")),
         automaticTime=hms::as_hms(.$`Actual Time`),
         `Follow #`=as.character(`Follow #`),
         fileN=as.character(`Follow #`),
         `Point Type`=tolower(`Point Type`),
         `Age Sex`=tolower(`Age Sex`),
         Activity=tolower(Activity),
         Focal = if_else(Focal=="caeser","caesar",Focal),
         Focal = if_else(Focal=="zackey","zacky",Focal))%>% 
    rename(c("follow"="Follow #",
           "followtype"="Follow Type",
           "ele"="Altitude",
           "PtType"="Point Type",
           "SpeciesOrDistance"="Species / Distance",
           "FoodtypeOrIndividualOrDirection"="Food Type / Individual / Direction",
           "focal"="Focal",
           "FollowIndData"="Follow#=IndData?",
           "AgeSex"="Age.Sex")) %>% 
  dplyr::select(-`Actual Time`,-Time)



##### CRS Code: EPSG 32647
##### Create SF Points
SUAQ_waypoints_17_18_sf <-  st_as_sf(SUAQ_waypoints_17_18, 
                          coords = c("X","Y"), 
                          crs = 32647)
coordinates_tmp <- st_coordinates(SUAQ_waypoints_17_18_sf)
colnames(coordinates_tmp) <- c("E","N")
SUAQ_waypoints_17_18_sf <- cbind(SUAQ_waypoints_17_18_sf,coordinates_tmp)
SUAQ_waypoints_17_18 <- st_drop_geometry(SUAQ_waypoints_17_18_sf)


## 2.  Suaq tracks data 2010-2020
### 2.1 Getting data from gpx files, clean and order it
##### Create a list of all gpx files
suaq_gpx_list<- list.files(path = "./data/20200717_All_stedit/gpx/",pattern = "*.gpx",full.names = T)

##### Import WAYPOINTS of gpx: files from files list, only retrieving waypoints (no automatically saved trackpoints) and adding the filename as attribute
start_time <- Sys.time()
SUAQ_waypoints_11_20<- suaq_gpx_list%>% 
  map_df(~st_read_GPX_waypoints(.))
end_time <- Sys.time()
print(start_time-end_time)
##### Two follows throw an error --> 20200225_Lois_Ahmad_FN, 20200225_Otto_Armas_FN are empty --> deleted from data files (not from delivery files)

##### Import TRACKPOINTS of gpx:
start_time <- Sys.time()
SUAQ_followertracks_11_20<- suaq_gpx_list%>%
  map_df(~st_read_GPX_followertracks(.))
end_time <- Sys.time()
print(start_time-end_time)

### 2.2 Tidying the attributes and values
##### extract the 5 attributes from filename: filedate, orangutanname, infant name, followername, followtype. "Adress" in the first field is left in the list to identify the start of a new list.

SUAQ_waypoints_11_20 <-
  SUAQ_waypoints_11_20 %>% mutate(
    gpsextraction="Stefan Graf",
    gpsextractionquality = "ok. GPS file as GPX with most metadata, then joined further info (attribute states from where with '.')",
    filedate = str_extract(fileN, "\\d{8}"),
    orangutanname = tolower(substr(
      str_extract(fileN, "\\d{8}_[A-Z][a-z]+"),
      10,
      nchar(str_extract(fileN, "\\d{8}_[A-Z][a-z]+"))
    )),
    # Testing
    testing_orangutannameInFollowlog = if_else(grepl(paste(SUAQ_orangutans$orangutanname, collapse="|"), fileN),str_extract(fileN,paste(SUAQ_orangutans$orangutanname, collapse="|")),orangutanname), # Get orangutanname from followlog
    infantname = tolower(substr(
      str_extract(fileN, "_[A-Z][a-z]+(\\([A-Z][a-z]+\\)|[A-Z][a-z]+)"),
      2 + nchar(orangutanname),
      nchar(
        str_extract(fileN, "_[A-Z][a-z]+(\\([A-Z][a-z]+\\)|[A-Z][a-z]+)")
      )
    )),
    followername = tolower(substr( # better approach split by underlines take third argument and test for names occuring in followlog (or a list of employees/ research assistance)
      str_extract(fileN, "_[A-Z][a-z_]+_[A-Z]{2}"),
      2,
      nchar(str_extract(fileN, "_[A-Z][a-z_]+_[A-Z]{2}")) - 3
    )),
    # followtype = substr(
    #   str_extract(fileN, "_[A-Z][a-z_]+_[A-Z]{2}"),
    #   nchar(str_extract(fileN, "_[A-Z][a-z_]+_[A-Z]{2}")) - 1,
    #   nchar(str_extract(fileN, "_[A-Z][a-z_]+_[A-Z]{2}"))
    # ),
    
    ## BESSER? --> following 
    followtype = ifelse(grepl("_NL", fileN),"_NL",NA),
    followtype = ifelse(grepl("_NN", fileN),"NN",followtype),
    followtype = ifelse(grepl("_FL", fileN),"FL",followtype),
    followtype = ifelse(grepl("_NL", fileN),"NL",followtype),
    followtype = ifelse(grepl("_J", fileN),"F",followtype),
    followtype = ifelse(grepl("_Jg", fileN),"F?",followtype),
    followtype = ifelse(grepl("_FN", fileN),"FN",followtype)
)
#### 2.2.1 get rid of empty collumns
SUAQ_waypoints_11_20 <-SUAQ_waypoints_11_20 %>% slice(1:nrow(SUAQ_waypoints_11_20)) # BUG: some kind of bug related to the rbind of rows of sf data frames, when applying the function read_gpx with map_df is causing a problem. The sf df are not index-able and dropping the geometry is also not possible
st_geometry(SUAQ_waypoints_11_20) <- SUAQ_waypoints_11_20$geometry
SUAQ_waypoints_11_20 <- SUAQ_waypoints_11_20[,(colSums(is.na(SUAQ_waypoints_11_20))<nrow(SUAQ_waypoints_11_20))]
#### 2.2.3 creating automatic Datetime (from gps collumn time or collumn cmt) and manual Datetime (from input user GPS Device and from name of Data file)

SUAQ_waypoints_11_20 <-
  SUAQ_waypoints_11_20 %>%
  mutate(
    name_original=name,
    cmt = dmy_hms(cmt, tz = "Asia/Pontianak"),
    time = ymd_hms(time, tz= "MET"),
    manualDatetime = as.POSIXct(
      paste0(ymd(filedate), " ", str_extract(name, "^\\d{4}")),
      format = "%Y-%m-%d %H%M",
      tz = "Asia/Pontianak"
    ),
    # matching string start following 4 digits. Nameing datetime but changeing afterwards (to a real datetime). Just for ordering purposes
    manualDate = date(as.POSIXct(ymd(filedate),
                            format = "%Y-%m-%d",
                            tz = "Asia/Pontianak")),
    manualTime = hms::as_hms(as.POSIXct(
      paste0(str_extract(name, "^\\d{4}")),
      format = "%H%M",
      tz = "Asia/Pontianak"
    )),
  ) %>% mutate(
    automaticDatetime=ymd_hms(cmt, tz = "Asia/Pontianak")
  ) %>% 
  mutate(
    automaticDatetime= if_else(is.na(automaticDatetime),with_tz(time, tz = "Asia/Pontianak"),automaticDatetime),
    manualTime=if_else(is.na(manualTime),hms::as_hms(manualDatetime),manualTime),
    manualDate=if_else(is.na(manualDate),date(manualDatetime),manualDate)
    ) %>% 
  mutate(
    automaticDate = date(automaticDatetime),
    automaticTime = hms::as_hms(automaticDatetime),
    name=str_extract(name, "[^\\d{4} ].*") # not matching the digits in the beginning plus whitespace but everything after
  )

##### adding automatic datetime if 
SUAQ_waypoints_11_20[is.na(SUAQ_waypoints_11_20$automaticDatetime),] %<>% mutate(automaticDatetime = cmt) # piping forth and back. In documentation its written x %<>% foo %>% bar,  its the same as x <- x %>% foo %>% bar. In this case thats not correct!



##### manual adjustment for follows which aren't matching a record in the followlog or have slight differences f.e. focal name is different.
SUAQ_waypoints_11_20<- SUAQ_waypoints_11_20 %<>%mutate(
    orangutanname = if_else(orangutanname=="lilli","lilly",orangutanname),
    orangutanname = if_else(orangutanname=="cissi","cissy",orangutanname),
    orangutanname = if_else(orangutanname=="julia","yulia",orangutanname),
    orangutanname = if_else(orangutanname=="zackey","zacky",orangutanname),
    orangutanname = if_else(fileN=="20130317_Dodi_Unk_FL","dodi",orangutanname),# manual adjustment for follows which aren't matching a record in the followlog or have slight differences f.e. focal name is different.
    orangutanname = if_else(fileN=="20130508_Unk_Unk_FN","pauline",orangutanname),
    orangutanname = if_else(fileN=="20130502_FlMale_Caco_FL","pluto",orangutanname),
    orangutanname = if_else(fileN=="20130510_Jebi_UNK_NL","pauline",orangutanname),
    orangutanname = if_else(fileN=="20130518_UnflMale_Unk_FL","unid.ind.",orangutanname),
    orangutanname = if_else(fileN=="20130925_Ulysses_Toni_NN","unfl.male",orangutanname),
    orangutanname = if_else(fileN=="20130926_Ulysses_Mudini_NN","unfl.male",orangutanname),
    orangutanname = if_else(fileN=="20130508_Unk_Unk_FN","pauline",orangutanname),
    orangutanname = if_else(fileN=="20191002_UnflUnid(U1200)_FL","fez",orangutanname),
    orangutanname = if_else(fileN=="20191129_UnflH1050_Ulil_FN","gura",orangutanname),
    orangutanname = if_else(orangutanname=="caeser","caesar",orangutanname)
  )
SUAQ_waypoints_11_20<- SUAQ_waypoints_11_20 %>% mutate(
  tmp_delete= if_else(
    fileN=="20110128_Karma_Unk_NN"|
    fileN=="20110130_Friska_Wiebe_NL"|
    fileN=="20130317_Dodi(prob)_Unk_FL"|
    fileN=="20130510_Jebi(prob)_UNK_NL",TRUE,FALSE)
) %>% filter(tmp_delete==FALSE)
#### 2.2.4 Extracting information from Name field: PtType--> Type of point: Longcall, Nest etc. See GPS processing information sheet. 
##### To lowercase name collumn
SUAQ_waypoints_11_20<- SUAQ_waypoints_11_20 %>% mutate(name=tolower(name)) # reduces complexity by around 277 combinations to total 897
#### See what are all possible combinations of the name fields (all levels)
SUAQ_wp_namecollumn_levels<- SUAQ_waypoints_11_20 %>% group_by(.$name,.$sym) %>% summarise(count=n())
##### Making naveaid green symbols same as green circles. Probably meant the same. Baseline for this categorization is the excel "Dateneckdaten" there are the main information on how many special cases there are and how they are handled.Manual corrections (for values which are otherwise uncategorizable):
SUAQ_waypoints_11_20$name[SUAQ_waypoints_11_20$name == "<100m 221 degrees"] <- "lc <100m 221 degrees"

##### Changeing altering sym values
SUAQ_waypoints_11_20 <- SUAQ_waypoints_11_20 %>% 
  mutate(sym = if_else(sym=="Horn","Radio Beacon",as.character(sym))) %>% 
  mutate(sym = if_else(sym=="Pin, Green","Flag, Green",as.character(sym)))%>% 
  mutate(sym = if_else(sym=="Navaid, Green","Circle, Green",as.character(sym)))%>% 
  mutate(sym = if_else(sym=="Navaid, Blue","Circle, Blue",as.character(sym)))

SUAQ_waypoints_11_20 <-
  SUAQ_waypoints_11_20 %>% mutate(
    PtType = ifelse((sym == "Circle, Green" |sym == "Navaid, Green") &
                      (grepl("bangun", name)|
                         grepl("arrive", name)|
                         grepl("jumpa", name)|
                         grepl("ketemu", name)|
                         grepl("found", name)|
                         grepl("jmp", name)|
                         grepl("jmpa", name)),
                    "found", # two falsly classified with navaid symbol
                    "unknown"),
    PtType = ifelse((sym == "Circle, Green" |
                       sym == "Navaid, Green") &
                      (grepl("sp", name) | # all with criteria Green + sp are morning nests not something else parsed with sp.
                       grepl("pagi", name)),
                    "mornnest",
                    PtType),
    PtType = ifelse((sym == "Circle, Green" |
                       sym == "Navaid, Green") &
                      (grepl("lost", name)|
                         grepl("lepas", name)|
                         grepl("dilepas", name)|
                         grepl("hilang", name)),
                    "lost", # two falsly classified with navaid symbol
                    PtType),
    PtType = ifelse((sym == "Circle, Green" |
                       sym == "Navaid, Green") &
                      (grepl("sm", name) | 
                         grepl("malam", name)),
                    "nightnest",
                    PtType),
    PtType = ifelse((sym == "Circle, Green" |
                       sym == "Navaid, Green"|
                       sym == "Light") & # single exception
                      (
                        grepl("ss", name) |
                        grepl("play nest", name) | # single exeception
                        grepl("ss1", name) | 
                        grepl("ss2", name) |  
                        grepl("siang", name)
                      ),
                    "daynest",
                    # maximum 3 daynests
                    PtType
    ),
    
    
    
##### Task: --> change every pttype variable above to a different attribute. See which are categorized in multiple groups!
    
    PtType = ifelse((sym == "Block, Blue" ) & (grepl("lch", name)|grepl("lc", name)), # Metainformation for some lch and lcg are not considered because there are only written down for very less points(10-20 points). Information about call direction is given in the activity table
                    "lch",
                    PtType),
    PtType = ifelse((sym == "Block, Blue" ) & grepl("lcg", name),
                    "lcg",
                    PtType),
    PtType = ifelse((sym == "Block, Red" |
                       sym == "Circle, Red") & grepl("dna", name),
                    "DNA sample taken",
                    PtType),
    PtType = ifelse((sym == "Circle, Blue" |
                   sym == "Navaid, Blue"),
                    # until now these symbols are all right categorized 
                    # two falsly classified with navaid symbol
                    "party",
                    PtType),
    PtType_individual = ifelse((sym == "Circle, Blue" |
                   sym == "Navaid, Blue")&
                    grepl(paste(as.vector(SUAQ_orangutans$orangutanname)
, collapse="|"), name),
                    # until now these symbols are all right categorized 
                    # two falsly classified with navaid symbol
                    str_match_all(SUAQ_waypoints_11_20$name,gsub("\\?","\\\\?",paste(as.vector(SUAQ_orangutans$orangutanname),collapse="|"))), # retrieving elements where its matchs an orangutan name in the list and getting the last element of the name string description. (Problem is "s?" in orangutanname list because its used in regex of the grepl function and matches more because the questionmark is not escaped.)
                    NA),
    PtType = ifelse(grepl("exp", name),
                    "experiments", # two falsly classified with navaid symbol
                    PtType),
    PtType = ifelse((sym == "Flag" | sym == "Flag, Green"),
                    "tree", # two falsly classified with navaid symbol
                    PtType),
    PtType = ifelse((sym == "Mine")&grepl("tool", name),
                    "tool", # two falsly classified with navaid symbol
                    PtType),
    PtType = ifelse((sym == "Flag, Red"),
                    "range", # two falsly classified with navaid symbol
                    PtType)
)




SUAQ_waypoints_11_20<- SUAQ_waypoints_11_20 %>%  mutate(
  PtType_individual = ifelse((sym == "Circle, Green" |sym == "Navaid, Green"),
                                 str_match_all(SUAQ_waypoints_11_20$name, 
                                               gsub("\\?", "\\\\?",
                                                  paste(as.vector(SUAQ_orangutans$orangutanname), collapse ="|")
                                                  )
                                               ),
                                 PtType_individual
    ),
  PtType_individual_1=map2_chr(PtType_individual, 1,~.x[.y]),
  PtType_individual_2=map2_chr(PtType_individual, 2,~.x[.y]),
  PtType_individual_3=map2_chr(PtType_individual, 3,~.x[.y]),
  PtType_direction = ifelse(PtType=="lcg" |PtType=="lch",
                            str_extract(name,"\\d+(?!\\d*m)"),NA),
  PtType_distance = ifelse(PtType=="lcg" |PtType=="lch",
                            str_extract(name,"\\d+(?=m)"),NA),
) %>% dplyr::select(-PtType_individual)


## 3.  Suaq tracks data 2020 for males
SUAQ_waypoints_11_20_male <- read_delim("data/20210101_MaleGPSToAdd_stedit.csv",delim = ";")
SUAQ_waypoints_11_20_male <-
  SUAQ_waypoints_11_20_male %>% mutate(
    PtType="range",
    gpsextraction = "Francis Short",
    gpsextractionquality = "bad. GPS file as GPX with no metadata, FN already indicated, then joined further info (attribute states from where with '.')",
    focal = tolower(Focal),
    manualDatetime = parse_date_time(timestamp,orders=c("%d.%m.%y %H%M","%m/%d/%y %H%M"),tz = "Asia/Pontianak"), # takes two different formats which are occuring in the given excelsheet
    manualDate=lubridate::date(manualDatetime),
    manualTime=strftime(manualDatetime, format = "%H:%M:%S",tz = "Asia/Pontianak")) %>% 
  mutate(fileN=group_indices(.,manualDate,focal)) %>% mutate(fileN=as.character(fileN)) %>% 
  dplyr::select(-timestamp,-Focal,-sensor.type )
SUAQ_waypoints_11_20_male <- SUAQ_waypoints_11_20_male %>% mutate(
    focal = if_else(focal=="caeser","caesar",focal),
    focal = if_else(focal=="zackey","zacky",focal)
    )

#### Create sf object
SUAQ_waypoints_11_20_male_sf<- st_as_sf(SUAQ_waypoints_11_20_male, 
                          coords = c("location.long","location.lat"), 
                          crs = 4326)

SUAQ_waypoints_11_20_male_sf <- st_transform(SUAQ_waypoints_11_20_male_sf,32647)
coordinates_tmp <- st_coordinates(SUAQ_waypoints_11_20_male_sf)
colnames(coordinates_tmp) <- c("E","N")
SUAQ_waypoints_11_20_male_sf <- cbind(SUAQ_waypoints_11_20_male_sf,coordinates_tmp)
SUAQ_waypoints_11_20_male<- st_drop_geometry(SUAQ_waypoints_11_20_male_sf)


## 4. Combine Datasets 
### 4.1. Merging 2017-2018 data with the rest
##### CRS Code: EPSG 32647
##### Create SF Points Dataset Waypoints 2010-2020
SUAQ_waypoints_11_20<- st_set_crs(SUAQ_waypoints_11_20,4326)
SUAQ_waypoints_11_20_sf <- st_transform(SUAQ_waypoints_11_20,32647)
coordinates_tmp <- st_coordinates(SUAQ_waypoints_11_20_sf)
colnames(coordinates_tmp) <- c("E","N")
SUAQ_waypoints_11_20_sf <- cbind(SUAQ_waypoints_11_20_sf,coordinates_tmp)
SUAQ_waypoints_11_20<- st_drop_geometry(SUAQ_waypoints_11_20_sf)


##### Create SF Points Dataset trackpoints 2010-2020
SUAQ_followertracks_11_20<- st_as_sf(SUAQ_followertracks_11_20,
                          crs = 4326)
SUAQ_followertracks_11_20_sf <- st_transform(SUAQ_followertracks_11_20,32647)
coordinates_tmp <- st_coordinates(SUAQ_followertracks_11_20_sf)
colnames(coordinates_tmp) <- c("E","N")
SUAQ_followertracks_11_20_sf <- cbind(SUAQ_followertracks_11_20_sf,coordinates_tmp)
SUAQ_followertracks_11_20<- st_drop_geometry(SUAQ_followertracks_11_20_sf)


##### Preparing 2017-18 dataset (is already in right coordinate system)
SUAQ_waypoints_17_18 <- SUAQ_waypoints_17_18 %>% 
  mutate(
    PtType = if_else(PtType == "jumpa", "found", PtType),
    PtType = if_else(PtType == "path", "range", PtType) # PATH values in the data of 2017 to 2018 means ranging points
  )


SUAQ_waypoints_11_20 <-
  SUAQ_waypoints_11_20 %>% 
  rename(
    c("altitude"="ele",
      )
  )%>% 
  mutate(
    "focal" = orangutanname,
    "follow"= NA,
    "AgeSex"= NA) %>% 
  mutate(
    "altitude"=as.character(altitude)
  ) %>% 
dplyr::select(-orangutanname)

SUAQ_waypoints_11all20<- SUAQ_waypoints_11_20 %>%  
  bind_rows(SUAQ_waypoints_17_18) %>% 
  bind_rows(SUAQ_waypoints_11_20_male)
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20%>%
  dplyr::select(-Date,
         -FollowIndData,
         -cmt,
         -desc
         )

# Adding unique identifier
specs_numTotalGPSData_beforeFNjoin <- nrow(SUAQ_waypoints_11all20)
identification <- rownames(SUAQ_waypoints_11all20)
SUAQ_waypoints_11all20 <- cbind(identification=as.integer(identification), SUAQ_waypoints_11all20)


## 5. ADDING FOLLOWNUMBER (JOIN) 
### 5.2. Joining 2011-2020 data with followlog and add information to gps file
##### for the first two follows which are not joined with the followlog it seams the date in the filename is wrong! --> should be 2011 not 2010. This is the case for many more! maybe look on the automatic date!
##### PROBLEMS
specs_AutomaticManualDateNotEqual<- SUAQ_waypoints_11all20 %>% filter(.$manualDate!=.$automaticDate) %>% group_by(.$fileN) %>%   summarise(count=n()) # date automatic and manual not the same


# Temporary files from followlog for joining follownumber (all only checking on two attributes)
# would there be a better approach? Need an algorithm/function which takes several attributes and looks if there is a match for all, all-1,all-2,all-3 until a minima f.e. matching at least followname and followdate.
test <- SUAQ_followlog[,c(2,4,14,19)]

tmp11 <- SUAQ_followlog[,c(2,4,14,19,25)] %>% mutate(tmp_FollowNumber_M_focal_followname_Ftype=FollowNumber) %>%
  dplyr::select(-FollowNumber) # adding followtype to control
tmp1 <- SUAQ_followlog[,c(2,4,14,19)] %>% mutate(tmp_FollowNumber_M_focal_followname=FollowNumber) %>%
  dplyr::select(-FollowNumber)

tmp22 <- SUAQ_followlog[,c(2,4,14,20,25)] %>% mutate(tmp_FollowNumber_M_focal_followname2_Ftype=.$FollowNumber) %>%
  dplyr::select(-FollowNumber)
tmp2 <- SUAQ_followlog[,c(2,4,14,20)] %>% mutate(tmp_FollowNumber_M_focal_followname2=.$FollowNumber) %>%
  dplyr::select(-FollowNumber)

tmp33<- SUAQ_followlog[,c(2,4,14,25)] %>% mutate(tmp_FollowNumber_M_focal_Ftype=.$FollowNumber) %>%
  dplyr::select(-FollowNumber)
tmp3<- SUAQ_followlog[,c(2,4,14)] %>% mutate(tmp_FollowNumber_M_focal=.$FollowNumber) %>%
  dplyr::select(-FollowNumber)

tmp44 <- SUAQ_followlog[,c(2,5,6,7,14,25)] %>% mutate(tmp_FollowNumber_M_focal_concDate_Ftype=.$FollowNumber)  %>% 
  mutate(Date=as.Date(paste0(Year,"-",Month,"-",Day),format = "%Y-%m-%d",tz = "Asia/Pontianak"))%>%
  dplyr::select(-FollowNumber,-Day,-Month,-Year)
tmp4 <- SUAQ_followlog[,c(2,5,6,7,14)] %>% mutate(tmp_FollowNumber_M_focal_concDate=.$FollowNumber)  %>% 
  mutate(Date=as.Date(paste0(Year,"-",Month,"-",Day),format = "%Y-%m-%d",tz = "Asia/Pontianak"))%>%
  dplyr::select(-FollowNumber,-Day,-Month,-Year)

tmp55<- SUAQ_followlog[,c(2,4,14,25)] %>% mutate(tmp_FollowNumber_M_focal_automatic_Ftype=.$FollowNumber) %>% dplyr::select(-FollowNumber)
tmp5<- SUAQ_followlog[,c(2,4,14)] %>% mutate(tmp_FollowNumber_M_focal_automatic=.$FollowNumber) %>% dplyr::select(-FollowNumber)

tmp66<- SUAQ_followlog[,c(2,4,19,25)] %>% mutate(tmp_FollowNumber_M_followname_Ftype=.$FollowNumber) %>%
  dplyr::select(-FollowNumber)
tmp6<- SUAQ_followlog[,c(2,4,19)] %>% mutate(tmp_FollowNumber_M_followname=.$FollowNumber) %>%
  dplyr::select(-FollowNumber)

tmp77<- SUAQ_followlog[,c(2,4,20,25)] %>% mutate(tmp_FollowNumber_M_followname2_Ftype=.$FollowNumber) %>%
  dplyr::select(-FollowNumber)
tmp7<- SUAQ_followlog[,c(2,4,20)] %>% mutate(tmp_FollowNumber_M_followname2=.$FollowNumber) %>%
  dplyr::select(-FollowNumber)

tmp88<- SUAQ_followlog[,c(2,4,14,25)] %>% mutate(tmp_FollowNumber_M_infant_Ftype=.$FollowNumber) %>%
  dplyr::select(-FollowNumber)
tmp8<- SUAQ_followlog[,c(2,4,14)] %>% mutate(tmp_FollowNumber_M_infant=.$FollowNumber) %>%
  dplyr::select(-FollowNumber)

##### Join followlog 
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp11,by=c("manualDate"="Date","focal"="FocalName","followername"="Observer1","followtype"="FollowType"),keep = FALSE,na_matches = "never")
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp1,by=c("manualDate"="Date","focal"="FocalName","followername"="Observer1"),keep = FALSE,na_matches = "never")

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp22,by=c("manualDate"="Date","focal"="FocalName","followername"="Observer2","followtype"="FollowType"),keep = FALSE,na_matches = "never")
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp2,by=c("manualDate"="Date","focal"="FocalName","followername"="Observer2"),keep = FALSE,na_matches = "never")

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  left_join(y=tmp33,by=c("manualDate"="Date","focal"="FocalName","followtype"="FollowType"),na_matches = "never")
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  left_join(y=tmp3,by=c("manualDate"="Date","focal"="FocalName"),na_matches = "never") # Problem some of them match with multiple points (n=+114) adding more hirarchy see above if matching 3 attributes --> more sure which one. "2019-02-08	yulia" n=40 entries also + 20 welche nicht existierten. Follow existiert ähnlich zwei mal aber observername unterschied sich --> Lösung tmp6 und tmp7 zur unterscheidung dieser sehr ähnlichen Followdaten.

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  left_join(y=tmp44,by=c("manualDate"="Date","focal"="FocalName","followtype"="FollowType"),na_matches = "never")
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  left_join(y=tmp4,by=c("manualDate"="Date","focal"="FocalName"),na_matches = "never")

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp55,by=c("automaticDate"="Date","focal"="FocalName","followtype"="FollowType"),keep = FALSE,na_matches = "never")
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp5,by=c("automaticDate"="Date","focal"="FocalName"),keep = FALSE,na_matches = "never")

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp66,by=c("manualDate"="Date","followername"="Observer1","followtype"="FollowType"),keep = FALSE,na_matches = "never")
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp6,by=c("manualDate"="Date","followername"="Observer1"),keep = FALSE,na_matches = "never")

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp77,by=c("manualDate"="Date","followername"="Observer2","followtype"="FollowType"),keep = FALSE,na_matches = "never")
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp7,by=c("manualDate"="Date","followername"="Observer2"),keep = FALSE,na_matches = "never")

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp88,by=c("manualDate"="Date","infantname"="FocalName","followtype"="FollowType"),keep = FALSE,na_matches = "never")
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(y=tmp8,by=c("manualDate"="Date","infantname"="FocalName"),keep = FALSE,na_matches = "never")


temp <- SUAQ_waypoints_11all20 %>% filter(identification %in% c(12184,12185,12186,12187,12188,12189,12190,12191,12192,12193,12194,12195,12196,12197,12198,12199,12200,12201,12202,12203,12204,29043,29044,29045,29046,29047,29048,29049,29050,4743,4744,4745,4746,4747,4748,4749))


SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=as.numeric(follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow)),"high: FN already given in GPS","low: unknown"))

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else((is.na(follow)),as.numeric(tmp_FollowNumber_M_focal_followname_Ftype),follow)) %>% 
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"high: date, name,followtype, observer or more",follownr_reliability))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else((is.na(follow)),as.numeric(tmp_FollowNumber_M_focal_followname),follow)) %>% 
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"high: date, name, observer or more",follownr_reliability))

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow),as.numeric(tmp_FollowNumber_M_focal_followname2_Ftype),follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"high: date, name, followtype, observer2",follownr_reliability))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow),as.numeric(tmp_FollowNumber_M_focal_followname2),follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"high: date, name, observer2",follownr_reliability))

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow),as.numeric(tmp_FollowNumber_M_focal_concDate_Ftype),follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"high: concDate, followtype, name",follownr_reliability))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow),as.numeric(tmp_FollowNumber_M_focal_concDate),follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"high: concDate, name",follownr_reliability))

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow),as.numeric(tmp_FollowNumber_M_focal_Ftype),follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"high: date, followtype, name",follownr_reliability))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow),as.numeric(tmp_FollowNumber_M_focal),follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"high: date, name",follownr_reliability))

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow),as.numeric(tmp_FollowNumber_M_focal_automatic_Ftype),follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"medium: aDate, followtype, name",follownr_reliability))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow),as.numeric(tmp_FollowNumber_M_focal_automatic),follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"medium: aDate, name",follownr_reliability))
# control if FN not already existing somewhere in the dataset because then its probably already given to a follow. But maybe single gps points with missing information about date focal or observer is not matched so hopefully every gps point within the gps follows have the same information and not suddenly some with missing information otherwise they get sorted out here.

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow)&!(tmp_FollowNumber_M_followname_Ftype %in% SUAQ_waypoints_11all20$follow),tmp_FollowNumber_M_followname_Ftype,follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"low: date, followername=observer1, followtype",follownr_reliability))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow)&!(tmp_FollowNumber_M_followname %in% SUAQ_waypoints_11all20$follow),tmp_FollowNumber_M_followname,follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"low: date, followername=observer1",follownr_reliability))

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow)&!(tmp_FollowNumber_M_followname2_Ftype %in% SUAQ_waypoints_11all20$follow),tmp_FollowNumber_M_followname2_Ftype,follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"low: date, followername=observer2, followtype",follownr_reliability))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow)&!(tmp_FollowNumber_M_followname2 %in% SUAQ_waypoints_11all20$follow),tmp_FollowNumber_M_followname2,follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"low: date, followername=observer2",follownr_reliability))

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow)&!(tmp_FollowNumber_M_infant_Ftype %in% SUAQ_waypoints_11all20$follow),tmp_FollowNumber_M_infant_Ftype,follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"low: Date, infantname, followtype",follownr_reliability))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(follow=if_else(is.na(follow)&!(tmp_FollowNumber_M_infant %in% SUAQ_waypoints_11all20$follow),tmp_FollowNumber_M_infant,follow)) %>%
  mutate(follownr_reliability=if_else((!is.na(follow))&(follownr_reliability=="low: unknown"),"low: Date, infantname",follownr_reliability))



### Delete helper collumns
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  dplyr::select(-tmp_FollowNumber_M_focal_followname) %>%
  dplyr::select(-tmp_FollowNumber_M_focal_followname2) %>%
  dplyr::select(-tmp_FollowNumber_M_focal_concDate) %>%
  dplyr::select(-tmp_FollowNumber_M_focal) %>%
  dplyr::select(-tmp_FollowNumber_M_focal_automatic) %>%
  dplyr::select(-tmp_FollowNumber_M_followname) %>%
  dplyr::select(-tmp_FollowNumber_M_followname2) %>%
  dplyr::select(-tmp_FollowNumber_M_infant) %>%
  dplyr::select(-tmp_FollowNumber_M_focal_followname_Ftype)%>%
  dplyr::select(-tmp_FollowNumber_M_focal_followname2_Ftype) %>%
  dplyr::select(-tmp_FollowNumber_M_focal_concDate_Ftype)%>%
  dplyr::select(-tmp_FollowNumber_M_focal_Ftype)%>%
  dplyr::select(-tmp_FollowNumber_M_focal_automatic_Ftype)%>%
  dplyr::select(-tmp_FollowNumber_M_followname_Ftype)%>%
  dplyr::select(-tmp_FollowNumber_M_followname2_Ftype)%>%
  dplyr::select(-tmp_FollowNumber_M_infant_Ftype)

#### Delete manually wrongly duplicated follows where multiple followlogs matched (better would be to make the regex etc and descripton or database better not having these problems)

SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% distinct() # 60 GPS points are added because of the above joins. This means that some added Follownumbers match multiple GPS points in the waypoints dataset.

##### Save number of rows after join
specs_numTotalGPSData_afterFNjoin <- nrow(SUAQ_waypoints_11all20)

##### manually adding follownumber for cases where join with followlog didn't retrieve one. See aditional excel file. "Dateneckdaten"
SUAQ_waypoints_11all20 <-SUAQ_waypoints_11all20 %>% 
  mutate(
    follow=if_else(fileN=="20100921_Ibu_Unk_NL",1000001,follow),
    #follow=if_else(fileN=="20110128_Karma_Sahrol_NL",717,follow),# müsste in followlog angepasst werden
    follow=if_else(fileN=="20110129_Friska_Unk_FN",1000002,follow),
    follow=if_else(fileN=="20110130_Friska_Wiebe_NL",1000003,follow),
    #follow=if_else(fileN=="20130317_Dodi_Unk_FL",951,follow),
    #follow=if_else(fileN=="20130502_FlMale_Caco_FL",970,follow),
    #follow=if_else(fileN=="20130508_Unk_Unk_FN",971,follow),
    follow=if_else(fileN=="20130518_Ellie_Armas_F",1000004,follow),
    follow=if_else(fileN=="20130518_UnflMale_Unk_FL",1000005,follow),
    follow=if_else(grepl("20130603_FriskaFrankie",fileN),1000006,follow),
    follow=if_else(fileN=="20130627_FriskaFrankie_Caco_F",1000007,follow),
    follow=if_else(fileN=="20130630_FriskaFrankieFredy_Raja_F",1000008,follow),
    #follow=if_else(fileN=="20130926_Ulysses_Mudini_NN",1109,follow),
    follow=if_else(fileN=="20150210_UnflMale(R1200)_P1LisaLois_FN_Fikar",1439,follow),
    follow=if_else(fileN=="20190112_Lisa_Fikar_NN",2559,follow),
    #follow=if_else(fileN=="20130925_Ulysses_Toni_NN",1108,follow),
    follow=if_else(fileN=="20190117_Rakus(prob)_Saidi_J",1000009,follow),
    follow=if_else(fileN=="20190303_Tiara_Saidi_FN",2599,follow),
    follow=if_else(fileN=="20190330_Kopi_Adami_NN",2621,follow),
    follow=if_else(fileN=="20190331_Kopi_Adami_NN",2622,follow),
    follow=if_else(fileN=="20190614_Lois_Ulil_NN",2685,follow),
    follow=if_else(fileN=="20190729_FlMale_Luz_J",1000010,follow),
    follow=if_else(fileN=="20190801_Cinnamon_Miftah_J",1000011,follow),
    follow=if_else(fileN=="20190917_Ellie_Saidi_J",1000012,follow),
    follow=if_else(fileN=="20190922_Balu_Luz_J",1000013,follow),
    #follow=if_else(fileN=="20191002_UnflUnid(U1200)_FL",2810,follow),
    follow=if_else(fileN=="20191011_Aqra_Lara_J",1000014,follow),
    follow=if_else(fileN=="20191110_Marjo_J",1000013,follow),
    follow=if_else(fileN=="20190922_Balu_Luz_J",1000015,follow),
    follow=if_else(fileN=="20191110_Sakura_J",1000016,follow),
    follow=if_else(fileN=="20191125_Ellie_Adami_J",1000017,follow),
    #follow=if_else(fileN=="20191129_UnflH1050_Ulil_FN",2873,follow),
    follow=if_else(fileN=="20200117_Balu_Tri_J",1000018,follow),
    follow=if_else(fileN=="20130510_Jebi_UNK_NL",1000019,follow),
    follow=if_else(fileN=="20190209_Yulia_Ulil_NN",2582,follow)
    )



#### Giving a random FN for data of steven hayward 
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% ungroup() %>% 
  mutate(follow=if_else(follow==9999,NA_real_,follow)) %>% 
  group_by(fileN,focal,manualDate,follow) %>% # if .$follow it can be modified later idk why with only "follow" it doesnt work
  mutate(follow = if_else(is.na(follow),as.numeric(cur_group_id()+1100000),follow)) ## adding FN above 11



#### Joining rest of Followlog (after finding all Follownumbers)
names(SUAQ_followlog) <- paste0("SUAQ_followlog.", names(SUAQ_followlog))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  left_join(SUAQ_followlog[,c(2,4,14,16,17,19,20,21,22,23,25,29,30,31,32,33,34,35,36,38,39,40,41,42,43,46,55,56,57,58,59,60,61,62,63,64,65,66,67:74)],by=c("follow"="SUAQ_followlog.FollowNumber"),suffix = c("", "_fromFollowlog"))



##### Focal names in followlog are correct overwrite the ones in GPS data (->See Excel)
temp_FN_whereFLogFocalnameIsCorrect<- c("1106","1039","1043","1085","1106","1479","1480","1481","2219","1697","2024","989","990","2192","2193","2167","974","1042","1041","1184","1439","1518","2263","2280","2188","2238","2272","2272","2272","2272","2272","2272","1606","1650","1651","1187","2198","2270","2271","2286","2288","2289")
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% # replaces the found focal names of the GPS data which are better specified in the followlog.
  mutate(focal=if_else(follow %in% temp_FN_whereFLogFocalnameIsCorrect,SUAQ_followlog.FocalName,focal))

##### Manually defining focalnames based on excel discussed with caroline
temp_FN_whereFLogFocalnameIsCorrect<- c("972","2202","2205","1600","1612","1613","1195","1196","987","988","2265","2269","1934","1937","1941","2256","2258","2261","1281","1284","1110","1116","1118","2941","2915")
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% # replaces the found focal names of the GPS data which are better specified in the followlog.
  mutate(focal=if_else(follow %in% temp_FN_whereFLogFocalnameIsCorrect,SUAQ_followlog.FocalName,focal))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% # replaces the found focal names of the GPS data which are better specified in the followlog.
  mutate(focal=if_else(follow =="1176","tristan",focal))

##### Deleting and manipulating main dataset based on GPS Duplicates analysis
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% dplyr::filter(!(fileN %in% c("20200129_Zackey(Guess)_Armas_NN","20150205_EllieEden_NN_Eric","20110117_Friska_Unk_NN","20110325_Cissy_Unk_NN","20110116_Friska_Unk_NN","20110215_Lisa_SofiaArmas_NN",'20110222_Friska_MudinToni_NN',"20110213_Lisa_SofiaArmas_NN","20110118_Friska_Unk1_NL","20110118_Friska_Unk2_NL","20130509_Jebi(prob)_Armas_NN","20131105_Cissy_UNK_NN","20101217_Friska_Sofia_NN","20101223_Friska_ToniArmas_NN","20100115_Friska_Unk_FN","20110119_Raffi_Unk_FN","20110121_Cissy_Unk_NN","20130323_Halte(prob)_Caco_FN","20130326_Halte(prob)_Caco_NN","20130521_Friska(prob)_Izumi_FN","20200129_Zackey(Guess)_Armas_NN","20150205_EllieEden_NN_Eric","20130630_Lilli_Mudin_FN"))) # 20110222_Friska_MudinToni_NN doesnt work? why? still existing in df

##### Duplicates to delete by id in a strange follow
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% filter(!((identification %in% c(8136,8138,8140,8142,8143,8145,8147))&follow%in%c(1429)))



##### Visualization: Correcting follows where timesetting is probably wrong (f.e. follows in the night)
SUAQ_waypoints_11all20 %>% ggplot(aes(manualTime))+geom_histogram(bins = 1000)
SUAQ_waypoints_11all20 %>% filter(is.na(manualTime)) %>% 
  ggplot(aes(hms::as_hms(automaticTime)))+geom_histogram(bins = 1000) # time before conversion

specs_follows_points_in_night<- SUAQ_waypoints_11all20 %>% 
  filter((manualTime<lubridate::hms("04:30:00"))|(manualTime>lubridate::hms("20:00:00")))
specs_follows_points_in_night_automaticTime<- SUAQ_waypoints_11all20 %>% 
  filter(is.na(manualTime)&(automaticTime<lubridate::hms("04:00:00"))) # probably one outlier and one track in the night. Or wrong time settings

##### Try to correct times by calc the amount of Points lying in the night period of the total follow
result_totnumfollows <- SUAQ_waypoints_11all20 %>% 
  group_by(follow) %>% summarise(follow_totNumOfGPSpoints=n()) # 1323 Follows
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% left_join(result_totnumfollows,by=c("follow"="follow"))

specs_percentageOfFollowGPSPointsInNight<- SUAQ_waypoints_11all20 %>% filter((manualTime<lubridate::hms("04:00:00"))|(manualTime>lubridate::hms("20:00:00"))) %>% group_by(follow,follow_totNumOfGPSpoints) %>%
  summarise(numberOfGPSinNighresting=n())
specs_percentageOfFollowGPSPointsInNight<- specs_percentageOfFollowGPSPointsInNight %>% mutate(percOfPointsInNight=1/(follow_totNumOfGPSpoints/numberOfGPSinNighresting))



##### Manual time corrections (quality unsure is it 6 or 7 hours shift) there are many wrong especially automatic time zones
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% mutate_cond(identification==24101,manualTime=automaticTime) # wrong time for one point probably in fn 2047
SUAQ_waypoints_11all20 <-
  SUAQ_waypoints_11all20 %>% 
  mutate_cond(follow %in% c(2326,1101259,2341,2336,2331,2409,2412,2415,2343),manualDatetime = manualDatetime+hours(7)) %>%  # wrong time for the whole follow
  mutate_cond(follow %in% c(2326,1101259,2341,2336,2331,2409,2412,2415,2343),manualTime =  hms::as_hms(manualDatetime), 
         manualDatetime= ymd_hms(paste(manualDate,manualTime),tz = "Asia/Pontianak")) 

# ##### Correcting some automatic times
# #####  6 hours
# SUAQ_waypoints_11all20 <-
#   SUAQ_waypoints_11all20 %>% 
#   mutate(automaticDatetime = if_else(follow %in% c(), automaticDatetime+hours(6), automaticDatetime)) %>%  # wrong time for the whole follow
#   mutate(automaticTime = if_else(follow %in% c(), hms::as_hms(automaticDatetime), automaticTime), 
#          automaticDatetime= if_else(follow %in% c(), ymd_hms(paste(automaticDate,automaticTime),tz = "Asia/Pontianak"), automaticDatetime)
#            ) # set old date because if time adition goes over midnight date is changed. And that doesnt make sense
# 
# #####  5 hours
# SUAQ_waypoints_11all20 <-
#   SUAQ_waypoints_11all20 %>% 
#   mutate(automaticDatetime = if_else(follow %in% c(), automaticDatetime+hours(6), automaticDatetime)) %>%  # wrong time for the whole follow
#   mutate(automaticTime = if_else(follow %in% c(), hms::as_hms(manualDatetime), automaticTime), 
#          automaticDatetime= ymd_hms(paste(automaticDate,automaticTime),tz = "Asia/Pontianak")) # set old date because if time adition goes over midnight date is changed. And that doesnt make sense


# 1101277 wrong time for all points

##### Changeing altering sym values
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(sym = if_else(sym=="Horn","Radio Beacon",as.character(sym))) %>% 
  mutate(sym = if_else(sym=="Pin, Green","Flag, Green",as.character(sym)))%>% 
  mutate(sym = if_else(sym=="Navaid, Green","Circle, Green",as.character(sym)))%>% 
  mutate(sym = if_else(sym=="Navaid, Blue","Circle, Blue",as.character(sym)))

##### Changeing altering sym values
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(altitude=as.numeric(altitude)) %>% ungroup()

##### Marking points which are way off GPS-Track (Excel) (took out because maybe I am miscorrecting)
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% mutate(PtType=if_else((manualTime==hms::as_hms("	07:00:00"))&(follow==1089),"abnormal off point",PtType)) # strange because another point has also a totally different automatic time. Additionally all other points have an automatic Time within an hour.

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% mutate(PtType=if_else((manualTime==hms::as_hms("12:30:00"))&(follow==1771),"abnormal off point",PtType))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%
  mutate(PtType=if_else((manualTime==hms::as_hms("09:00:00"))&(follow==1776)&(PtType=="range"),"abnormal off point",PtType))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(PtType=if_else((manualTime%in% c(hms::as_hms("08:00:00"),hms::as_hms("10:00:00")))&(follow==1822),"abnormal off point",PtType))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(PtType=if_else((manualTime%in% c(hms::as_hms("17:30:00")))&(follow==1874),"abnormal off point",PtType))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(manualTime=if_else((automaticTime%in% c(hms::as_hms("16:11:30")))&(follow==1819),hms::as_hms("16:00:00"),manualTime))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(manualTime=if_else((automaticTime%in% c(hms::as_hms("18:02:01")))&(follow==1819),hms::as_hms("18:00:00"),manualTime))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(manualTime=if_else((automaticTime%in% c(hms::as_hms("12:21:30")))&(follow==1819),hms::as_hms("12:21:30"),manualTime))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(manualTime=if_else((automaticTime%in% c(hms::as_hms("17:30:25")))&(follow==671),hms::as_hms("17:30:00"),manualTime))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(automaticTime=if_else((automaticTime%in% c(hms::as_hms("06:31:22")))&(follow==1501),hms::as_hms("11:31:22"),automaticTime))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(manualTime=if_else((automaticTime%in% c(hms::as_hms("11:31:22")))&(follow==1501),hms::as_hms("11:31:22"),manualTime))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(manualTime=if_else((automaticTime%in% c(hms::as_hms("13:09:49")))&(follow==1501),hms::as_hms("18:00:00"),manualTime))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(automaticTime=if_else((automaticTime%in% c(hms::as_hms("13:09:49")))&(follow==1501),hms::as_hms("18:09:49"),automaticTime))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(manualTime=if_else((automaticTime%in% c(hms::as_hms("06:30:58")))&(follow==1761),hms::as_hms("06:30:00"),manualTime))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(PtType=if_else((manualTime%in% c(hms::as_hms("06:30:00"),hms::as_hms("10:00:00"),hms::as_hms("13:00:00")))&(follow==1780),"abnormal off point",PtType))


###### Applying automaticTime if manual Time is empty
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% mutate(manualTime=if_else(is.na(manualTime),automaticTime,manualTime))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% mutate(manualDate=if_else(is.na(manualDate),date(automaticDate),manualDate))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate(manualDatetime=if_else(is.na(manualDatetime),ymd_hms(paste(manualDate,manualTime),tz = "Asia/Pontianak"),manualDatetime))

###### Deleting empty E N or Time. To do: Do we really have to delete it.
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% filter(!(is.na(E)|is.na(N)|is.na(manualTime)))

### 5.?. Only keep gps points within Bounding box of 330000-360000N / 323000-328000E because some points are wrong probably the N and the E variable are the same (accidently copied)
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% filter(E>323000 & 
                                                            E<328000 & 
                                                            N>330000 & 
                                                            N<360000)


## 6. Adding informative attributes, cleaning attributes, and finishing data frame
### 6.1. Joining orangutans info
identification <- rownames(SUAQ_orangutans)
SUAQ_orangutans <- SUAQ_orangutans %>% ungroup()
SUAQ_orangutans <- cbind(identification=as.integer(identification), SUAQ_orangutans)

names(SUAQ_orangutans) <- paste0("SUAQ_orangutans.", names(SUAQ_orangutans))
SUAQ_waypoints_11all20 <-
  SUAQ_waypoints_11all20 %>% left_join(SUAQ_orangutans[,c(1:10,38:51)], by = c("focal" = "SUAQ_orangutans.orangutanname"))


##### Cleaning Followtypes
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% # replaces the found focal names of the GPS data which are better specified in the followlog.
  mutate(followtype=if_else(followtype =="Fl","FL",followtype))
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% # replaces the found followtype of the GPS data which are PROBABLY better specified in the followlog. --> Check with caroline to do
  mutate(followtypeGPSoriginal=followtype,
    followtype=if_else(followtype!=SUAQ_followlog.FollowType,SUAQ_followlog.FollowType,followtype))

### 6.2. Joining FAI and Weather info
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% left_join(SUAQ_weather,by=c("manualDate"="SUAQ_weather.daymonthyear"))
SUAQ_waypoints_11all20 <-
  SUAQ_waypoints_11all20 %>% mutate(manualYear = year(manualDate),
                                    manualMonth = month(manualDate)) %>%  left_join(SUAQ_fai,
                                                                                    by = c("manualYear" = "SUAQ_fai.year", "manualMonth" = "SUAQ_fai.monthnum")) %>% dplyr::select(-manualMonth, -manualYear,)

#tmp<- SUAQ_waypoints_11all20 %>% filter(is.na())

### 6.3. Create new variables like offspringage, Sinuosity, DJL, Edge Speed
##### SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% left_join()
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>%  
  mutate(focal=if_else(is.na(focal),SUAQ_followlog.FocalName,focal)) # get missing focal names from SUAQ followlog.


##### Calculate age of focal
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>%  
  mutate(ageFromDOB=time_length(difftime(manualDate, SUAQ_orangutans.dateofbirth), "years")) 

##### Defining current offspring ages

SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>%  
  mutate(ageOfOffspring1=time_length(difftime(manualDate, as.Date(SUAQ_orangutans.offspring1_dob,format= "%d.%m.%y" )), "years"),
         ageOfOffspring2=time_length(difftime(manualDate, as.Date(SUAQ_orangutans.offspring2_dob,format= "%d.%m.%y" )), "years"),
         ageOfOffspring3=time_length(difftime(manualDate, as.Date(SUAQ_orangutans.offspring3_dob,format= "%d.%m.%y" )), "years")
         ) %>%  # get missing focal names from SUAQ followlog.
  mutate(
    ageOfOffspring1 = if_else((ageOfOffspring1>7)|(ageOfOffspring1<0),NA_real_,ageOfOffspring1), # taking a weaning phase of 7 years. And delete minus years of unborn offsprings
    ageOfOffspring2 = if_else((ageOfOffspring2>7)|(ageOfOffspring2<0),NA_real_,ageOfOffspring2),
    ageOfOffspring3 = if_else((ageOfOffspring3>7)|(ageOfOffspring3<0),NA_real_,ageOfOffspring3),
  )
##### get the youngest focal
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% rowwise() %>% 
  mutate(
    ageOfCurrentOffspring=if_else((is.na(ageOfOffspring1)&is.na(ageOfOffspring2)&is.na(ageOfOffspring3)),NA_real_,min(ageOfOffspring1,ageOfOffspring2,ageOfOffspring3,na.rm = TRUE))) %>% ungroup()
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% ungroup()

##### Adding the current offspring name as attribute
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>%  
  mutate(currentOffspring=if_else(ageOfCurrentOffspring%in%c(ageOfOffspring1),SUAQ_orangutans.offspring1_id,NA_character_)) %>%
  mutate(currentOffspring=if_else(ageOfCurrentOffspring%in%c(ageOfOffspring2),SUAQ_orangutans.offspring2_id,currentOffspring)) %>%
  mutate(currentOffspring=if_else(ageOfCurrentOffspring%in%c(ageOfOffspring3),SUAQ_orangutans.offspring3_id,currentOffspring)) %>% 
  mutate(ageOfCurrentOffspring=if_else(is.infinite(ageOfCurrentOffspring),NA_real_,ageOfCurrentOffspring))



##### Deleting duplicates
###### Description of general idea: 1. all duplicates where multiple attributes are the same (E,N,Follow,Focal,manualDatetime and pttype). There select all the first entries if autmaticDatetime is the same aswell or is empty. If autmaticDatetime is different for all grouped rows. Select the row which is nearest to the manualDatetime and keep this rows untouched (specs_selectedDuplicatToKeep), but define the automaticDatetime as the manualDatetime for all the other row ID's (the unselected). 2. for all duplicates where manualDatetime and Focal is the same, do the same as above. Keep the manualDatetime if the automaticDatetime is the nearest of the grouped rows. For the others assign the automaticDatetime as the manualDatetime and if all automaticDatetimes are NA add or subtract one minute of the manualDatetime (add if originalrownumber is bigger/after the selected true row and subtract if the original rownumber is smaller/before the selected row (the row which keeps its manualDatetime).)

specs_duplicates <-
  SUAQ_waypoints_11all20 %>% ungroup() %>% filter(PtType %in% c("daynest","found","lost","mornnest","nightnest","range","tree")) %>%
  group_by(E, N, follow, focal, manualDatetime,PtType) %>%
  summarise(
    count = n(),
    follow = as.character(list(follow)),
    fileN = as.character(list(fileN)),
    automaticDate = as.character(list(automaticDate)),
    manualDate = as.character(list(as.character(manualDate))),
    automaticTime = list(automaticTime),
    manualTime = list(as.numeric(manualTime)),
    identification=list(identification)
    ) %>% ungroup()
specs_duplicates<- specs_duplicates%>% filter(count>1) # retrieve duplicates where E N Follow Focal and the ManualDatetime is the same. These are must have attributes.

specs_duplicatesWide <- specs_duplicates %>% 
  unnest_wider(automaticTime) %>% 
  rename(c("automaticTime_1"="...1","automaticTime_2"="...2"))
specs_duplicatesWide <- specs_duplicatesWide %>% 
  unnest_wider(manualTime) %>% 
  rename(c("manualTime_1"="...1","manualTime_2"="...2"))
specs_duplicatesWide <- specs_duplicatesWide %>% 
  unnest_wider(identification) %>% 
  rename(c("id_1"="...1","id_2"="...2"))
specs_duplicatesWide <- specs_duplicatesWide %>%
  mutate(sameAtime=automaticTime_1 %in% c(automaticTime_2))

#### From the duplicates get the first row/id of the duplicates where everything is identical also the automaticTime.
specs_duplicatesWideIdentical <- specs_duplicatesWide %>% filter(sameAtime)
specs_selectedDuplicatToKeep <- specs_duplicatesWideIdentical$id_1

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%  dplyr::filter(!(identification %in% specs_selectedDuplicatToKeep)) # only select first id's of the duplicates dataframe, and therefore keep the first rows of the duplicates in the dataset. Hopefully they have the most information but this is not sure. To do a function which would select the row with more information.

#### From the duplicates get the id of the entries where the automaticTime is further off the manualTime. Overwrite the manualTime with the automaticTime and create the manualDatetime newly.
specs_duplicatesDifferentATime <- specs_duplicatesWide %>%  filter(!sameAtime)
specs_duplicatesDifferentATime <- specs_duplicatesDifferentATime %>% 
  mutate(selectedID=if_else(!is.na((automaticTime_1-manualTime_1)<(automaticTime_2-manualTime_1))|is.na(automaticTime_2),id_2,id_1))

SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% 
  mutate_cond(identification %in% specs_duplicatesDifferentATime$selectedID,manualTime=automaticTime) %>%
  mutate_cond(identification %in% specs_duplicatesDifferentATime$selectedID,manualDatetime=ymd_hms(paste(manualDate,manualTime),tz = "Asia/Pontianak"))
  
 
duplicates_datefocal <-
  SUAQ_waypoints_11all20 %>% filter(PtType %in% c("daynest","found","lost","mornnest","nightnest","range","tree")) %>% 
  group_by(focal, manualDatetime) %>%
  summarise(
    count = n(),
    follow = as.character(list(follow)),
    fileN = as.character(list(fileN)),
    automaticDatetime = list(automaticDatetime),
    manualDate = list(as.character(manualDate)),
    automaticTime = list(automaticTime),
    manualTime = list(as.numeric(manualTime)),
    identification=list(as.character(identification)),
    orig_rownumber=list(as.character(originalFileRownumber)),
  ) %>% ungroup()
duplicates_datefocal<- duplicates_datefocal%>% filter(count>1) 

duplicates_datefocal <-duplicates_datefocal %>% unnest_wider(automaticDatetime) %>% 
  rename(c("automaticDatetime1"="...1","automaticDatetime2"="...2","automaticDatetime3"="...3")) %>% 
  mutate(automaticDatetime1=as.POSIXct(automaticDatetime1,tz = "Asia/Pontianak"),
         automaticDatetime2=as.POSIXct(automaticDatetime2,tz = "Asia/Pontianak"),
         automaticDatetime3=as.POSIXct(automaticDatetime3,tz = "Asia/Pontianak"))  # for three rows there is no automaticDatetime


##### Find the ids of points which are the nearest in respect of automatic time to the manual datetime. Create a vector of all the other ids and overwrite the manualTime with the automatic time.
duplicates_datefocal <-duplicates_datefocal %>% ungroup() %>% rowwise() %>% 
  mutate(nearestAutomaticTimeValueKeepTime= ifelse(!all(is.na(c(automaticDatetime1,automaticDatetime2,automaticDatetime3))),
            which.min(abs(c(automaticDatetime1,automaticDatetime2,automaticDatetime3) - manualDatetime)),as.integer(1))) # check if all automatic times are NA then just take the first id as the nearest automatic Time and therefore keep the manualDatetime for this record
duplicates_datefocal <- duplicates_datefocal %>% rowwise() %>% 
  mutate(correctID=identification[nearestAutomaticTimeValueKeepTime])

##### Get all automaticTimes and all records as one row withe the correctID column indicating the right row which keeps its manualDatetime and the identification row indicating the row number which should be altered. Filter out the the rows which are the ones keeping its automaticDatetime seeing if they match itself (the selected id's)
duplicates_datefocal <- duplicates_datefocal %>% 
  unnest_longer(identification) %>% 
  filter(!(correctID==identification)) %>% rowwise() %>% 
  mutate(beforeSelected=if_else(as.numeric(SUAQ_waypoints_11all20$originalFileRownumber[SUAQ_waypoints_11all20$identification==identification])<as.numeric(SUAQ_waypoints_11all20$originalFileRownumber[SUAQ_waypoints_11all20$identification==correctID]),TRUE,FALSE)) # if rownumber of selectedID's (selectedID's are the rows which keep the manualDatetime) is bigger than the rownumber of rows which have to overwrite manualDatetime then TRUE otherwise FALSE. That means if TRUE the time should be corrected back if FALSE the time should be corrected forth.


##### Changeing the manualTime in the main data
SUAQ_waypoints_11all20 <-
  SUAQ_waypoints_11all20%>% rowwise() %>% 
  mutate_cond((identification %in% duplicates_datefocal$identification),
              manualDatetime=if_else(!is.na(automaticDatetime),
                                     automaticDatetime,
                                    if_else(duplicates_datefocal$beforeSelected[duplicates_datefocal$identification==identification]
,manualDatetime-minutes(1),manualDatetime+minutes(1)))) # for the ones where there is no automatic datetime we take a minute after the event to differentiate from the other
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% ungroup()


#### For trackpoints aswell
SUAQ_followertracks_11_20 <-
  SUAQ_followertracks_11_20 %>% filter(E > 323000 &
                                         E < 328000 &
                                         N > 336000 &
                                         N < 365000)


#### Replacing the manualDatetimes which are missing with the first autmaticDatetime of the follows because the once I found were all mornnests
specs_noManualDatetime<- SUAQ_waypoints_11all20 %>% filter(is.na(manualDatetime))
tmp<- SUAQ_waypoints_11all20[order(SUAQ_waypoints_11all20$manualTime , decreasing = FALSE ),] %>%filter(!is.na(manualDatetime)) %>%  group_by(follow) %>% slice_head()
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>%  mutate_cond(is.na(manualDatetime)&&(PtType=="mornnest"),manualDatetime=tmp$automaticDatetime[tmp$follow==follow]-minutes(30))

### 6.5. Cleaning important attributes
##### 6.5.1 Sexes overview
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% mutate(SUAQ_followlog.ClassFocal=if_else(SUAQ_followlog.ClassFocal=="ad.female","adult female",SUAQ_followlog.ClassFocal))
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% mutate(SUAQ_followlog.ClassFocal=if_else(SUAQ_followlog.ClassFocal=="fl.male","flanged male",SUAQ_followlog.ClassFocal))
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% mutate(SUAQ_followlog.ClassFocal=if_else(SUAQ_followlog.ClassFocal=="unfl.male","unflanged male",SUAQ_followlog.ClassFocal))

##### 6.5.2 Clean up class focal if false follow or child/mother change class focal

##### Adding new classFocal variable
SUAQ_waypoints_11all20 <-
  SUAQ_waypoints_11all20 %>% mutate(ClassFocal=as.character(SUAQ_followlog.ClassFocal))

##### Find entries where the focal name of follow is different to the followlog name
specs_ClassFocalWrong <- SUAQ_waypoints_11all20 %>% filter(focal!=SUAQ_followlog.FocalName)
specs_ClassFocalWrong <- SUAQ_waypoints_11all20 %>%filter((ClassFocal!="mother")&(!is.na(ageOfCurrentOffspring)))

#specs_ClassFocalWrong <- SUAQ_waypoints_11all20 %>% filter(focal!=SUAQ_followlog.FocalName) %>%group_by(focal,SUAQ_followlog.FocalName,AgeSex,SUAQ_followlog.ClassFocal) %>% summarise(n())

SUAQ_waypoints_11all20 <-
  SUAQ_waypoints_11all20 %>%
  mutate(ClassFocal=ifelse((identification %in% as.vector(specs_ClassFocalWrong$identification)),NA_character_,ClassFocal))

##### 6.5.3 ClassFocal complement: if ClassFocal is empty/""/unk --> get Class from Orangutan information

#SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% mutate(SUAQ_followlog.ClassFocal=if_else(SUAQ_followlog.ClassFocal=="mother","adult female",SUAQ_followlog.ClassFocal))

##### Writing function: Use !!sym(columnname) for using columnnames in functions where dplyr is used within
own_valuefinder <- function(df,pk,pkcol,replaceterm,startcol,targetcol,lookuptype,datecol){
    out <- tryCatch(
        { #message("Try to find value in target collumn which as temporally/tabullary nearest and not the mentioned to 'replaceterm' or is the most abundant value")
          pk <- as.integer(pk)
          targetvalue <- replaceterm
            if(missing(datecol)) {
              print("Searching in df distance")
              if(lookuptype=="frequency"){
                print("freq search")
                df_forcorrsponvalue<- df %>% filter(targetcol==df$targetcol[which(df$identification == pk),])
                targetvalue <- tail(names(sort(table(df_forcorrsponvalue$targetcol))), 1)
              }
              if(lookuptype=="next"){
                print("next row search")
                df_forcorrsponvalue<- df %>% filter(targetcol==df$targetcol[which(df$identification == pk),])
                index <- which(df_forcorrsponvalue$pkcol == pk)
                for(i in c(1:(nrow(df_forcorrsponvalue)-index))){
                  if(is.na(targetvalue)|(targetvalue==replaceterm)){targetvalue<- df_forcorrsponvalue[index+i,targetcol]
                  paste(print("found target value"),targetvalue)
                  }
                }
              }
              if(lookuptype=="last"){
                print("last row search")
                df_forcorrsponvalue<- df %>% filter(targetcol==df$targetcol[which(df$identification == pk),])
                index <- which(df_forcorrsponvalue$pkcol == pk)
                for(i in c(1:(index-1))){
                  if(is.na(targetvalue)|(targetvalue==replaceterm)){targetvalue<- df_forcorrsponvalue[index-i,targetcol]
                  paste(print("found target value"),targetvalue)
                  }
                }
              }
            } else {
              if(lookuptype=="temporally"){
                #print("search temporally date collumn is given")
                date<- df %>% filter(identification%in%c(pk)) %>% dplyr::select(!!sym(datecol))
                df_row <- df %>% filter(identification%in%c(pk))
                startcol_value <- df_row[,startcol]
                df_forcorrsponvalue<- df %>% filter(focal%in%c(startcol_value))
                df_forcorrsponvalue <-  df_forcorrsponvalue %>% mutate(diff_todate=abs(!!sym(datecol)-date[[1]]))
                df_forcorrsponvalue <-  df_forcorrsponvalue %>% arrange(diff_todate) %>% filter(focal==SUAQ_followlog.FocalName)
                for(i in c(1:nrow(df_forcorrsponvalue))){
                  if(is.na(targetvalue)|(targetvalue==replaceterm)|(targetvalue=="")){
                    targetvalue<- df_forcorrsponvalue[i,targetcol]
                    targetvalue <- as.character(targetvalue)
                    }
                }
              }
            }
          
            return(targetvalue)
        },
        error=function(cond) {
            message("Error")
            message("Here's the original error message:")
            message(cond)
            # Choose a return value in case of error
            return(replaceterm) # use dataframe as return instead of NA --> See here why, without it throws an error. https://stackoverflow.com/questions/48512461/error-in-bind-rows-x-id-argument-1-must-have-names-using-map-df-in-purrr
        },
        warning=function(cond) {
            message("Warning")
            message("Here's the original warning message:")
            message(cond)
            # Choose a return value in case of warning
            return(replaceterm)
        },
        finally={
            if(targetvalue%in%c(replaceterm)){message("Didn't found a value")}
            if(!(targetvalue%in%c(replaceterm))){message(paste(pk,": found target value",targetvalue))}
            #message("Finished")
        }
    )    
    return(out)
}


###### Problem replaceterm why also filter  if we have a replaceterm
SUAQ_waypoints_11all20 <-
  SUAQ_waypoints_11all20 %>% # replace any SexClass value which is unk or NA to the temporally nearest other Sex Class value for this orangutan
  ungroup() %>% rowwise() %>% 
  mutate(ClassFocal = ifelse((is.na(ClassFocal)|(ClassFocal== "unk")),
                                  own_valuefinder(
                                          SUAQ_waypoints_11all20,
                                          identification,
                                          "identification",
                                          "unk",
                                          "focal",
                                          "ClassFocal",
                                          "temporally",
                                          "manualDate"
                                        ),
                             ClassFocal)
         )



### 6.6. Create project Master-Dataframes
##### find strange geometry points delete them
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% ungroup() 
SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% filter(!(identification %in% c(3248))) #inspect point its far away from the follow where it is saved in (FN 989 20130601_Islo_Raja_FN) but it matched to FN 975



### 6.7. Create project Master-Dataframes
##### save all waypoints as sf
SUAQ_waypoints_11all20_sf <-  st_as_sf(SUAQ_waypoints_11all20, 
                          coords = c("E","N"), 
                          crs = 32647)
##### waypoints of female orangutans in SUAQ (attention here the defined gender by the followlog is taken)
SUAQ_waypoints_fem_sf<- SUAQ_waypoints_11all20_sf %>% filter(SUAQ_orangutans.Sex=="female")
SUAQ_waypoints_fem <- SUAQ_waypoints_11all20 %>% filter(SUAQ_orangutans.Sex=="female")

 

#### To do: make type of every collumn right f.e. altitude to integer not string


##### Shiny
write_csv(SUAQ_waypoints_11all20,path="shinyapp/orangapp/data/SUAQ_waypoints_11all20_backup.csv")








# ################################################################################################################################
# ### inspect ####################################################################################################################
# ################################################################################################################################
# #### Quality check for Followlog join: Finding potential falsly joined follownumbers
# ##### FN with multiple dates. Only FN: 9999 which is wrong has fuzzy dates
# specs_FNwithUnUniqueDatesAfterJoin <- SUAQ_waypoints_11all20[FALSE,]
# for(i in levels(as.factor(SUAQ_waypoints_11all20$follow))){
#   df <- SUAQ_waypoints_11all20 %>% filter(follow==i)
#   print(paste0("Follownumber to check if unique: ",i))
#   print((length(unique(df$manualDate)) == 1)) # check if the date of the selected FN-row is unique?
#   if(length(unique(df$manualDate)) != 1){specs_FNwithUnUniqueDatesAfterJoin <- specs_FNwithUnUniqueDatesAfterJoin %>% bind_rows(df)} # add if not unique
# }
# 
# 
# ##### FN with multiple focals?
# specs_FNwithUnUniqueFocalAfterJoin <- SUAQ_waypoints_11all20[FALSE,]
# SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% ungroup()
# for(i in levels(as.factor(SUAQ_waypoints_11all20$follow))){
#   df <- SUAQ_waypoints_11all20 %>% filter(follow==i)
#   print(paste0("Follownumber to check if unique: ",i))
#   print((length(unique(df$focal)) == 1)) # check if the date of the selected FN-row is unique?
#   if(length(unique(df$focal)) != 1){specs_FNwithUnUniqueFocalAfterJoin <- specs_FNwithUnUniqueFocalAfterJoin %>% bind_rows(df)} # add if not unique
# }
# specs_FNwithUnUniqueFocalAfterJoin <- specs_FNwithUnUniqueFocalAfterJoin %>% group_by(follow,focal,manualDate) %>% summarise(count=n())
# 
# 
# ##### Inspecting sex differences and class differences
# specs_FollowlogOrangutanlog_sexdifference <- SUAQ_waypoints_11all20 %>% group_by(follow,focal,manualDate,SUAQ_followlog.SexFocal,SUAQ_orangutans.Sex) %>% summarise(count=n()) %>%  filter(SUAQ_followlog.SexFocal!=SUAQ_orangutans.Sex) # there are 788 difference in sex between joined info
# specs_FollowlogOrangutanlog_ClassDifference <- SUAQ_waypoints_11all20 %>% group_by(follow,focal,manualDate,SUAQ_followlog.ClassFocal,SUAQ_orangutans.Class) %>% summarise(count=n()) %>% filter(SUAQ_followlog.ClassFocal!=SUAQ_orangutans.Class) 
# 
# #### Find places where wrong FN was given. Mostly because an orangutans FN is not given because it was followed during a FN under anothers OU Name f.e. because the GPS is from an infant of the followlogs orangutanname.
# 
# tmp_colnames<- colnames(SUAQ_waypoints_11all20)
# ##### Filter all rows where focal not matching focal name in followlog. Look if any other attribute contains the focal Name of the GPS entry.
# tmp_SUAQ_waypoints_11all20 <- mutate_all(SUAQ_waypoints_11all20, .funs=str_to_lower)
# tmp_SUAQ_waypoints_11all20 <- tmp_SUAQ_waypoints_11all20 %>%
#   filter(focal != SUAQ_followlog.FocalName) %>% rowwise() %>%
#   mutate(
#     missmatch_or_FNambiguity = if_else(
#       grepl(focal, as.character(SUAQ_followlog.Observer1)) |
#         grepl(focal, as.character(SUAQ_followlog.Observer2)) |
#         grepl(focal, as.character(SUAQ_followlog.Observer3)) |
#         grepl(focal, as.character(SUAQ_followlog.Observer4)) |
#         grepl(focal, as.character(SUAQ_followlog.Observer5)) |
#         grepl(focal, as.character(SUAQ_followlog.Comments)) |
#         grepl(focal, as.character(SUAQ_followlog.GPS)) |
#         grepl(focal, as.character(SUAQ_followlog.PartyPresence)) |
#         grepl(focal, as.character(`SUAQ_followlog.M-MParty`)) |
#         grepl(focal, as.character(`SUAQ_followlog.M-FParty`)) |
#         grepl(focal, as.character(`SUAQ_followlog.F-FParty`)) |
#         grepl(focal, as.character(SUAQ_followlog.NrPartymembersOriginal)) |
#         grepl(focal, as.character(SUAQ_followlog.NrPartymembersCorrected)) |
#         grepl(focal, as.character(SUAQ_followlog.P1)) |
#         grepl(focal, as.character(SUAQ_followlog.P2)) |
#         grepl(focal, as.character(SUAQ_followlog.P3)) |
#         grepl(focal, as.character(SUAQ_followlog.P4)) |
#         grepl(focal, as.character(SUAQ_followlog.P5)) |
#         grepl(focal, as.character(SUAQ_followlog.P6)) |
#         grepl(focal, as.character(SUAQ_followlog.P7)),"FNambigous","missmatch"
#     )
#   )
# 
# test <-
#   tmp_SUAQ_waypoints_11all20 %>% group_by(
#     follownr_reliability,
#     focal,
#     follow, # joined follownumber from followlog based on multiple hierarchical criterias
#     fileN,
#     source,
#     testing_orangutannameInFollowlog,
#     infantname,
#     followername,
#     manualDate,
#     SUAQ_followlog.Date,
#     SUAQ_followlog.FocalName,
#     SUAQ_followlog.ClassFocal,
#     SUAQ_followlog.SexFocal,
#     SUAQ_followlog.Observer1,
#     SUAQ_followlog.Observer2,
#     SUAQ_followlog.Observer3,
#     SUAQ_followlog.Observer4,
#     SUAQ_followlog.Observer5,
#     SUAQ_followlog.FollowType,
#     SUAQ_followlog.StartActivity,
#     SUAQ_followlog.EndActivity,
#     SUAQ_followlog.LengthActivity,
#     SUAQ_followlog.ReasonExclude,
#     SUAQ_followlog.Comments,
#     SUAQ_followlog.SpecialFeedingTechniques,
#     SUAQ_followlog.Tools,
#     SUAQ_followlog.Longcalls,
#     SUAQ_followlog.LongcallsFocal,
#     SUAQ_followlog.LongcallsHeardNotFocal,
#     SUAQ_followlog.LongcallsRecording,
#     SUAQ_followlog.NestsObserved,
#     SUAQ_followlog.GPS,
#     SUAQ_followlog.PartyPresence,
#     SUAQ_followlog.NrPartymembersOriginal,
#     SUAQ_followlog.NrPartymembersCorrected,
#     SUAQ_followlog.P1,
#     SUAQ_followlog.P2,
#     SUAQ_followlog.P3,
#     SUAQ_followlog.P4,
#     SUAQ_followlog.P5,
#     SUAQ_followlog.P6,
#     SUAQ_followlog.P7,
#     SUAQ_followlog.Begging,
#     SUAQ_followlog.Peering,
#     SUAQ_followlog.SocialPlay,
#     SUAQ_followlog.SexualActivities,
#     SUAQ_followlog.AgonisticInteractions,
#   ) %>% summarise(count = n())
# #test <- tmp_SUAQ_waypoints_11all20 %>% group_by(focal,manualDate,follow,missmatch_or_FNambiguity,SUAQ_followlog.FocalName,follownr_reliability) %>% summarise(count=n())
# 
# 
# test_df <- test %>% left_join(SUAQ_orangutans[,c(2,3,6)],by=c("focal"="SUAQ_orangutans.orangutanname","SUAQ_followlog.FocalName"="SUAQ_orangutans.Mother"),keep = FALSE,na_matches = "never",suffix=c("","infantMother."))
# specs_FocalNameNotMatching <- test_df %>% left_join(SUAQ_orangutans[,c(2,3,6)],by=c("focal"="SUAQ_orangutans.Mother","SUAQ_followlog.FocalName"="SUAQ_orangutans.orangutanname"),keep = FALSE,na_matches = "never",suffix=c("","motherInfant."))
# 
# # write_csv(specstest_FocalNameNotMatching, path = paste(
# #   paste(
# #     "/Users/stefgr/Nextcloud/12_Semester/20200313_Masterthesis/R/output/",
# #     format(Sys.Date(), "%Y%m%d"),
# #     "_SUAQAll_FocalNameNotMatchingFollowlog",
# #     sep = ""
# #   ),
# #   "csv",
# #   sep = "."
# # ))
# # TODO: Delete all the joined Followlog attributes for the found ambigous match of AgeClass and fill the empty fields with own function.
# 
# 
# ##### Find double saved waypoints/ways? due to data flow.
# ##### inspect follows
# tmp_SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20 %>% # make a id for every grouped location. Every occuring location fix gets a group ID.
#   group_by(E,N,manualTime) %>%
#   mutate(diagnostic_groupedbylocation = cur_group_id())
# 
# specs_SUAQALL_DoubleOccuringTimeLocations <-
#   tmp_SUAQ_waypoints_11all20 %>%
#   group_by(diagnostic_groupedbylocation) %>% summarise(diagnostic_numOfOccuringGPSfix =
#                                                          n()) %>%
#   left_join(
#     tmp_SUAQ_waypoints_11all20,
#     by = c("diagnostic_groupedbylocation" = "diagnostic_groupedbylocation")
#   ) %>%
#   filter(.$diagnostic_numOfOccuringGPSfix > 1) %>% group_by(follow, .$diagnostic_numOfOccuringGPSfix) %>% summarise() ## Looks ok only around 100 GPS points have exact same location and time. Maybe these are just occuring twice in a follow but they shouldn't have a too big influence.
# 
# 
# ##### Inspecting Followtypes
# levels(as.factor(SUAQ_waypoints_11all20$followtype))
# levels(as.factor(SUAQ_waypoints_11all20$SUAQ_followlog.FollowType))
# 
# specs_followtypeDiffFollowTypeFromlog <- SUAQ_waypoints_11all20 %>% filter(followtype!=SUAQ_followlog.FollowType) %>%
#   group_by(follow,followtype,SUAQ_followlog.FollowType,focal) %>% summarise()
# specs_followtypeDiffFollowTypeFromlog
# 
# specs_numOfFollowsWithFollowtype <- SUAQ_waypoints_11all20 %>% filter(!is.na(followtype))
# tmp <- SUAQ_waypoints_11all20 %>% filter(followtype=="Jg")

# specs_focalsWithoutDOB <- SUAQ_waypoints_11all20 %>% group_by(focal,as.character(SUAQ_orangutans.dateofbirth),orangutan_tot_num_of_gps) %>% summarise()

####################################################################################################################




Sys.time()-start
```



```{r R-specific preparation}
##### Create analysis collumns ######
##### Set a GPS Tracking Laufnummer oder Lösung des Zeitproblems ##### 
# Begründung: In den Tracks kommen teilweise Punkte vor welche zu einer viel späteren Zeit gemacht wurden. Oder wurde Zeit falsch gespeichert (bzw. lief umwandlung in Indonesische Zeitzone falsch)
#suaq_orangutan_follows_2020_sf<- suaq_orangutan_follows_2020_sf %>%  arrange(desc(datetime))
#SUAQ_data<- SUAQ_data %>%  arrange(desc(.$CreationTime))
#### Laufnummer für GPS Punkt erstellen ####
SUAQ_waypoints_11all20_sf %>% ggplot(aes(manualTime))+geom_histogram(bins = 1000)
SUAQ_waypoints_11all20_sf %>% filter(is.na(manualTime)) %>% 
  ggplot(aes(hms::as_hms(automaticTime)))+geom_histogram(bins = 1000) # time before conversion
specs_follows_points_in_night<- SUAQ_waypoints_11all20_sf %>% 
  filter((manualTime<lubridate::hms("04:00:00"))|(manualTime>lubridate::hms("20:00:00")))
specs_follows_points_in_night_automaticTime<- SUAQ_waypoints_11all20_sf %>% 
  filter(is.na(manualTime)&(automaticTime<lubridate::hms("04:00:00"))) # probably one outlier and one track in the night. Or wrong time settings

# todo


## DJL ##
#### Create timelag to last waypoints in not spatial dataframe #### 
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% 
  group_by(follow)%>% arrange(manualDatetime,.by_group = TRUE) %>% 
  mutate(timelag=as.numeric(difftime(as.POSIXlt(manualTime),
                                     as.POSIXlt(lag(manualTime)),units 
                                     ="secs")),
         # calculate distance with approach number 1 --> st_distance but to do that we need to calculate lead first because the lead function doesnt work within st distance (not same datatype (df))
         timelag_lead=as.numeric(difftime(as.POSIXlt(lead(manualTime)),
                                          as.POSIXlt(manualTime),units ="secs")),
         manual_distTolast=sqrt((E-lag(E))^2+(N-lag(N))^2),
         manual_distToNext=sqrt((E-lead(E))^2+(N-lead(N))^2),
         speed_last = manual_distTolast/timelag,
         speed_next = manual_distToNext/timelag_lead,
         turningAngle=turning_angle(E,N),
         altitudediff_next=altitude-lead(altitude),
         )
##### Delete all points around Research camp if edges are longer than 60m thats in the upper quartile of manual distances of edges
SUAQ_waypoints_11all20<- SUAQ_waypoints_11all20 %>% mutate(PtType=if_else(((manual_distTolast>40)|(manual_distToNext>40))&((N>336992)&(N<337052))&((E>324023)&(E<324083)),"potentially campside",PtType)) # these follows have a campsite point "1113","1730","1805","1805","1949","1951","2841","2841"

##### Histogramm for timelags of edges.
tmp_mean<- mean(SUAQ_waypoints_11all20$timelag,na.rm=TRUE)
plot_timelagToLast_Histo_log <-
  SUAQ_waypoints_11all20 %>% ggplot(aes(.$timelag)) + geom_histogram(bins = 100) +
  scale_y_log10() + labs(x = "timelag [seconds]", y = "count")+
  geom_vline(xintercept = tmp_mean,
             size = 1,
             color = "red")+
  geom_text(aes(tmp_mean+50, 150, label = paste0("Mean\n",round(tmp_mean, 2))), data.frame())
ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis_frombeginning/figures/",
    format(Sys.Date(), "%Y%m%d"),
    "_plot_timelagToLast_Histo_log",
    sep = ""
  ),
  "pdf",
  sep = "."
), plot = plot_timelagToLast_Histo_log)
##### Histogramm for distances of edges, looks the same for distance to next or distance to last ;), same edges are calculated
tmp_mean<- mean(SUAQ_waypoints_11all20$manual_distTolast,na.rm=TRUE)
plot_manualDistLast_Histo_log <-
  SUAQ_waypoints_11all20 %>% ggplot(aes(.$manual_distTolast)) + geom_histogram(bins = 100) +
  scale_x_log10(labels = scales::comma) +
  labs(x = "distance to next point [m]", y = "count") +
  geom_vline(xintercept = tmp_mean,
             size = 1,
             color = "red")+
  geom_text(aes(tmp_mean+50, 150, label = paste0("Mean\n",round(tmp_mean, 2))), data.frame())
ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis_frombeginning/figures/",
    format(Sys.Date(), "%Y%m%d"),
    "_plot_manualDistLast_Histo_log",
    sep = ""
  ),
  "pdf",
  sep = "."
), plot = plot_manualDistLast_Histo_log)





DJL_follows<- SUAQ_waypoints_11all20 %>% 
  filter(followtype=="NN") %>% 
  group_by(follow,focal,SUAQ_followlog.ClassFocal) %>% 
  summarise(DJL=sum(as.numeric(manual_distTolast), na.rm = TRUE),count=n()) %>% 
  arrange(SUAQ_followlog.ClassFocal) %>% ungroup() %>% 
  mutate(focal = fct_reorder(focal, SUAQ_followlog.ClassFocal))

DJL_follows %>% 
  ggplot( aes(x=focal, y=DJL)) +
    geom_boxplot(aes(x=focal, y=DJL, fill=focal)) +
    scale_fill_viridis(discrete = TRUE, alpha=0.6) +
    geom_jitter(color="black", size=0.4, alpha=0.9,aes(fill=SUAQ_followlog.ClassFocal)) +
    ggtitle("Day journey length for NN follows in Suaq grouped by orangutans") +
    xlab("")+
    coord_cartesian(ylim=c(0, 5000))+
    theme(legend.position = "none")+
    theme(axis.text.x = element_text(angle = 90))

#### number of follows ####
result_numoffollows<- SUAQ_waypoints_11all20 %>% group_by(follow,focal) %>% summarize(count=n()) %>% group_by(focal) %>% summarize(count=n())


#### Number of GPS points ####
specs_orangutan_tot_num_of_gps <-SUAQ_waypoints_11all20 %>% 
  group_by(focal) %>%
  summarise(n()) %>% left_join(result_numoffollows,by=c('focal'='focal'))
colnames(specs_orangutan_tot_num_of_gps) <- c("focal",
                                           "orangutan_tot_num_of_gps","orangutan_num_of_follows")

tmp<- specs_orangutan_tot_num_of_gps
SUAQ_waypoints_11all20 <-SUAQ_waypoints_11all20 %>% 
  left_join(tmp,by = c("focal" = "focal"))


### Find follows where monrnest / nightnest is missing or not first or last element of follow. (Found 87 follows of 640 NN follows)
##### Find all follows where start of follow is not mornnest or found and end is not lost or nightnest. Sth wrong?
specs_followsStartWrong <- SUAQ_waypoints_11all20[order(SUAQ_waypoints_11all20$manualDatetime , decreasing = FALSE ),] %>% group_by(follow) %>%  slice_head() %>% filter(!PtType%in%c("mornnest","found"))
specs_followsEndWrong <- SUAQ_waypoints_11all20[order(SUAQ_waypoints_11all20$manualDatetime , decreasing = TRUE ),] %>% group_by(follow) %>%  slice_head()%>% filter(!PtType%in%c("nightnest","lost")) # control other way around with slice head again instead of slice tail. Because there are two possibilities to filter; either change decreasing value or function --> Both result in the same df.

##### Find follows which are not in standard pattern (morningnest,nightnest,found,lost)
specs_followsStartAndEndWrong <- specs_followsStartWrong %>% rbind(specs_followsEndWrong)
specs_followsStartAndEndWrong_follows <- specs_followsStartAndEndWrong %>% group_by(follow) %>% summarise(count=n())


##### TODELETE


plot_gps_pttype <- SUAQ_waypoints_11all20[order(SUAQ_waypoints_11all20$manualDatetime , decreasing = TRUE ),] %>% 
  group_by(follow) %>%
  filter((follow %in% c(2298))) %>%
  ggplot()+
  geom_point(aes(E,N,color=as.character(manualDatetime)),size=1)+
  #geom_point(data = temp_duplicates,aes(E,N,fill=as.factor(follow)),size=2)+
  geom_path(aes(E,N,color=as.factor(follow)), alpha = 0.7,size=0.5)
ggplotly(plot_gps_pttype)





##### TODELETE
```

```{r harmonizing main data}
#### CHOOOSE 
SUAQ_waypoints_11all20_homo <- SUAQ_waypoints_11all20 %>% filter(PtType %in% c("range")) %>% filter(followtype == "NN")

SUAQ_waypoints_11all20_homo <- SUAQ_waypoints_11all20 %>% filter(PtType %in% c("daynest","found","lost","mornnest","nightnest","range","tree")) %>% filter(followtype == "NN")


##### Calculate the edge lengths again for "clean" follows
SUAQ_waypoints_11all20_homo<- SUAQ_waypoints_11all20_homo %>% 
  group_by(follow)%>% arrange(manualDatetime,.by_group = TRUE) %>% 
  mutate(timelag=as.numeric(difftime(as.POSIXlt(manualTime),
                                     as.POSIXlt(lag(manualTime)),units 
                                     ="secs")),
         # calculate distance with approach number 1 --> st_distance but to do that we need to calculate lead first because the lead function doesnt work within st distance (not same datatype (df))
         timelag_lead=as.numeric(difftime(as.POSIXlt(lead(manualTime)),
                                          as.POSIXlt(manualTime),units ="secs")),
         manual_distTolast=sqrt((E-lag(E))^2+(N-lag(N))^2),
         manual_distToNext=sqrt((E-lead(E))^2+(N-lead(N))^2),
         speed_last = manual_distTolast/timelag,
         speed_next = manual_distToNext/timelag_lead,
         turningAngle=turning_angle(E,N),
         altitudediff_next=altitude-lead(altitude),
         )

test <- SUAQ_waypoints_11all20_homo %>% filter(timelag_lead>1800)

specs_HmanyWith1800SF <- SUAQ_waypoints_11all20_homo %>% group_by(follow,timelag_lead) %>% summarise(number=n())
specs_HmanyWith1800SF <- SUAQ_waypoints_11all20_homo %>% group_by(follow) %>% summarise(types=n())


plot_SamplingIntervallHomo<- SUAQ_waypoints_11all20_homo %>%
  ggplot(aes(.$manualDatetime,timelag_lead, colour = focal)) +
  #geom_line() +
  geom_point()+
  theme(legend.position = "none")
plot_SamplingIntervallHomo





##### Function for defining new manualDatetime_hormonized (only if first and last entry is a mornnest and nightnest and all breaks are filled)
harmonize_waypoints <- function(flnm){
    out <- tryCatch(
        { message("Try to read file")
            file <- data.frame()
            start <- Sys.time()
            file <- st_read(flnm,layer = "waypoints") # better than read_GPX
            #if(class(file)[1]=="list"){file <- file$waypoints} # only use if read_GPX is used
            end <- Sys.time()
            processduration <- end-start
            file <- file %>% #Skip the first 16 rows because see below
              mutate(fileN=substr(flnm, 33,(nchar(flnm)+1)-5))
            temp_id <- rownames(file)
            file <- cbind(originalFileRownumber=temp_id, file)
            
            return(file)
        },
        error=function(cond) {
            message(paste("File seems not to exist", flnm))
            message("Here's the original error message:")
            message(cond)
            # Choose a return value in case of error
            return(data.frame()) # use dataframe as return instead of NA --> See here why, without it throws an error. https://stackoverflow.com/questions/48512461/error-in-bind-rows-x-id-argument-1-must-have-names-using-map-df-in-purrr
        },
        warning=function(cond) {
            message(paste("Loading file didn't work", flnm))
            message("Here's the original warning message:")
            message(cond)
            # Choose a return value in case of warning
            return(data.frame())
        },
        finally={
            message(paste("Processed URL: ", flnm," Duration: ",processduration))
            message("Finished")
        }
    )    
    return(out)
}

```


```{r saving project data}

### Make Project variables ### 
##### save all waypoints as sf ##### 
SUAQ_waypoints_11all20_sf <-  st_as_sf(SUAQ_waypoints_11all20, 
                          coords = c("E","N"), 
                          crs = 32647) # can also do that in the new sricpts


##### Project datasets one time with date for backup and one time without f.e. using ##### 
write_csv(SUAQ_waypoints_11all20, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "SUAQ_waypoints_11all20",
    sep = ""
  ),
  "csv",
  sep = "."
))
write_csv(SUAQ_fai, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "SUAQ_fai",
    sep = ""
  ),
  "csv",
  sep = "."
))
write_csv(SUAQ_orangutans, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "SUAQ_orangutans",
    sep = ""
  ),
  "csv",
  sep = "."
))
write_csv(SUAQ_followlog, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "SUAQ_followlog",
    sep = ""
  ),
  "csv",
  sep = "."
))
write_csv(SUAQ_weather, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    "SUAQ_weather",
    sep = ""
  ),
  "csv",
  sep = "."
))

### Backup
write_csv(SUAQ_waypoints_11all20, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    format(Sys.Date(), "%Y%m%d"),
    "_SUAQ_waypoints_11all20",
    sep = ""
  ),
  "csv",
  sep = "."
))
write_csv(SUAQ_fai, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    format(Sys.Date(), "%Y%m%d"),
    "_SUAQ_fai",
    sep = ""
  ),
  "csv",
  sep = "."
))
write_csv(SUAQ_orangutans, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    format(Sys.Date(), "%Y%m%d"),
    "_SUAQ_orangutans",
    sep = ""
  ),
  "csv",
  sep = "."
))
write_csv(SUAQ_followlog, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    format(Sys.Date(), "%Y%m%d"),
    "_SUAQ_followlog",
    sep = ""
  ),
  "csv",
  sep = "."
))
write_csv(SUAQ_weather, path = paste(
  paste(
    "/Users/stefgr/Nextcloud/UZH/12_Semester/20200313_Masterthesis/R/data/Processed_data/",
    format(Sys.Date(), "%Y%m%d"),
    "_SUAQ_weather",
    sep = ""
  ),
  "csv",
  sep = "."
))

```


### Analysis
## First visuals SUAQ
```{r Visualization social relationships}
##### VISUALIZE ######
##### View offspring ages and focals
test<- SUAQ_waypoints_11all20 %>% filter((!is.na(currentOffspring))) %>% filter(focal=="alice",currentOffspring=="Luther")
plot_OffspringAgeAndMotherTracking <-
  SUAQ_waypoints_11all20 %>% filter((!is.na(currentOffspring))) %>% ungroup() %>% 
  ggplot(
    aes(manualDate, .$focal, colour = currentOffspring, size =
          ageOfCurrentOffspring)
  ) + geom_point() + labs(colour = "Offspring",x="Date", y="Orangutan mother",size="Age [years]")

ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis_frombeginning/figures/",
    format(Sys.Date(), "%Y%m%d"),
    "_plot_OffspringAgeAndMotherTracking",
    sep = ""
  ),
  "pdf",
  sep = "."
), plot = plot_OffspringAgeAndMotherTracking)


#### number of points per individual no matter if its as a infant or focal ####
SUAQ_tracksperorangutanfocal_sf <-
  SUAQ_waypoints_11all20_sf %>% 
  group_by(follow,focal,infantname) %>% 
  summarise(count =n()) %>%
  ungroup() %>%
  group_by(focal) %>%
  summarize(count_focal = sum(count))
SUAQ_tracksperorangutaninfant_sf <-
  SUAQ_waypoints_11all20_sf %>% 
  group_by(follow,focal,infantname) %>% 
  summarise(count =n()) %>%
  ungroup() %>%
  group_by(infantname) %>%
  summarize(count_infant = sum(count))
SUAQ_tracksperorangutanfocal<- st_drop_geometry(SUAQ_tracksperorangutanfocal_sf)
SUAQ_tracksperorangutaninfant<- st_drop_geometry(SUAQ_tracksperorangutaninfant_sf)
SUAQ_tracksperorangutan<- SUAQ_tracksperorangutanfocal %>% left_join(SUAQ_tracksperorangutaninfant,by=c("focal"="infantname")) %>% mutate(NumPointsPerFocal=ifelse(is.na(.$count_infant),.$count_focal,.$count_infant+.$count_focal))

#### Orangutan hirarchy ####
SUAQ_family<- data.frame(SUAQ_orangutans$SUAQ_orangutans.orangutanname, 
                         SUAQ_orangutans$SUAQ_orangutans.Mother,
                         SUAQ_orangutans$SUAQ_orangutans.Sex,stringsAsFactors = FALSE)
 names(SUAQ_family) <- c("name","mother","sex")
SUAQ_family <- SUAQ_family %>%
  left_join(SUAQ_tracksperorangutan,by=c("name"="focal"))
SUAQ_family <- SUAQ_family%>%
  left_join(SUAQ_tracksperorangutan[,c(1,4)],by=c("mother"="focal"),na_matches="never")
SUAQ_family <-
  SUAQ_family %>% mutate(
    sex = ifelse(sex == "male","#b2df8a","#a6cee3"),
    name = ifelse(
      is.na(NumPointsPerFocal.x),
      name,
      paste(name, "[", NumPointsPerFocal.x,"]")
    ),
    mother = ifelse(
      is.na(NumPointsPerFocal.y),
      mother,
      paste(mother, "[", NumPointsPerFocal.y,"]")
    )
  )
SUAQ_family<- SUAQ_family %>% filter(mother!="NA  : [ NA ]")
network <- graph_from_data_frame(d=SUAQ_family, directed=F) 
layout <- layout.reingold.tilford(network, circular=T)
#layout <- layout_(network,as_tree())
V(network)[SUAQ_family$mother]$color = "#1f78b4"
V(network)[SUAQ_family$name]$color = SUAQ_family$sex
plot.igraph(network, layout=layout,edge.width=2,edge.size=2,vertex.size=5,vertex.label.dist=1,vertex.label.cex=1, label.degree=-pi/4,main="SUAQ Orangutans July 2020 \n (Mother = dark blue, Male = Green, Female = Blue)",vertex.label.color="black")
```

```{r Visualization observation duration}

#### Visualize Observation duration for individuals ####
tmp_SUAQ_waypoints_11all20 <- SUAQ_waypoints_11all20
tmp_SUAQ_waypoints_11all20 <-
  tmp_SUAQ_waypoints_11all20 %>%  mutate(focal = paste(focal," [#GPS: ", orangutan_tot_num_of_gps,"] [#Follows: ",orangutan_num_of_follows,"]"))
tmp_SUAQ_waypoints_11all20$focal = with(tmp_SUAQ_waypoints_11all20,
                                        reorder(focal, orangutan_tot_num_of_gps, length))

plot_orangutan_followperiods <- tmp_SUAQ_waypoints_11all20 %>%
  filter(!is.na(focal)) %>%
  filter(SUAQ_orangutans.Sex=="female") %>% 
  ggplot(aes(manualDate, focal)) +
  geom_point(aes(colour = focal)) +
  labs(title = "Duration of observation for \n female orangutans", x = "date", y =
         "orangutanname") +
  theme(legend.position = "none")
plot_orangutan_followperiods

#### Histogram of orangutans and their number of follows ####
specs_orangutan_tot_num_of_gps<- specs_orangutan_tot_num_of_gps %>%
  left_join(SUAQ_orangutans[,c(1:5)],by=c("focal"="SUAQ_orangutans.orangutanname"))
specs_orangutan_tot_num_of_gps %>% 
  filter(.$SUAQ_orangutans.Sex=="female") %>%
  ggplot(aes(reorder(focal, -orangutan_num_of_follows),x =orangutan_num_of_follows))+
  geom_bar(stat="identity")

#### Histogram of number of gps per individual #### 
plot_orangutan_followhisto<- tmp_SUAQ_waypoints_11all20 %>%
  filter(!is.na(focal)) %>%
  filter(SUAQ_orangutans.Sex=="female") %>% 
  ggplot(aes(manualDate, focal,fill=focal)) +
  geom_density_ridges(alpha=0.6,
                      scale=0.95, 
                      stat="binline", 
                      bins=120,
                      jittered_points=TRUE,
                      draw_baseline = FALSE,
                      color = "Black") + # bin for every 3 months
  theme_ridges() +
  labs(title = "Duration of observation for \n female orangutans", x = "Date", y =
         "Orangutan name [number of GPS observations]") +
  theme(legend.position = "none")
plot_orangutan_followhisto

#### Histogram of number of gps per individual for the 10 most tracked females #### 
plot_orangutan_followhisto_best<- tmp_SUAQ_waypoints_11all20 %>%
  filter(!is.na(focal)) %>%
  filter(SUAQ_orangutans.Sex=="female") %>% 
  filter(orangutan_tot_num_of_gps>200) %>% 
  ggplot(aes(manualDate,focal,fill=focal)) +
  geom_density_ridges(alpha=0.6,
                      scale=0.95, 
                      stat="binline", 
                      bins=120,
                      jittered_points=TRUE,
                      draw_baseline = FALSE,
                      color = "Black") + # bin for every 3 months
  theme_ridges() +
  labs(title = "Duration of observation for \n female orangutans", x = "date", y =
         "orangutanname [number of GPS observations]") +
  theme(legend.position = "none")
plot_orangutan_followhisto_best





p1 <- tmp_SUAQ_waypoints_11all20 %>%
  filter(!is.na(focal)) %>%
  filter(SUAQ_orangutans.Sex=="female") %>% 
  group_by(focal,manualDate,follow) %>% summarise() %>% 
  ggplot(aes(manualDate, focal)) +
  annotate("rect", xmin=as.Date("2010-01-01"), xmax=as.Date("2010-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  annotate("rect", xmin=as.Date("2012-01-01"), xmax=as.Date("2012-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  annotate("rect", xmin=as.Date("2014-01-01"), xmax=as.Date("2014-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  annotate("rect", xmin=as.Date("2016-01-01"), xmax=as.Date("2016-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  annotate("rect", xmin=as.Date("2018-01-01"), xmax=as.Date("2018-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  annotate("rect", xmin=as.Date("2020-01-01"), xmax=as.Date("2020-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  geom_point(aes(colour = focal,stroke=0.3),shape =4,size=1.5) +
  labs( x = "date", y =
         "orangutanname") +
  theme(legend.position = "none",
        plot.margin = unit(c(1,0.05,0.02,1), "cm"))+
  theme(#axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x = element_text(angle = 45, vjust = 0.6, hjust=0),
        axis.title.y = element_blank())+
  scale_x_date(position = "top",breaks = scales::pretty_breaks(n = 10))+
  labs(x="")


p2 <- tmp_SUAQ_waypoints_11all20 %>%
  filter(!is.na(focal)) %>%
  filter(SUAQ_orangutans.Sex=="female") %>% 
  mutate(orangutan_num_of_follows_log=log10(orangutan_num_of_follows),orangutan_num_of_follows_percentage=(orangutan_num_of_follows/nrow(result_totnumfollows)) ) %>%  # if i want log scales
  group_by(focal,orangutan_num_of_follows,orangutan_num_of_follows_percentage,orangutan_num_of_follows_log) %>% summarise() %>% 
  ggplot() +
  geom_bar(aes(x=orangutan_num_of_follows_percentage ,y=focal,fill = focal),stat= "identity",na.rm = TRUE,width = 0.4)+
  geom_text(aes(label = scales::percent(orangutan_num_of_follows_percentage,accuracy = .001), # show two decimals
                   x=orangutan_num_of_follows_percentage ,y=focal),size=1.5, stat= "identity", hjust = -0.5) +
  theme(legend.position = "none")+
  theme_minimal()+
  theme(axis.text.y = element_blank(),
        #axis.text.x = element_text(angle = 90,size=12),
        axis.text.x = element_blank(),
        #axis.ticks.y = element_blank(),
        #axis.ticks.x = element_blank(),
        axis.title.y = element_blank(),
        plot.background = element_blank(),
        #axis.title.x= element_text(angle = -45,hjust = 1.2))+
        axis.title.x= element_blank())+
  scale_x_continuous(labels = percent_format(),position = "top")+
  labs(y="# Follows") +
  theme(legend.position = "none",
        plot.margin = unit(c(0,1,2.06,0), "cm"))+
  xlim(0,0.2)


p3 <- tmp_SUAQ_waypoints_11all20 %>%
  filter(!is.na(focal)) %>%
  filter(SUAQ_orangutans.Sex=="female") %>% 
  ggplot(aes(x=manualDate)) +
  geom_histogram(bins = 120)+ # bins for every 3 month
  theme_minimal()+
  annotate("rect", xmin=as.Date("2010-01-01"), xmax=as.Date("2010-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  annotate("rect", xmin=as.Date("2012-01-01"), xmax=as.Date("2012-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  annotate("rect", xmin=as.Date("2014-01-01"), xmax=as.Date("2014-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  annotate("rect", xmin=as.Date("2016-01-01"), xmax=as.Date("2016-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  annotate("rect", xmin=as.Date("2018-01-01"), xmax=as.Date("2018-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  annotate("rect", xmin=as.Date("2020-01-01"), xmax=as.Date("2020-12-31"), ymin=-Inf, ymax=Inf, alpha=0.1, fill="coral4")+
  theme(legend.position = "none")+
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        plot.background = element_blank(),
        axis.text.y = element_text(size=5),
        legend.position = "none",
        plot.margin = unit(c(0,0,1,0.56), "cm"))+
  scale_y_continuous()+
  scale_x_date(breaks = scales::pretty_breaks(n = 10))+
  scale_y_reverse()


blank <- grid.rect(gp=gpar(col="white")) # create empty white plots to make margins afterwards
p<- arrangeGrob( # Use only grobs to save it
  arrangeGrob(
    p1,
    arrangeGrob(blank, p3, ncol = 2, widths = c(4.8 / 40, 35.2 / 40)),
    heights = c(6.5 / 8, 1.5 / 8),
    nrow = 2
  ),
  arrangeGrob(blank, p2, heights = c(3.27 / 16, 12.83 / 16), nrow = 2),
  ncol = 2,
  widths = c(3, 1)
) 
ggsave(filename = paste(
  paste(
    "/Users/stefgr/Dropbox/Apps/Overleaf/Msc_Thesis_frombeginning/figures/",
    format(Sys.Date(), "%Y%m%d"),
    "_Data_FemaleOrangutansFollowDensityTemporal",
    sep = ""
  ),
  "pdf",
  sep = "."
), plot = p)




```

```{r Visualization gps on map}
##### Grouping follows and visualize it #####
plot1<- SUAQ_waypoints_11all20 %>%
  group_by(follow) %>%
  ggplot(aes(E,N))+
  geom_point(aes(color=SUAQ_waypoints_11all20$focal),size=0.3)+
  geom_path(aes(color=SUAQ_waypoints_11all20$focal), alpha = 0.2,size=0.3)+
  theme(legend.position = "none")
plot1


#####  Zoom-Panable map of tracks based on follow attribute ##### 
plot2<- SUAQ_waypoints_11all20 %>%
  group_by(follow) %>%
  ggplot(aes(E,N))+
  geom_point(aes(color=SUAQ_waypoints_11all20$focal),size=0.3)+
  geom_path(aes(color=SUAQ_waypoints_11all20$focal), alpha = 0.2,size=0.3)
ggplotly(plot2)

#### FEMALE: Map of female gps tracks ####
# Zoom-Panable map of tracks of females with over 200 GPS points
tmp_SUAQ_mosttrackedfemales <- SUAQ_waypoints_11all20 %>%
  filter(!(SUAQ_orangutans.Sex == "male")) %>%
  filter(
    focal %in% c(
      "lisa",
      "friska",
      "ellie",
      "cissy",
      "lilly",
      "yulia",
      "raffi",
      "sarabi",
      "trident",
      "alice",
      "mocca",
      "cinnamon"
    )
  )
tmp_SUAQ_mosttrackedfemales_sf <- SUAQ_waypoints_11all20_sf %>%
  filter(!(SUAQ_orangutans.Sex == "male")) %>%
  filter(
    focal %in% c(
      "lisa",
      "friska",
      "ellie",
      "cissy",
      "lilly",
      "yulia",
      "raffi",
      "sarabi",
      "trident",
      "alice",
      "mocca",
      "cinnamon"
    )
  )
#### Plot most tracked females OU
plot2<-tmp_SUAQ_mosttrackedfemales %>% 
  group_by(follow) %>%
  ggplot(aes(E,N))+
  geom_point(aes(color=focal),size=0.3)+
  geom_path(aes(color=focal), alpha = 0.2,size=0.3)
ggplotly(plot2)

#### Find wrong gps points #### 
plot_gps_pttype<-tmp_SUAQ_mosttrackedfemales %>% 
  group_by(follow) %>%
  ggplot(aes(E,N))+
  geom_point(aes(color=tmp_SUAQ_mosttrackedfemales$PtType),size=0.3)
  #geom_path(aes(color=focal), alpha = 0.2,size=0.3)
ggplotly(plot_gps_pttype)



#### analysis of gps tracks where focals are not matching
temp<-SUAQ_waypoints_11all20 %>% 
  filter(follow %in% c("1101277","1101278"))
temp<-SUAQ_waypoints_11all20 %>% 
  filter(fileN %in% c("20150204_Friska_Fikar_NN"))


plot_gps_pttype<-SUAQ_waypoints_11all20 %>% 
  filter(follow %in% c("689")) %>% 
  group_by(follow) %>%
  ggplot()+
  geom_point(aes(E,N,color=followername),size=1)+
  geom_point(data = SUAQ_locationnetwork_loc,aes(E,N,fill="black"),size=2)+
  geom_path(aes(E,N,color=focal), alpha = 0.7,size=0.5)
ggplotly(plot_gps_pttype)




##### show points where edge length is high
tmp_SUAQ_gpsOfFollowsCOntainingAbnormalEdgeLengths<-SUAQ_waypoints_11all20 %>% 
  filter((manual_distToNext>150)|( manual_distTolast >150)) %>% 
  group_by(manualDate,focal,follow,followername) %>% 
  summarise()

plot_distToLats_over_100<-SUAQ_waypoints_11all20 %>% 
  filter() %>% 
  filter((manual_distToNext>200)&( manual_distTolast >200)) %>% 
  group_by(focal,manualDate,follow) %>%
  ggplot(aes(E,N))+
  geom_point(aes(color=PtType),size=1)+
  geom_path(aes(color=as.factor(follow)), alpha = 0.8,size=0.6)
ggplotly(plot_distToLats_over_100)



#### Create convex hulls on points of each most tracked female orangutan #### 
tmp_SUAQ_mosttrackedfemales_chulls <- tmp_SUAQ_mosttrackedfemales_sf %>%
  group_by(focal) %>% 
  summarise(geometry = st_combine(geometry) ) %>%
  st_convex_hull()
tmp_SUAQ_mosttrackedfemales_centroid <- tmp_SUAQ_mosttrackedfemales_sf %>%
  group_by(focal) %>% 
  summarise(geometry = st_combine(geometry) ) %>%
  st_centroid()
plot_SUAQ_mosttrackedfemales_chulls_centroid <-
  ggplot(tmp_SUAQ_mosttrackedfemales_chulls) + 
  geom_sf(data = tmp_SUAQ_mosttrackedfemales_chulls,
                                               aes(colour = focal, alpha = 1),
                                               fill = NA)+
  #geom_sf(data = tmp_SUAQ_mosttrackedfemales_centroid,aes(colour = focal, alpha = 1))+
  geom_sf(data = SUAQ_pathnetwork_sf,
                                               aes(colour = "black", alpha = 1),
                                               fill = NA,colour = "black")
ggplotly(plot_SUAQ_mosttrackedfemales_chulls_centroid)

#### Create MCP with percentage #### 
tmp_SUAQ_waypoints_morethan50gps_11all20<- tmp_SUAQ_waypoints_11all20 %>% 
  filter(orangutan_tot_num_of_gps>=50)
tmp_SUAQ_waypoints_morethan50gps_11all20.sp<- tmp_SUAQ_waypoints_morethan50gps_11all20 %>% 
  dplyr::select(focal,E,N)
coordinates(tmp_SUAQ_waypoints_morethan50gps_11all20.sp) <- c("E","N")
proj4string(tmp_SUAQ_waypoints_morethan50gps_11all20.sp) <- CRS( "+proj=utm +zone=47 +datum=WGS84 +units=m +no_defs" )

tmp_SUAQ_waypoints_morethan50gps_11all20.mcp<- mcp(tmp_SUAQ_waypoints_morethan50gps_11all20.sp,percent = 95)

tmp_SUAQ_waypoints_morethan50gps_11all20.spgeo <- spTransform(tmp_SUAQ_waypoints_morethan50gps_11all20.sp, CRS("+proj=longlat"))
tmp_SUAQ_waypoints_morethan50gps_11all20.mcpgeo <- spTransform(tmp_SUAQ_waypoints_morethan50gps_11all20.mcp, CRS("+proj=longlat"))

mybasemap <- get_stamenmap(bbox = c(left = min(tmp_SUAQ_waypoints_morethan50gps_11all20.spgeo@coords[,1])-0.005, 
                                    bottom = min(tmp_SUAQ_waypoints_morethan50gps_11all20.spgeo@coords[,2])-0.005, 
                                    right = max(tmp_SUAQ_waypoints_morethan50gps_11all20.spgeo@coords[,1])+0.005, 
                                    top = max(tmp_SUAQ_waypoints_morethan50gps_11all20.spgeo@coords[,2])+0.005), 
                           zoom = 12)

tmp_SUAQ_waypoints_morethan50gps_11all20.geo <- data.frame(tmp_SUAQ_waypoints_morethan50gps_11all20.spgeo@coords, 
                          id = tmp_SUAQ_waypoints_morethan50gps_11all20.spgeo@data$focal )

mcp_map_95 <- ggmap(mybasemap) + 
  geom_polygon(data =     fortify(tmp_SUAQ_waypoints_morethan50gps_11all20.mcpgeo),  
               # Polygon layer needs to be "fortified" to add geometry to the dataframe
              aes(long, lat, colour = id, fill = id),
              alpha = 0.3) + # alpha sets the transparency
  geom_point(data = tmp_SUAQ_waypoints_morethan50gps_11all20.geo, 
             aes(x = tmp_SUAQ_waypoints_morethan50gps_11all20.geo$E, y = tmp_SUAQ_waypoints_morethan50gps_11all20.geo$N, colour = 
                   tmp_SUAQ_waypoints_morethan50gps_11all20.geo$id))  +
  theme(legend.position = c(0.15, 0.80)) +
  labs(x = "Longitude", y = "Latitude")
mcp_map_95

mcp(tmp_SUAQ_waypoints_morethan50gps_11all20.sp,percent = 95)
graphics.off() 
par("mar") 
par(mar=c(1,1,1,1))
mcp.area(tmp_SUAQ_waypoints_morethan50gps_11all20.sp, percent = seq(20, 100, by = 5))
hrs


#### Plot mcp with ggplot ####
mcp_map_95 <- ggmap(mybasemap) +
  geom_polygon(
    data =     fortify(tmp_SUAQ_waypoints_morethan50gps_11all20.mcpgeo),
    # Polygon layer needs to be "fortified" to add geometry to the dataframe
    aes(long, lat, colour = id, fill = id),
    alpha = 0.3
  ) + # alpha sets the transparency
  geom_point(
    data = tmp_SUAQ_waypoints_morethan50gps_11all20.geo,
    aes(
      x = E,
      y = N,
      colour =
        id
    )
  )  +
  theme(legend.position = c(0.15, 0.80)) +
  labs(x = "Longitude", y = "Latitude")
ggplotly(mcp_map_95)



#### Create kernelUD #### 
SUAQ_HR_kernelUD<- kernelUD(tmp_SUAQ_waypoints_morethan50gps_11all20.sp, h = "href", grid = 60,
             same4all = FALSE, hlim = c(0.1, 1.5),
             kern = c("bivnorm", "epa"), extent = 1,
             boundary = NULL)
plot(SUAQ_HR_kernelUD$ellie)


#### Create dBBMM #### 
tmp_SUAQ_mosttrackedfemales_test <- tmp_SUAQ_mosttrackedfemales %>%
  filter(!is.na(.$manualDatetime) &
           !is.na(focal)) %>% group_by(follow) %>%
  arrange(manualDatetime) %>%
  group_by(focal) %>%
  distinct(manualDatetime, focal, .keep_all = TRUE)
tmp_SUAQ_mosttrackedfemales_test <-
  tmp_SUAQ_mosttrackedfemales_test %>%
  group_by(focal)
data2 <- move(
  x = tmp_SUAQ_mosttrackedfemales_test$E,
  y = tmp_SUAQ_mosttrackedfemales_test$N,
  time = tmp_SUAQ_mosttrackedfemales_test$manualDatetime,
  proj = CRS("+proj=utm +zone=47 +datum=WGS84 +units=m +no_defs"),
  animal = tmp_SUAQ_mosttrackedfemales_test$focal
)
plot(data, type = "b", pch = 20)



#### GENDER: #### 
plot_gender_map<- SUAQ_waypoints_11all20 %>%
  group_by(follow) %>%
  ggplot(aes(E,N))+
  geom_point(aes(color=SUAQ_orangutans.Sex),size=0.3)
  #geom_path(aes(color=SUAQ_orangutans.Sex), alpha = 0.2,size=0.3)
ggplotly(plot_gender_map)



####  Map with tiles (leaflet) #### 
pal <- colorFactor(get_palette(palette = "default", 42), domain = levels(as.factor(SUAQ_waypoints_11all20_sf$focal)))

plot2<- leaflet(data = st_transform(SUAQ_waypoints_11all20_sf, crs = 4326)) %>% 
  addProviderTiles(providers$Esri.WorldImagery) %>% 
  addCircleMarkers(color = ~pal(SUAQ_waypoints_11all20_sf$focal),
                   fillOpacity = 1,
                   radius = 1,
                   opacity = 1)
plot2



## next idea homerange per month or year (need more years!)
# suaq_orangutan_chulls_month <- suaq_orangutan_follows_2020_sf %>%
#   group_by(orangutanname) %>%
#   summarise(geometry = st_combine(geometry)) %>%
#   st_convex_hull()
# rownames(suaq_orangutan_chulls_month) <- suaq_orangutan_chulls_month$orangutanname
# 
# suaq_orangutan_chulls_january <- suaq_orangutan_follows_2020_sf %>%
#   filter(between(datetime, as.Date("2019-01-01"),as.Date("2019-01-31"))) %>% 
#   group_by(orangutanname) %>%
#   summarise(geometry = st_combine(geometry)) %>%
#   st_convex_hull()
# colnames(suaq_orangutan_chulls_january)[2]
# class(suaq_orangutan_chulls_january$geometry[1])
# 
# suaq_orangutan_chulls_month<-bind_cols(suaq_orangutan_chulls_month, suaq_orangutan_chulls_january,by = c("orangutanname" = "orangutanname"))
# ?full_join
# 
# suaq_orangutan_chulls %>% ggplot()+
#     geom_polygon(suaq_orangutan_chulls$geometry)
# plot_tmp<- ggplot(suaq_orangutan_chulls) + geom_sf(data = suaq_orangutan_chulls, aes(colour = orangutanname,alpha=1),fill=NA)
# ggplotly(plot_tmp)

```